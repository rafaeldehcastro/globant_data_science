<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[SBIR Phase I:  High performance non-volatile-memory circuits for artificial intelligence]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/01/2020</AwardEffectiveDate>
<AwardExpirationDate>12/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>225000.00</AwardTotalIntnAmount>
<AwardAmount>250000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>15030000</Code>
<Directorate>
<Abbreviation>TIP</Abbreviation>
<LongName>Dir for Tech, Innovation, &amp; Partnerships</LongName>
</Directorate>
<Division>
<Abbreviation>TI</Abbreviation>
<LongName>Translational Impacts</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ela Mirowski</SignBlockName>
<PO_EMAI>emirowsk@nsf.gov</PO_EMAI>
<PO_PHON>7032922936</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is to enable wider adoption of Artificial Intelligence (AI)  through development of a high-bandwidth, low-cost integrated circuit memory solution.  AI is poised to make fundamental changes to how people live and work but require dramatic improvement in computing power and efficiency.  So-called "edge AI" applications, such as smart home devices, smart city, and autonomous vehicles, will demand on-device AI subject to tight power and cost constraints.  Current configurations with conventional memories may not offer a combination of performance, cost, power, operating temperature range necessary for many edge applications. The proposed project will advance the development of a new circuit architecture to address these challenges. &lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research Phase I project develops high-speed analog circuit architectures and techniques in the context of emerging memory readout circuits.  The proposed novel read circuit is applicable to magnetoresistive random-access memory (MRAM) and other emerging memories to achieve high performance and low power.  This Phase I project will fully develop the concept and overcome key technical challenges that include (1) increasing differential amplifier speed and margin under severe area limitation, (2) reducing noise level and silicon area of a novel signal passing circuit, and (3) searching for an efficient way to serve typical data access requests with the novel read operation. The project goals are to validate the novel MRAM read circuit with silicon test data and perform a model study to quantify system level benefits.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>05/01/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/20/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2014959</AwardID>
<Investigator>
<FirstName>Yu</FirstName>
<LastName>Lu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yu Lu</PI_FULL_NAME>
<EmailAddress><![CDATA[lu.yu@supermemtech.com]]></EmailAddress>
<NSF_ID>000817566</NSF_ID>
<StartDate>05/01/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SUPERMEM INC.</Name>
<CityName>LA JOLLA</CityName>
<ZipCode>920371482</ZipCode>
<PhoneNumber>9143164030</PhoneNumber>
<StreetAddress>4250 EXECUTIVE SQ STE 675</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>50</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA50</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>LP7ALE5DGMQ3</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>SUPERMEM INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[SUPERMEM INC.]]></Name>
<CityName>La Jolla</CityName>
<StateCode>CA</StateCode>
<ZipCode>920378404</ZipCode>
<StreetAddress><![CDATA[4250 Executive Sq Ste 200]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>50</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA50</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramElement>
<Code>8091</Code>
<Text>SBIR Outreach &amp; Tech. Assist</Text>
</ProgramElement>
<ProgramReference>
<Code>8035</Code>
<Text>Hardware Devices</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~250000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-fb9dc63d-7fff-1499-5dfb-d8e1c1460758"> </span></p> <p dir="ltr"><span>STT-MRAM has emerged as the embedded non-volatile-memory (NVM) of choice for advanced technologies starting at the 22nm/28nm CMOS nodes.&nbsp; The combination of long-term data storage, fast random access, and compatibility with advanced CMOS for processors is very unique and opens new possibilities to engineer computing systems.&nbsp; One of the most intriguing opportunities is on-device Artificial-Intelligence (AI) computing where memory access plays a critical role in overall system performance.&nbsp; This is especially true for low power NN computation on wearable and IoT devices, where the key metrics for the memory component include: (1) data access bandwidth (BW) and (2) energy cost per data retrieved or pJ/b.&nbsp; With this NSF sponsored project, SuperMem Inc. developed a novel memory read architecture, High-Bandwidth-Sense-Amplifier or HBSA (patent-pending), to solve both these two challenges and achieve:</span></p> <ol> <li dir="ltr"> <p dir="ltr"><span>4x sustained data bandwidth,&nbsp; and</span></p> </li> <li dir="ltr"> <p dir="ltr"><span>3x read energy reduction during long burst read.</span></p> </li> </ol> <p dir="ltr"><span>HBSA leverages the predictability of long burst read operations to increase the utilization of precision circuit components and avoid unnecessary power consumption.&nbsp; Detailed analysis showed that HBSA can be further extended to increase data bandwidth. The area overhead is about 5% for a 4Mb macro, and will be smaller for larger memory arrays.</span></p> <p dir="ltr"><span>SuperMem Inc. proposes a low-power AI computer by integrating High-Bandwidth MRAM with dedicated Multiply-Accumulate-Circuit (MAC) through either monolithic integration or 3-D stacking.&nbsp; Analysis shows that 10x higher bandwidth in the fetching of large NN models can be easily achieved using 8% power of DDR based systems.</span></p> <p dir="ltr"><span>SuperMem Inc. designed and taped out a testchip using advanced STT-MRAM technology. The testchip contains multiple macros using both the conventional read circuit and using HBSA, and are based on the 1T1J STT-MRAM cell.&nbsp; The macro with HBSA achieved 400Mb/s per IO with 12.5ns latency, and less than 0.3pJ/bit when reading out 1Kbit of data.</span></p> <p dir="ltr"><span>SuperMem is developing an easy-to-use AI accelerator that computes MB-level NN models without the cost and power requirement of DRAM.&nbsp; Such products fill a gap between ultra-low-power &ldquo;always-on&rdquo; processors that can only run KB level NN and power-hungry processors that require DRAM.</span></p> <p dir="ltr"><span>SuperMem engaged with various industry and research organizations to develop broad partnerships that will give ubiquitous AI far greater capabilities than simple tasks like keyword-spotting.&nbsp; SuperMem&rsquo;s breakthrough technology is the key to add intelligence to billions of things, unclog the internet from data traffic, and save terawatt-hours of electricity.</span></p> <div><span><br /></span></div> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 01/14/2022<br>      Modified by: Yu&nbsp;Lu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   STT-MRAM has emerged as the embedded non-volatile-memory (NVM) of choice for advanced technologies starting at the 22nm/28nm CMOS nodes.  The combination of long-term data storage, fast random access, and compatibility with advanced CMOS for processors is very unique and opens new possibilities to engineer computing systems.  One of the most intriguing opportunities is on-device Artificial-Intelligence (AI) computing where memory access plays a critical role in overall system performance.  This is especially true for low power NN computation on wearable and IoT devices, where the key metrics for the memory component include: (1) data access bandwidth (BW) and (2) energy cost per data retrieved or pJ/b.  With this NSF sponsored project, SuperMem Inc. developed a novel memory read architecture, High-Bandwidth-Sense-Amplifier or HBSA (patent-pending), to solve both these two challenges and achieve:   4x sustained data bandwidth,  and   3x read energy reduction during long burst read.   HBSA leverages the predictability of long burst read operations to increase the utilization of precision circuit components and avoid unnecessary power consumption.  Detailed analysis showed that HBSA can be further extended to increase data bandwidth. The area overhead is about 5% for a 4Mb macro, and will be smaller for larger memory arrays. SuperMem Inc. proposes a low-power AI computer by integrating High-Bandwidth MRAM with dedicated Multiply-Accumulate-Circuit (MAC) through either monolithic integration or 3-D stacking.  Analysis shows that 10x higher bandwidth in the fetching of large NN models can be easily achieved using 8% power of DDR based systems. SuperMem Inc. designed and taped out a testchip using advanced STT-MRAM technology. The testchip contains multiple macros using both the conventional read circuit and using HBSA, and are based on the 1T1J STT-MRAM cell.  The macro with HBSA achieved 400Mb/s per IO with 12.5ns latency, and less than 0.3pJ/bit when reading out 1Kbit of data. SuperMem is developing an easy-to-use AI accelerator that computes MB-level NN models without the cost and power requirement of DRAM.  Such products fill a gap between ultra-low-power "always-on" processors that can only run KB level NN and power-hungry processors that require DRAM. SuperMem engaged with various industry and research organizations to develop broad partnerships that will give ubiquitous AI far greater capabilities than simple tasks like keyword-spotting.  SuperMemâ€™s breakthrough technology is the key to add intelligence to billions of things, unclog the internet from data traffic, and save terawatt-hours of electricity.               Last Modified: 01/14/2022       Submitted by: Yu Lu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
