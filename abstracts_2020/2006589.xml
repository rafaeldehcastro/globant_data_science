<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[AF: CIF: Small: Communication complexity techniques beyond classical information theory]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>497639.00</AwardTotalIntnAmount>
<AwardAmount>497639</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Phillip Regalia</SignBlockName>
<PO_EMAI>pregalia@nsf.gov</PO_EMAI>
<PO_PHON>7032922981</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[Communication is central to modern computing systems, which involve data distributed across multiple entities. Developing communication-efficient algorithmic strategies (protocols) to solve problems featuring distributed data is therefore an important practical goal. Correspondingly, communication complexity---which studies the possibilities and limitations of such protocols---is important to foundational research in computer science.  In fact, the influence of communication complexity runs much deeper, because the operation of an algorithm can itself be seen as a careful orchestration of information flow from input bits to output bits, which gives rise to a communication protocol between abstract entities. Key questions in communication complexity are: how much efficiency is gained by allowing the communicating parties to (a) use randomized strategies that may err with some small probability, or (b) use a complex pattern of interactive communication as opposed to a simple one?  This project will address some such questions, seeking theorems that provably require fresh mathematical ideas, forcing an expansion of our mathematical arsenal. The project aims to grow the foundations of communication complexity either through novel lower bounds or by obtaining surprising new protocols that may teach us algorithmic lessons.&lt;br/&gt;&lt;br/&gt;Viewing communication as information flow and quantifying this using the machinery of Shannon entropy and Kullback-Leibler divergence is a powerful technique for proving lower bounds on the communication required to accomplish a task. This project's central goal is to make progress on problems where this general paradigm provably cannot work. The investigator has identified some concrete communication tasks where a deterministic solution plausibly requires considerably more resources than a randomized solution, and proposes to prove such separations by developing a more delicate quantification of information flow that is attuned to deterministic communication protocols. Additionally, the project will study a class of communication problems involving parties with asymmetric knowledge (the so-called Arthur-Merlin setting, where one super-player knows all of the distributed input but is not blindly trusted by the other, regular, players), where classical information theory fails to capture the communication from the super-player.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>06/24/2020</MinAmdLetterDate>
<MaxAmdLetterDate>06/24/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2006589</AwardID>
<Investigator>
<FirstName>Amit</FirstName>
<LastName>Chakrabarti</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Amit Chakrabarti</PI_FULL_NAME>
<EmailAddress><![CDATA[Amit.Chakrabarti@Dartmouth.edu]]></EmailAddress>
<NSF_ID>000202522</NSF_ID>
<StartDate>06/24/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Dartmouth College</Name>
<CityName>HANOVER</CityName>
<ZipCode>037552170</ZipCode>
<PhoneNumber>6036463007</PhoneNumber>
<StreetAddress>7 LEBANON ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New Hampshire</StateName>
<StateCode>NH</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NH02</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>EB8ASJBCFER9</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF DARTMOUTH COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>T4MWFG59C6R3</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Dartmouth College]]></Name>
<CityName>Hanover</CityName>
<StateCode>NH</StateCode>
<ZipCode>037551404</ZipCode>
<StreetAddress><![CDATA[Office of Sponsored Projects]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Hampshire</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NH02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7927</Code>
<Text>COMPLEXITY &amp; CRYPTOGRAPHY</Text>
</ProgramReference>
<ProgramReference>
<Code>7935</Code>
<Text>COMM &amp; INFORMATION THEORY</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~497639</FUND_OBLG>
</Award>
</rootTag>
