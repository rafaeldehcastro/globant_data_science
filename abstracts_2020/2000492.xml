<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Student Reasoning Patterns in Next Generation Science Standards Assessment]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2020</AwardEffectiveDate>
<AwardExpirationDate>06/30/2022</AwardExpirationDate>
<AwardTotalIntnAmount>299862.00</AwardTotalIntnAmount>
<AwardAmount>299862</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EDU</Abbreviation>
<LongName>Directorate for STEM Education</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gregg Solomon</SignBlockName>
<PO_EMAI>gesolomo@nsf.gov</PO_EMAI>
<PO_PHON>7032928333</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[The goal of this project, led by a team at Educational Testing Services, is to develop automated tools by which assessments aligned with the Next Generation Science Standards (NGSS) can be scored to reveal student reasoning patterns, some of which would reflect particular weaknesses in student reasoning. Reasoning patterns refer to various ways of student thinking when making sense of a natural phenomenon or trying to solve a problem. The investigators will conduct a proof of concept study to develop automated diagnostics that can identify middle-school students’ reasoning patterns based on their written responses to assessments of their understanding of concepts in ecology. With the states increasingly moving towards implementing assessments aligned to the NGSS, feedback based on individual students’ reasoning patterns would allow teachers the ability to develop more individualized feedback and would also support the design of automated instruction based on evidence of what students know and how they learn, rather than instruction based simply on whether they had answered correctly or not. The project is funded by the EHR Core Research (ECR) program, which supports work that advances the fundamental research literature on STEM learning. &lt;br/&gt;&lt;br/&gt;The investigators will conduct a proof of concept study to identity student reasoning patterns for making sense of ecosystems by investigating student responses to constructed test items collected from an NGSS-aligned assessment database. In the first stage of the study, the investigators will use a 3-dimensional (content knowledge, procedural knowledge, and epistemic knowledge) approach to assessment that aligns with the NGSS. They will leverage cutting-edge natural language processing (NLP) techniques to identify student reasoning patterns, attempting to label text as data description and system relationship description and attempting to identify superficial integration as opposed to integrated reasoning. The investigators will engage in an iterative process to compare the classification produced by the automated tools with that produced by human scorers. With this classification developed and validated, the investigators will have demonstrated the feasibility of later attempting to develop an NLP-based automated system that could provide immediate feedback to students, identifying weaknesses in reasoning rather than only whether an answer was correct, and to teachers, allowing them to tailor instruction to individual students.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>04/02/2020</MinAmdLetterDate>
<MaxAmdLetterDate>11/05/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2000492</AwardID>
<Investigator>
<FirstName>Matthew</FirstName>
<LastName>Johnson</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Matthew Johnson</PI_FULL_NAME>
<EmailAddress><![CDATA[msjohnson@ets.org]]></EmailAddress>
<NSF_ID>000550937</NSF_ID>
<StartDate>04/02/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Lei</FirstName>
<LastName>Liu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lei Liu</PI_FULL_NAME>
<EmailAddress><![CDATA[lliu001@ets.org]]></EmailAddress>
<NSF_ID>000623460</NSF_ID>
<StartDate>04/02/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Dante</FirstName>
<LastName>Cisterna-Alburquerque</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dante Cisterna-Alburquerque</PI_FULL_NAME>
<EmailAddress><![CDATA[dcisterna@ets.org]]></EmailAddress>
<NSF_ID>000738870</NSF_ID>
<StartDate>04/02/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Brian</FirstName>
<LastName>Riordan</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Brian W Riordan</PI_FULL_NAME>
<EmailAddress><![CDATA[briordan@ets.org]]></EmailAddress>
<NSF_ID>000763693</NSF_ID>
<StartDate>11/05/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Aoife</FirstName>
<LastName>Cahill</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Aoife Cahill</PI_FULL_NAME>
<EmailAddress><![CDATA[acahill@ets.org]]></EmailAddress>
<NSF_ID>000789539</NSF_ID>
<StartDate>04/02/2020</StartDate>
<EndDate>11/05/2021</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Educational Testing Service</Name>
<CityName>PRINCETON</CityName>
<ZipCode>085402218</ZipCode>
<PhoneNumber>6096832734</PhoneNumber>
<StreetAddress>660 ROSEDALE RD</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ03</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>SZN1MPHQN853</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>EDUCATIONAL TESTING SERVICE</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>SZN1MPHQN853</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Educational Testing Service]]></Name>
<CityName>Princeton</CityName>
<StateCode>NJ</StateCode>
<ZipCode>085402218</ZipCode>
<StreetAddress><![CDATA[660 Rosedale Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7980</Code>
<Text>ECR-EDU Core Research</Text>
</ProgramElement>
<ProgramReference>
<Code>8817</Code>
<Text>STEM Learning &amp; Learning Environments</Text>
</ProgramReference>
<Appropriation>
<Code>0420</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>04002021DB</Code>
<Name><![CDATA[NSF Education & Human Resource]]></Name>
<FUND_SYMB_ID>040106</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~299862</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The SPIN-NGSS project addresses critical challenges faced in research and practice in the implementation of NGSS or NGSS-like standards in many states. Capitalizing on existing assessment data and machine learning techniques, the SPIN-NGSS conducted a proof-of-concept study to develop an automated diagnosis and feedback tool to support student science learning. SPIN-NGSS responds to the national need to document various student reasoning patterns in response to 3D science assessments and support students? 3D learning through real-time, automated diagnostics.&nbsp;</p> <p>The project focuses on a proof of concept study to:&nbsp;(1) develop a framework to describe characteristic features in different categories of student reasoning patterns (SRP) based on literature and existing data, (2) develop two NLP models for student written responses to two constructed response items on ecosystems and constructing scientific explanations to automate the identification of student reasoning patterns, and (3) conduct a preliminary cognitive interview study to try out the NLP models.&nbsp;</p> <p>AI applications in education are on the rise given its potential in supporting personalized learning and teaching. With the great challenges of implementing the NGSS in classroom teaching, AI techniques have the potential of supporting teachers to diagnose student reasoning patterns and inform their instruction. The product of the AI diagnosis and feedback has the potential to enhance teachers&rsquo; use of science assessments to facilitate student learning through individualized and immediate feedback. The automated diagnosis of student reasoning patterns can support teachers to interpret and use student data to make evidence-based instructional decisions.&nbsp;</p> <p>In the first year of the project life, the project completed: (1) the development of a framework for student reasoning patterns based on literature and student data, and (2) the development of the first AI model for a selected constructed response item that measured student sensemaking of an ecosystem phenomenon.</p> <p>In the second year of the project life, the project focused on completing three major milestones: (1) a second AI model for a new constructed response item from the CA Science Assessment field test; (2) embedding the first AI model (developed in Year 1) into an online tool; and (3) a cognitive interview study to explore how students use the AI-supported diagnosisis and feedback to refine their responses.&nbsp;</p> <p>We developed a framework that described several typical student reasoning patterns by analyzing student responses. Some students focused on describing observations and data only, while others only provided scientific principles without referring to data or evidence. Finally, we found some students attempted to integrate both data and scientific principles into their reasoning.</p> <p>In addition, we developed machine learning models to automate the diagnosis of student reasoning patterns based on key features related to NGSS dimensions. These models provide both a reasoning pattern label and evidence in student responses associated with the pattern. As part of this process, content experts first coded a set of student responses. Then Natural Language Processing (NLP) experts used the human annotated codes to train computers to develop automated models. The automation includes evidence annotation (i.e., identifying parts of responses related to the NGSS dimensions), SRP classification (i.e., classifying entire responses with a reasoning pattern label), and real-time feedback (i.e., generating real-time feedback associated with specific reasoning patterns).</p> <p>To validate the implementation of the AI models for the ecosystem assessment item, we conducted 45 sessions of interviews with middle and high school students. Forty out of 45 students revised their initial responses after receiving AI-generated feedback. Thirty students made one revision and 10 students made more than one revision. There were multiple response paths students took when revising their responses. Some were able to move from a unidimensional pattern to a multidimensional pattern with only one revision, while other students needed multiple revisions to achieve a multidimensional pattern.</p> <p>This Project Outcomes Report for the General Public is displayed verbatim as submitted by the Principal Investigator (PI) for this award. Any opinions, findings, and conclusions or recommendations expressed in this Report are those of the PI and do not necessarily reflect the views of the National Science Foundation; NSF has not approved or endorsed its content.</p> <p>&nbsp;</p><br> <p>            Last Modified: 09/26/2022<br>      Modified by: Lei&nbsp;Liu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The SPIN-NGSS project addresses critical challenges faced in research and practice in the implementation of NGSS or NGSS-like standards in many states. Capitalizing on existing assessment data and machine learning techniques, the SPIN-NGSS conducted a proof-of-concept study to develop an automated diagnosis and feedback tool to support student science learning. SPIN-NGSS responds to the national need to document various student reasoning patterns in response to 3D science assessments and support students? 3D learning through real-time, automated diagnostics.   The project focuses on a proof of concept study to: (1) develop a framework to describe characteristic features in different categories of student reasoning patterns (SRP) based on literature and existing data, (2) develop two NLP models for student written responses to two constructed response items on ecosystems and constructing scientific explanations to automate the identification of student reasoning patterns, and (3) conduct a preliminary cognitive interview study to try out the NLP models.   AI applications in education are on the rise given its potential in supporting personalized learning and teaching. With the great challenges of implementing the NGSS in classroom teaching, AI techniques have the potential of supporting teachers to diagnose student reasoning patterns and inform their instruction. The product of the AI diagnosis and feedback has the potential to enhance teachers’ use of science assessments to facilitate student learning through individualized and immediate feedback. The automated diagnosis of student reasoning patterns can support teachers to interpret and use student data to make evidence-based instructional decisions.   In the first year of the project life, the project completed: (1) the development of a framework for student reasoning patterns based on literature and student data, and (2) the development of the first AI model for a selected constructed response item that measured student sensemaking of an ecosystem phenomenon.  In the second year of the project life, the project focused on completing three major milestones: (1) a second AI model for a new constructed response item from the CA Science Assessment field test; (2) embedding the first AI model (developed in Year 1) into an online tool; and (3) a cognitive interview study to explore how students use the AI-supported diagnosisis and feedback to refine their responses.   We developed a framework that described several typical student reasoning patterns by analyzing student responses. Some students focused on describing observations and data only, while others only provided scientific principles without referring to data or evidence. Finally, we found some students attempted to integrate both data and scientific principles into their reasoning.  In addition, we developed machine learning models to automate the diagnosis of student reasoning patterns based on key features related to NGSS dimensions. These models provide both a reasoning pattern label and evidence in student responses associated with the pattern. As part of this process, content experts first coded a set of student responses. Then Natural Language Processing (NLP) experts used the human annotated codes to train computers to develop automated models. The automation includes evidence annotation (i.e., identifying parts of responses related to the NGSS dimensions), SRP classification (i.e., classifying entire responses with a reasoning pattern label), and real-time feedback (i.e., generating real-time feedback associated with specific reasoning patterns).  To validate the implementation of the AI models for the ecosystem assessment item, we conducted 45 sessions of interviews with middle and high school students. Forty out of 45 students revised their initial responses after receiving AI-generated feedback. Thirty students made one revision and 10 students made more than one revision. There were multiple response paths students took when revising their responses. Some were able to move from a unidimensional pattern to a multidimensional pattern with only one revision, while other students needed multiple revisions to achieve a multidimensional pattern.  This Project Outcomes Report for the General Public is displayed verbatim as submitted by the Principal Investigator (PI) for this award. Any opinions, findings, and conclusions or recommendations expressed in this Report are those of the PI and do not necessarily reflect the views of the National Science Foundation; NSF has not approved or endorsed its content.          Last Modified: 09/26/2022       Submitted by: Lei Liu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
