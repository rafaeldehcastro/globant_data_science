<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Collaborative Research: Learning by Touch: Preparing Blind Students to Participate in the Data Science Revolution]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>421811.00</AwardTotalIntnAmount>
<AwardAmount>421811</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Dan Cosley</SignBlockName>
<PO_EMAI>dcosley@nsf.gov</PO_EMAI>
<PO_PHON>7032928832</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[Over the past decade the data science revolution has transformed the way scientists, engineers, and businesses work. A key enabler is the rise of interactive data visualization tools, which allow users to filter, analyze, and understand large data sets. Beyond static charts and graphs, interactive data visualization allows users to view data in different ways and from different perspectives, to build deeper understanding of trends, and to test hypotheses. However, Blind and Visually Impaired People have not been able to fully participate in this data revolution. Common tools for data analysis and data exploration are based on interactive spatial graphics, displayed on 2D screens. These spatial diagrams, charts, and other representations are not easily conveyed through speech or text – the typical ways in which Blind and Visually impaired people consume information through computers. This lack of access to common tools has presented a barrier for Blind and Visually Impaired People to enter STEM fields. History teaches us that, with the right tools, Blind and Visually Impaired People can contribute fully to highly technical fields. For example, many blind people are engaged as programmers and network administrators across a range of industries.  It is evident that, if Blind and Visually Impaired People are provided with accessible tools that are functionally equivalent to those used by others and are able to interact with and generate their own data, they will take their place in the world of work, alongside their sighted peers. To address these issues, this project will work to: (1) increase understanding of data literacy amongst Blind and Visually Impaired People; (2) develop new tools and techniques, using touch and audio, to help prepare Blind and Visually Impaired People’s to understand and explore data. This is expected to begin to increase access to STEM concepts and materials in the BVI community, where access has previously been limited.  Spatial information is ubiquitous in STEM; finding effective ways to make it accessible to everyone is imperative. Increasing access to Interactive Data Visualization tools will help prepare the Blind and Visually Impaired to participate as data scientists, software engineers, and informed citizens.&lt;br/&gt; &lt;br/&gt;This research will work to make fundamental contributions in the fields of information visualization, assistive technology, and haptic perception, advancing our understanding of techniques for effective encoding and exploration of spatial information in alternate forms to graphical representation. It will also expand on guidelines for multi-modal haptic interaction with spatial information and create new open source software to enable these interactions. Finally, it will contribute to the field of informal STEM learning, providing understanding about data literacy and personal data exploration as a pathway to engage the Blind and Visually Impaired community in data science and STEM activities. The research will use a mixed methods approach, using co-design, qualitative and longitudinal field studies, and quantitative lab studies. Through 4 synergistic research themes, this project will expand knowledge of broadening access to interactive data visualization for Blind and Visually Impaired People by investigating: (1) current practices, gaps and needs in data literacy for Blind and Visually Impaired People; (2) how task goals affect exploration strategies for tactile perception of data for BVI people; (3) data exploration and manipulation strategies through co-design using an interactive tactile display; and (4) the efficacy of interactive tactile data exploration to expand data literacy for BVI people.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>08/24/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/20/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2016789</AwardID>
<Investigator>
<FirstName>Sean</FirstName>
<LastName>Follmer</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sean Follmer</PI_FULL_NAME>
<EmailAddress><![CDATA[sfollmer@stanford.edu]]></EmailAddress>
<NSF_ID>000703330</NSF_ID>
<StartDate>08/24/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Stanford University</Name>
<CityName>STANFORD</CityName>
<ZipCode>943052004</ZipCode>
<PhoneNumber>6507232300</PhoneNumber>
<StreetAddress>450 JANE STANFORD WAY</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>16</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA16</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>HJD6G4D6TJY5</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>THE LELAND STANFORD JUNIOR UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Stanford University]]></Name>
<CityName>Stanford</CityName>
<StateCode>CA</StateCode>
<ZipCode>943052203</ZipCode>
<StreetAddress><![CDATA[Bldg 550, Room 155]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>16</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA16</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8020</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~421811</FUND_OBLG>
</Award>
</rootTag>
