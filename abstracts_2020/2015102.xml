<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[STTR Phase I:  Multiple Eye Disease Detection Using a Smartphone]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2020</AwardEffectiveDate>
<AwardExpirationDate>06/30/2022</AwardExpirationDate>
<AwardTotalIntnAmount>225000.00</AwardTotalIntnAmount>
<AwardAmount>225000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>15030000</Code>
<Directorate>
<Abbreviation>TIP</Abbreviation>
<LongName>Dir for Tech, Innovation, &amp; Partnerships</LongName>
</Directorate>
<Division>
<Abbreviation>TI</Abbreviation>
<LongName>Translational Impacts</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Alastair Monk</SignBlockName>
<PO_EMAI>amonk@nsf.gov</PO_EMAI>
<PO_PHON>7032924392</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[The broader impact/commercial impact of this Small Business Technology Transfer (STTR) Phase I project is to proactively manage eye health. Approximately 285 million people and 39 million people suffer respectively from visual impairment and blindness. Monitoring of eye disease in early stages is critical to slowing its progression, but currently this assessment requires specialized equipment in ophthalmology practices or optometry offices.  Smartphone-based disease detection is customizable, portable, easy-to-access, and multi-functional.&lt;br/&gt;&lt;br/&gt;This Small Business Technology Transfer (STTR) Phase I project aims to design and develop an eye disease diagnostic tool using a smartphone. This project will develop and validate novel data acquisition, image processing and machine learning techniques for keratoconus, glaucoma, and cataract detection, including new algorithms for detection of motion and noise artifacts to reduce image corruption.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>08/10/2020</MinAmdLetterDate>
<MaxAmdLetterDate>12/16/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041, 47.084</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2015102</AwardID>
<Investigator>
<FirstName>Jiyeon</FirstName>
<LastName>Kim</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jiyeon Kim</PI_FULL_NAME>
<EmailAddress><![CDATA[inoon.research@gmail.com]]></EmailAddress>
<NSF_ID>000810819</NSF_ID>
<StartDate>08/10/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>INOON, LLC</Name>
<CityName>LUBBOCK</CityName>
<ZipCode>794247869</ZipCode>
<PhoneNumber>8067781865</PhoneNumber>
<StreetAddress>10402 IOLA AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>19</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX19</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>HM2BY7N3Q7D6</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>INOON, LLC</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[INOON, LLC]]></Name>
<CityName>Lubbock</CityName>
<StateCode>TX</StateCode>
<ZipCode>794015920</ZipCode>
<StreetAddress><![CDATA[2104 Main Street #7]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>19</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX19</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1505</Code>
<Text>STTR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>066E</Code>
<Text>INSTRUMENTATION &amp; DIAGNOSTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>090E</Code>
<Text>Chem/Bio and Physical Diagnostics</Text>
</ProgramReference>
<ProgramReference>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramReference>
<ProgramReference>
<Code>8033</Code>
<Text>Hardware Software Integration</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~225000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Our innovation is an entirely new topographically inspired, smartphone-based way to detect keratoconus, glaucoma, and cataract by precisely acquiring required information for each eye disease with the help of a smartphone camera, proprietary image processing techniques, machine learning techniques, and a proprietary optical device for detection.</p> <p>This solution utilizes smartphones-and potentially other small hand-held devices, such as tablets that have a camera and a central processing unit (CPU) embedded in them-to provide customers with their eye disease diagnosis based on the eye images taken by the camera as shown in&nbsp;&nbsp;Figure 1.</p> <p>We have developed all detection algorithms for three eye diseases (i.e., cataract, glaucoma, and keratoconus) with the emulated eye model and images acquired from ophthalmic equipment. In additon, we have developed pilot mobile apps&nbsp;Figure 2&nbsp;and optical devices Figure 3&nbsp;in Phase I.</p> <p>Images captured by the smartphone camera are utilized to monitor the conditions of the eye for healthy or eye disease cases. Our proposed method to diagnose diseases consists of four main steps: 1) data acquisition, 2) preprocessing, 3) feature extraction, and 4) classification. In Phase I, we used an eye model to emulate healthy and diseased eye in different environmental conditions. We also used eye images acquired from the ophthalmic equipment in developing our proposed eye disease detection methods. The flowchart for our proposed smartphone-based eye diseases detection solution is shown in&nbsp;Figure 4.&nbsp;</p> <p>Figure 5 shows flowcharts of the color enhancement preprocessing stage with the corresponding images acquired from each step for each eye diseases, cataract, glaucoma, and keratoconus.&nbsp;</p> <p><strong>Cataract: shown in Figure 5(a)</strong></p> <p>The smartphone is used to capture images of the eye focusing on the iris. The iris, which is the colorful part the eye, is the region of interest. The proposed method applies different image processing techniques to remove any noise or disruption in the image. The image processing also makes the edges and contours more visible. The white region or the cloudy region of the cataract is then isolated. The overall area which the opacity spans is calculated. A threshold value is set for the area and once the area exceeds this value, we identify the presence of cataract.</p> <p><strong>Glaucoma: shown in Figure 5(b)</strong></p> <p>For the diagnosis of glaucoma, retinal images are necessary. To obtain these images of the retina, the gadget is used. The retinal image is processed using image processing technique to increase the contrast between the region of interest and the surrounding. The cup and disc, which is part of the optical nerve head, are isolated and their dimensions are measured. Using the dimensions and patient history, the glaucoma patients are identified where both the presence and severity of glaucoma is considered.&nbsp;</p> <p><strong>Keratoconus: shown in Figure 5(c)</strong></p> <p>The keratoconus image is captured using the smartphone without any additional gadget. It uses the phone screen to illuminate or cause the reflection of the circles known as Placido disc on to the eye. These circles are used detect the structure of the eye shape as they compare the distances between each concentric circle. A healthy eye will have even or equal distance between concentric circles whilst the diseased will have uneven distribution. This is shown using graphs where even regions are represented by blue and uneven regions are represented by yellow color.</p> <p>iNoon's technology based on these algorithms will be effectively providing the accurate diagnosis using machine learning and image processing. Also, iNoon's user-friendly smartphone app and the handy optical device will help ophthalmologist, optometrist, and patients to access and use our diagnosis service easily.</p> <p>As a result, our approach to eye disease detection using a smartphone will give ophthalmologist, optometrist, and patients the opportunity to monitor eye diseases under a wide variety of conditions, e.g., outside of the eye care professional's office, at home, and other locations like military bases and jails. Since our approach does not require the equipment operation by trained technicians due to its easy-to-use and portable characteristics, it will be not only be cost-effective, but also accepted with less resistance by patients. iDetect has the potential to significantly change the way eye diseases have been traditionally diagnosed, allowing for more frequent, rapid, and personally initiated eye disease screening and detection.</p><br> <p>            Last Modified: 07/10/2022<br>      Modified by: Jiyeon&nbsp;Kim</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2022/2015102/2015102_10695153_1656623103009_iNoon_Outcome_Figure1--rgov-214x142.jpg" original="/por/images/Reports/POR/2022/2015102/2015102_10695153_1656623103009_iNoon_Outcome_Figure1--rgov-800width.jpg" title="How to use iDetect app and the optical device"><img src="/por/images/Reports/POR/2022/2015102/2015102_10695153_1656623103009_iNoon_Outcome_Figure1--rgov-66x44.jpg" alt="How to use iDetect app and the optical device"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Figure 1: How to use iDetect app and the optical device</div> <div class="imageCredit">iNoon</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Jiyeon&nbsp;Kim</div> <div class="imageTitle">How to use iDetect app and the optical device</div> </div> </li> <li> <a href="/por/images/Reports/POR/2022/2015102/2015102_10695153_1656623165212_iNoon_Outcome_Figure2--rgov-214x142.jpg" original="/por/images/Reports/POR/2022/2015102/2015102_10695153_1656623165212_iNoon_Outcome_Figure2--rgov-800width.jpg" title="iDetect iPhone app"><img src="/por/images/Reports/POR/2022/2015102/2015102_10695153_1656623165212_iNoon_Outcome_Figure2--rgov-66x44.jpg" alt="iDetect iPhone app"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Figure 2: iDetect iPhone app</div> <div class="imageCredit">iNoon</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Jiyeon&nbsp;Kim</div> <div class="imageTitle">iDetect iPhone app</div> </div> </li> <li> <a href="/por/images/Reports/POR/2022/2015102/2015102_10695153_1656625050859_iNoon_Outcome_Figure3--rgov-214x142.jpg" original="/por/images/Reports/POR/2022/2015102/2015102_10695153_1656625050859_iNoon_Outcome_Figure3--rgov-800width.jpg" title="iDetect optical device"><img src="/por/images/Reports/POR/2022/2015102/2015102_10695153_1656625050859_iNoon_Outcome_Figure3--rgov-66x44.jpg" alt="iDetect optical device"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Figure 3: iDetect optical device</div> <div class="imageCredit">iNoon</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Jiyeon&nbsp;Kim</div> <div class="imageTitle">iDetect optical device</div> </div> </li> <li> <a href="/por/images/Reports/POR/2022/2015102/2015102_10695153_1656625137640_iNoon_Outcome_Figure4--rgov-214x142.jpg" original="/por/images/Reports/POR/2022/2015102/2015102_10695153_1656625137640_iNoon_Outcome_Figure4--rgov-800width.jpg" title="The flowchart of iDetect system"><img src="/por/images/Reports/POR/2022/2015102/2015102_10695153_1656625137640_iNoon_Outcome_Figure4--rgov-66x44.jpg" alt="The flowchart of iDetect system"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Figure 4: The flowchart of iDetect system</div> <div class="imageCredit">iNoon</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Jiyeon&nbsp;Kim</div> <div class="imageTitle">The flowchart of iDetect system</div> </div> </li> <li> <a href="/por/images/Reports/POR/2022/2015102/2015102_10695153_1656625256895_iNoon_Outcome_Figure5--rgov-214x142.jpg" original="/por/images/Reports/POR/2022/2015102/2015102_10695153_1656625256895_iNoon_Outcome_Figure5--rgov-800width.jpg" title="Eye diseases detection algorithms"><img src="/por/images/Reports/POR/2022/2015102/2015102_10695153_1656625256895_iNoon_Outcome_Figure5--rgov-66x44.jpg" alt="Eye diseases detection algorithms"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Figure 5: Flowcharts of the color enhancement preprocessing stage with the corresponding images acquired from each step for each eye diseases, cataract, glaucoma, and keratoconus</div> <div class="imageCredit">iNoon</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Jiyeon&nbsp;Kim</div> <div class="imageTitle">Eye diseases detection algorithms</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Our innovation is an entirely new topographically inspired, smartphone-based way to detect keratoconus, glaucoma, and cataract by precisely acquiring required information for each eye disease with the help of a smartphone camera, proprietary image processing techniques, machine learning techniques, and a proprietary optical device for detection.  This solution utilizes smartphones-and potentially other small hand-held devices, such as tablets that have a camera and a central processing unit (CPU) embedded in them-to provide customers with their eye disease diagnosis based on the eye images taken by the camera as shown in  Figure 1.  We have developed all detection algorithms for three eye diseases (i.e., cataract, glaucoma, and keratoconus) with the emulated eye model and images acquired from ophthalmic equipment. In additon, we have developed pilot mobile apps Figure 2 and optical devices Figure 3 in Phase I.  Images captured by the smartphone camera are utilized to monitor the conditions of the eye for healthy or eye disease cases. Our proposed method to diagnose diseases consists of four main steps: 1) data acquisition, 2) preprocessing, 3) feature extraction, and 4) classification. In Phase I, we used an eye model to emulate healthy and diseased eye in different environmental conditions. We also used eye images acquired from the ophthalmic equipment in developing our proposed eye disease detection methods. The flowchart for our proposed smartphone-based eye diseases detection solution is shown in Figure 4.   Figure 5 shows flowcharts of the color enhancement preprocessing stage with the corresponding images acquired from each step for each eye diseases, cataract, glaucoma, and keratoconus.   Cataract: shown in Figure 5(a)  The smartphone is used to capture images of the eye focusing on the iris. The iris, which is the colorful part the eye, is the region of interest. The proposed method applies different image processing techniques to remove any noise or disruption in the image. The image processing also makes the edges and contours more visible. The white region or the cloudy region of the cataract is then isolated. The overall area which the opacity spans is calculated. A threshold value is set for the area and once the area exceeds this value, we identify the presence of cataract.  Glaucoma: shown in Figure 5(b)  For the diagnosis of glaucoma, retinal images are necessary. To obtain these images of the retina, the gadget is used. The retinal image is processed using image processing technique to increase the contrast between the region of interest and the surrounding. The cup and disc, which is part of the optical nerve head, are isolated and their dimensions are measured. Using the dimensions and patient history, the glaucoma patients are identified where both the presence and severity of glaucoma is considered.   Keratoconus: shown in Figure 5(c)  The keratoconus image is captured using the smartphone without any additional gadget. It uses the phone screen to illuminate or cause the reflection of the circles known as Placido disc on to the eye. These circles are used detect the structure of the eye shape as they compare the distances between each concentric circle. A healthy eye will have even or equal distance between concentric circles whilst the diseased will have uneven distribution. This is shown using graphs where even regions are represented by blue and uneven regions are represented by yellow color.  iNoon's technology based on these algorithms will be effectively providing the accurate diagnosis using machine learning and image processing. Also, iNoon's user-friendly smartphone app and the handy optical device will help ophthalmologist, optometrist, and patients to access and use our diagnosis service easily.  As a result, our approach to eye disease detection using a smartphone will give ophthalmologist, optometrist, and patients the opportunity to monitor eye diseases under a wide variety of conditions, e.g., outside of the eye care professional's office, at home, and other locations like military bases and jails. Since our approach does not require the equipment operation by trained technicians due to its easy-to-use and portable characteristics, it will be not only be cost-effective, but also accepted with less resistance by patients. iDetect has the potential to significantly change the way eye diseases have been traditionally diagnosed, allowing for more frequent, rapid, and personally initiated eye disease screening and detection.       Last Modified: 07/10/2022       Submitted by: Jiyeon Kim]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
