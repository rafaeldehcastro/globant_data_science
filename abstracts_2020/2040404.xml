<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Collaborative Research: GeoGaze: Gaze-Driven Adaptive Multimedia to Augment Geoscience Learning for Neurodiverse Learners]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2022</AwardEffectiveDate>
<AwardExpirationDate>12/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>46758.00</AwardTotalIntnAmount>
<AwardAmount>46758</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Soo-Siang Lim</SignBlockName>
<PO_EMAI>slim@nsf.gov</PO_EMAI>
<PO_PHON>7032927878</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[Much of learning occurs today in multimedia environments. This project will design and test GeoGaze, a novel technology that uses eye tracking to augment learning with multimedia in real time. GeoGaze analyzes and predicts effective strategies for students based on differences in working memory capacity and changes the presentation of learning materials to help everyone view and learn information. Investigators will first study what visual attention strategies work best for learners with different levels of working memory capacity. This information will be used to build a gaze-driven technology to help each learner use the most effective strategies by adapting the learning materials in real time and for each learner. Examples of this include predicting where learners will look on the screen, what order they will explore the content, and then highlighting the most important elements in the sequence to be viewed or blurring the less relevant content before revealing when appropriate. The results of this project will help us understand how individual differences in visual attention and working memory capacity influence multimedia learning and how to adapt learning materials to improve learning in real time. This project seeks to engage more students in learning geoscience, a field not well represented by a diversity of students and researchers.&lt;br/&gt;&lt;br/&gt;Studies of multimedia learning traditionally focus on final learning outcomes but what happens during the learning process (e.g., visual attention strategies to integrate multimedia) is often unexplored. This project addresses these shortcomings to gain a robust perspective of how students with different working memory capacities learn authentic STEM content (geoscience) in multimedia environments, and how their cognition can be enhanced using gaze-driven adaptive learning technology, GeoGaze. This approach is based on a novel integration of behavioral and psychophysiological data as well as multi-layer backpropagation neural network analysis to predict media integration strategies. GeoGaze represents a novel gaze-driven technology for adapting multimedia learning in real time based on effective media integration strategies for each learner. This research will generate new empirical evidence for using real-time gaze-driven adaptation of learning materials to augment cognition and improve learning.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>08/19/2021</MinAmdLetterDate>
<MaxAmdLetterDate>09/06/2023</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2040404</AwardID>
<Investigator>
<FirstName>Marc</FirstName>
<LastName>Pomplun</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marc Pomplun</PI_FULL_NAME>
<EmailAddress><![CDATA[marc@cs.umb.edu]]></EmailAddress>
<NSF_ID>000090280</NSF_ID>
<StartDate>08/19/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Boston</Name>
<CityName>BOSTON</CityName>
<ZipCode>021253300</ZipCode>
<PhoneNumber>6172875370</PhoneNumber>
<StreetAddress>100 MORRISSEY BLVD RM 80</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA08</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>CGCDJ24JJLZ1</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MASSACHUSETTS</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>MLBQUML9JJT6</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Massachusetts Boston]]></Name>
<CityName>Boston</CityName>
<StateCode>MA</StateCode>
<ZipCode>021253300</ZipCode>
<StreetAddress><![CDATA[100 Morrissey Blvd]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA08</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>127Y</Code>
<Text>Sci of Lrng &amp; Augmented Intel</Text>
</ProgramElement>
<ProgramReference>
<Code>059Z</Code>
<Text>Science of Learning</Text>
</ProgramReference>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002324DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2021~31172</FUND_OBLG>
<FUND_OBLG>2023~15586</FUND_OBLG>
</Award>
</rootTag>
