<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[CHS: Small: Adaptive rendering and display for emerging immersive experiences]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>497177.00</AwardTotalIntnAmount>
<AwardAmount>497177</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032924341</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[The fundamental architecture for rendering information on TVs and monitors has changed very little: the information is still sent as pixels, scanned row by row into a sequence of images called frames. At the same time, an increasingly important class of immersive applications is emerging: socially rich videoconferencing supports the nonverbal communication; in-situ learning has remote students using augmented reality to see lessons in context, such as biology in the garden; teleoperation allows doctors to deliver healthcare at distance. Unfortunately, traditional display architecture cannot deliver crucial features these applications require, including life-size, zero-delay remote windows; and multi-viewer, glasses-free experiences. This project investigates transformative, adaptive display architectures that might support these features. By designing an abstract “ideal display” using an API (Application Programming Interface), the research team will enable exploration of a diverse range of underlying display architectures for supporting emerging applications. In this process, it will convene workshops to build the multidisciplinary research relationships needed to meet these goals and begin addressing the dearth of women and minorities in computing with a special effort in the university's computer graphics class. &lt;br/&gt;&lt;br/&gt;To rekindle innovation in displays, the project will focus on five non-traditional, adaptive display techniques: frameless rendering, selective updates, local storage and processing, knowledge of the viewer, and high-level representations. Frameless rendering forms images with pixels representing different moments in time. This is particularly effective at reducing delay. Selective updates replace part of the image, rather than all of it, useful when images are too large for a full change. Local storage and processing allow older samples to be stored on the display, then combined with new samples just in time to make imagery with less delay and bandwidth. Higher level primitives like gradients and edges reduce bandwidth by succinctly describing local pixel distributions. Finally, knowledge of the viewer allows displays to render information only where and when it is needed, for example by using eye tracking. The project will apply these techniques toward three goals. First, to define an open API for the ideal perceptual display, which saturates all of the visual sense. This effort will drive future research by identifying underserved perceptual sensitivities, clarifying engineering tradeoffs in actual displays, and increasing the market for those displays. The second and third goals are to prototype two adaptive approximations of the ideal perceptual display on hybrid display-FPGA (Field Programmable Gate Arrays) systems, to test and inform our API. A frameless, foveated display will reduce detail in the periphery to reduce delay, particularly for large displays. A foveated light field display will vary color by view angle to support glasses-free stereo and multi-user viewing. The project will evaluate both prototypes with perceptual comparisons of them to more traditional displays.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>08/14/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/19/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2008590</AwardID>
<Investigator>
<FirstName>Benjamin</FirstName>
<LastName>Watson</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Benjamin A Watson</PI_FULL_NAME>
<EmailAddress><![CDATA[bwatson@ncsu.edu]]></EmailAddress>
<NSF_ID>000460838</NSF_ID>
<StartDate>08/14/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>North Carolina State University</Name>
<CityName>RALEIGH</CityName>
<ZipCode>27607</ZipCode>
<PhoneNumber>9195152444</PhoneNumber>
<StreetAddress>2601 WOLF VILLAGE WAY</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC02</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>U3NVH931QJJ3</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>NORTH CAROLINA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>N8DMK1K4C2K5</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[North Carolina State University]]></Name>
<CityName/>
<StateCode>NC</StateCode>
<ZipCode>276957214</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~497177</FUND_OBLG>
</Award>
</rootTag>
