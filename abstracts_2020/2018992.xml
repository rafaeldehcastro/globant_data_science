<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[MRI: Development of a Calibration System for Stereophotogrammetry to Enable Large-Scale Measurement and Monitoring]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2020</AwardEffectiveDate>
<AwardExpirationDate>08/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>455096.00</AwardTotalIntnAmount>
<AwardAmount>455096</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CMMI</Abbreviation>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Alex Leonessa</SignBlockName>
<PO_EMAI>aleoness@nsf.gov</PO_EMAI>
<PO_PHON>7032922633</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[This Major Research Instrumentation (MRI) project will develop a multi-sensor system that will allow measurements from moving platforms, such as remotely connected/remotely paired unmanned vehicles or drones. The novel instrument will be used for real-time calibration of specialty cameras in a novel computer-vision system. This new knowledge and technique will enhance public safety through rapid and accurate inspection of critical infrastructure and large-scale physical systems. This instrumentation will contribute to fundamental research at the University of Massachusetts-Lowell and the development of new curriculum on sensors integration, controls, and machine-vision. Collaborations with local high school teachers will introduce K-12 students to computer-vision and unmanned aerial vehicle (UAV) inspection, encouraging them to pursue STEM careers.&lt;br/&gt;&lt;br/&gt;This potentially transformative instrumentation will be used for real-time calibration of stereophotogrammetry and remotely paired digital cameras, thereby streamlining calibration procedures and enabling measurements from moving platforms. The multi-sensor system records the orientation angles and the relative distance between two paired cameras needed to triangulate the 3D position of optical targets with respect to the cameras’ retinal plane. This obviates the need for time-consuming calibration and fixed sensor positioning and has the potential to enlarge the field of view. The instrumentation will provide a new means for recording data to inform and validate ongoing advanced modeling efforts and to enable a new understanding of large-scale systems’ dynamic characteristics. Research using this instrumentation will drive a fundamental understanding of how physical parameters such as displacement, deformation, and strain characterize the behavior of large-scale systems like large infrastructure, wind turbine blades and parachutes.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>08/06/2020</MinAmdLetterDate>
<MaxAmdLetterDate>09/07/2022</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2018992</AwardID>
<Investigator>
<FirstName>Christopher</FirstName>
<LastName>Niezrecki</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Christopher Niezrecki</PI_FULL_NAME>
<EmailAddress><![CDATA[Christopher_Niezrecki@uml.edu]]></EmailAddress>
<NSF_ID>000114924</NSF_ID>
<StartDate>08/06/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Yan</FirstName>
<LastName>Luo</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yan Luo</PI_FULL_NAME>
<EmailAddress><![CDATA[Yan_Luo@uml.edu]]></EmailAddress>
<NSF_ID>000488411</NSF_ID>
<StartDate>08/06/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kshitij</FirstName>
<LastName>Jerath</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kshitij Jerath</PI_FULL_NAME>
<EmailAddress><![CDATA[Kshitij_Jerath@uml.edu]]></EmailAddress>
<NSF_ID>000695967</NSF_ID>
<StartDate>08/06/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Alessandro</FirstName>
<LastName>Sabato</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alessandro Sabato</PI_FULL_NAME>
<EmailAddress><![CDATA[Alessandro_Sabato@uml.edu]]></EmailAddress>
<NSF_ID>000819143</NSF_ID>
<StartDate>08/06/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Lowell</Name>
<CityName>LOWELL</CityName>
<ZipCode>018543624</ZipCode>
<PhoneNumber>9789344170</PhoneNumber>
<StreetAddress>600 SUFFOLK ST STE 212</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA03</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>LTNVSTJ3R6D5</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MASSACHUSETTS</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Massachusetts Lowell]]></Name>
<CityName>Lowell</CityName>
<StateCode>MA</StateCode>
<ZipCode>018543643</ZipCode>
<StreetAddress><![CDATA[600 Suffolk St]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1189</Code>
<Text>Major Research Instrumentation</Text>
</ProgramElement>
<ProgramReference>
<Code>034E</Code>
<Text>Dynamical systems</Text>
</ProgramReference>
<ProgramReference>
<Code>036E</Code>
<Text>CIVIL INFRASTRUCTURE</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~455096</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The Major Research Instrumentation (MRI) project has successfully developed an innovative sensor-based system for the real-time calibration of remotely paired digital cameras. This advancement streamlines calibration procedures and significantly enhances the capabilities of stereophotogrammetry for large-scale applications. The developed multi-sensor system incorporates three inertial measurement units and a laser sensor to precisely record orientation angles and the relative distance between synchronized cameras (i.e., cameras&rsquo; extrinsic parameters). The knowledge of the cameras&rsquo; extrinsic parameters is crucial for triangulating the positions of optical targets in relation to the cameras&rsquo; retinal plane and measuring the three-dimensional displacement of an object of interest.</p> <p>Throughout the project&rsquo;s duration, a prototype of the multi-sensor board was designed and rigorously validated through both analytical and experimental methods. Laboratory tests, spanning from small to large scales, demonstrated that the sensor-based calibration achieved with the developed multi-sensor board attains the same level of accuracy as calibration performed using the traditional image-based approach. In particular, the errors associated with the sensor-based calibration consistently fell within the noise floor of the measurement, with accuracy consistently above 95%.</p> <p>Moreover, the project has significantly impacted education and outreach efforts. Graduate and undergraduate students have been able to engage in research related to sensor integration, controls, and machine vision. Simultaneously, outreach initiatives to local schools and the local chapter of the Society of Women Engineers (SWE) have introduced students, particularly females and minority groups, to computer vision and unmanned aerial vehicle inspection.</p> <p>The multi-sensor system eliminates the requirement for the cameras to be fixed while also obviating the need for time-consuming calibration. The outcomes of this research will progress the state of the art of computer vision technologies and significantly enhance their utility for structural health monitoring of real-world systems. The multi-sensor system will function as a next-generation measurement approach for experimental modal analysis and damage diagnostics research. Through this instrumentation, researchers will gain a deeper understanding of physical parameters such as displacement, deformation, and strain, thereby enabling new insights into the behavior of large-scale systems, including transportation infrastructure, wind turbine blades, and parachutes.</p> <p>&nbsp;</p><br> <p>            Last Modified: 09/07/2023<br>      Modified by: Alessandro&nbsp;Sabato</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The Major Research Instrumentation (MRI) project has successfully developed an innovative sensor-based system for the real-time calibration of remotely paired digital cameras. This advancement streamlines calibration procedures and significantly enhances the capabilities of stereophotogrammetry for large-scale applications. The developed multi-sensor system incorporates three inertial measurement units and a laser sensor to precisely record orientation angles and the relative distance between synchronized cameras (i.e., cameras’ extrinsic parameters). The knowledge of the cameras’ extrinsic parameters is crucial for triangulating the positions of optical targets in relation to the cameras’ retinal plane and measuring the three-dimensional displacement of an object of interest.  Throughout the project’s duration, a prototype of the multi-sensor board was designed and rigorously validated through both analytical and experimental methods. Laboratory tests, spanning from small to large scales, demonstrated that the sensor-based calibration achieved with the developed multi-sensor board attains the same level of accuracy as calibration performed using the traditional image-based approach. In particular, the errors associated with the sensor-based calibration consistently fell within the noise floor of the measurement, with accuracy consistently above 95%.  Moreover, the project has significantly impacted education and outreach efforts. Graduate and undergraduate students have been able to engage in research related to sensor integration, controls, and machine vision. Simultaneously, outreach initiatives to local schools and the local chapter of the Society of Women Engineers (SWE) have introduced students, particularly females and minority groups, to computer vision and unmanned aerial vehicle inspection.  The multi-sensor system eliminates the requirement for the cameras to be fixed while also obviating the need for time-consuming calibration. The outcomes of this research will progress the state of the art of computer vision technologies and significantly enhance their utility for structural health monitoring of real-world systems. The multi-sensor system will function as a next-generation measurement approach for experimental modal analysis and damage diagnostics research. Through this instrumentation, researchers will gain a deeper understanding of physical parameters such as displacement, deformation, and strain, thereby enabling new insights into the behavior of large-scale systems, including transportation infrastructure, wind turbine blades, and parachutes.          Last Modified: 09/07/2023       Submitted by: Alessandro Sabato]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
