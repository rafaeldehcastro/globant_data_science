<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Collaborative Research: PPoSS: Planning: Fixpoint: an operating system and architecture for data-centric computing]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2022</AwardExpirationDate>
<AwardTotalIntnAmount>125000.00</AwardTotalIntnAmount>
<AwardAmount>125000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[Computer operating systems run programs that read input data and produce output data. However, today's operating systems generally don't keep track of enough information to make sure that the process of generating a given piece of data can be reproduced, especially when the program that produced it may have considered input that came over the network, from a mutable file on disk, or from a non-deterministic phenomenon such as thread scheduling. This project will design a new kind of operating system, called Fixpoint, that explicitly represents and names computations on data: each invocation of a program, in terms of its minimal data-dependencies, in a reproducible content-addressed manner. If successful, the project will have a significant impact on how computer systems are used every day. By making all computation reproducible by default and trivially shareable, Fixpoint can improve scientific reproducibility and as a consequence increase the public's confidence in scientific results. &lt;br/&gt;&lt;br/&gt;The hypothesis of this project is that by changing the way software is represented, substantial benefits can be unlocked in the areas of scalability, security, efficiency, performance, and reproducibility. Fixpoint's operating-system-visible dataflow will give it an ability to take advantage of massive transient parallelism, which means that parallel tasks that effectively require batch-processing today -- submitting jobs to servers and waiting hours -- will become near real-time. This will change the kinds of operations that people expect to do interactively at a computer. Errors discovered in data, even after the fact, can be backed out of computations that depend on them, similar to recalculating a spreadsheet today.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>08/25/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/14/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2028733</AwardID>
<Investigator>
<FirstName>Keith</FirstName>
<LastName>Winstein</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Keith Winstein</PI_FULL_NAME>
<EmailAddress><![CDATA[keithw@cs.stanford.edu]]></EmailAddress>
<NSF_ID>000682184</NSF_ID>
<StartDate>08/25/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>David</FirstName>
<LastName>Mazieres</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David Mazieres</PI_FULL_NAME>
<EmailAddress><![CDATA[dm-list-sup-nsf14@scs.stanford.edu]]></EmailAddress>
<NSF_ID>000100121</NSF_ID>
<StartDate>08/25/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Stanford University</Name>
<CityName>STANFORD</CityName>
<ZipCode>943052004</ZipCode>
<PhoneNumber>6507232300</PhoneNumber>
<StreetAddress>450 JANE STANFORD WAY</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>16</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA16</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>HJD6G4D6TJY5</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>THE LELAND STANFORD JUNIOR UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Stanford University]]></Name>
<CityName>Stanford</CityName>
<StateCode>CA</StateCode>
<ZipCode>943059025</ZipCode>
<StreetAddress><![CDATA[450 Jane Stanford Way]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>16</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA16</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>042Y</Code>
<Text>PPoSS-PP of Scalable Systems</Text>
</ProgramElement>
<ProgramReference>
<Code>026Z</Code>
<Text>NSCI: National Strategic Computing Initi</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~125000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In this planning-grant project, we explored putting <em>computation</em> at the center of what networked computers and cloud services do for their users. We envision a shared representation of a computation: a deterministic procedure, run in an environment of well-specified dependencies. This suggests an end-to-end argument for serverless computing, shifting the service model from &ldquo;renting CPUs by the second&rdquo; to &ldquo;providing the unambiguously correct result of a computation.&rdquo; Accountability to these higher-level abstractions could permit agility and innovation on other axes.</p> <p>While classical &ldquo;infrastructure-as-a-service&rdquo; cloud computing involves renting a virtual server and paying by the second, current &ldquo;function-as-a-service&rdquo; offerings provide almost the same service model: renting an x86 or ARM worker and paying by the tenth of a second until a task completes. Providers have little visibility into client dataflow, which translates into inefficient placement and poor utilization. When most jobs spend most of their time waiting for bytes to arrive from across the network, even a clever provider has little ability (or incentive) to improve the situation.<br /><br />In this project, we explored the idea that the root cause of these challenges is an underconstrained notion of networked computation. We developed a research agenda centered around what we call &ldquo;computation-centric networking&rdquo;: the idea that a networked service&rsquo;s job is primarily to provide answers to computations and would benefit from (1) fine-grained visibility into application dataflow, (2) an objective, common notion of correctness, and (3) a separation between I/O and compute, with delineated nondeterminism.</p> <p>In our view, successfully realizing this vision would:<br />&bull; let networked systems track the computational relationships between artifacts, so that sharing a reproducible pipeline is as simple as a git push / git pull / &ldquo;git reproduce",<br />&bull; guarantee reproducibility of server-side algorithms that process data on a user&rsquo;s behalf,<br />&bull; allow rerunning a computational pipeline with modified code or data, to discover the consequences of, and clean up after, an intrusion, and<br />&bull; benefit &ldquo;serverless&rdquo; providers and customers. Providers would have the flexibility to schedule and place jobs in a way that minimizes dataflow and maximizes utilization, as long as they reach the correct answer. If the customer chooses to double-check a result and finds the provider was mistaken, they&rsquo;d be able to collect from the provider&rsquo;s insurance. That, in turn, might free the customer to bid jobs out to competing providers. Our theory is akin to an end-to-end argument [ 21]: accountability to one high-level abstraction (correctness) can create agility on other axes.<br /><br />We have begun to design and implement a framework for computation-centric networking, which we call Fixpoint. We are defining a low-level, lightweight<br />representation for deterministic computations-on-named-data,<br />known as &ldquo;Fix.&rdquo; To represent the relationships between code<br />and data, Fix defines an addressing scheme that allows data to<br />be identified either in terms of its contents (similar to systems<br />like Git, BitTorrent, and IPFS) or by referring to a deter-<br />ministic computation that computes it. The Fixpoint system<br />includes a compiler that transforms Fix into raw machine<br />codelets, and runtime engines that evaluate such codelets on<br />various platforms: multicore computers, clusters, and server-<br />less computing platforms.</p> <p>Our preliminary benchmarks have found that these abstrac-<br />tions are lightweight enough to let Fixpoint provide isolation<br />and reproducibility with overhead close to an ordinary virtual<br />function call. On a recent x86-64 CPU and Linux kernel, Fix-<br />point&rsquo;s invocation overhead is about 37&times; faster than vforking a<br />process, and about 531&times; faster than record-replay techniques<br />such as rr. The raw invocation overhead is roughly 50 ns,<br />about 5&times; as slow as a virtual function call in C++.</p><br> <p>            Last Modified: 07/14/2023<br>      Modified by: Keith&nbsp;Winstein</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In this planning-grant project, we explored putting computation at the center of what networked computers and cloud services do for their users. We envision a shared representation of a computation: a deterministic procedure, run in an environment of well-specified dependencies. This suggests an end-to-end argument for serverless computing, shifting the service model from "renting CPUs by the second" to "providing the unambiguously correct result of a computation." Accountability to these higher-level abstractions could permit agility and innovation on other axes.  While classical "infrastructure-as-a-service" cloud computing involves renting a virtual server and paying by the second, current "function-as-a-service" offerings provide almost the same service model: renting an x86 or ARM worker and paying by the tenth of a second until a task completes. Providers have little visibility into client dataflow, which translates into inefficient placement and poor utilization. When most jobs spend most of their time waiting for bytes to arrive from across the network, even a clever provider has little ability (or incentive) to improve the situation.  In this project, we explored the idea that the root cause of these challenges is an underconstrained notion of networked computation. We developed a research agenda centered around what we call "computation-centric networking": the idea that a networked service’s job is primarily to provide answers to computations and would benefit from (1) fine-grained visibility into application dataflow, (2) an objective, common notion of correctness, and (3) a separation between I/O and compute, with delineated nondeterminism.  In our view, successfully realizing this vision would: &bull; let networked systems track the computational relationships between artifacts, so that sharing a reproducible pipeline is as simple as a git push / git pull / "git reproduce", &bull; guarantee reproducibility of server-side algorithms that process data on a user’s behalf, &bull; allow rerunning a computational pipeline with modified code or data, to discover the consequences of, and clean up after, an intrusion, and &bull; benefit "serverless" providers and customers. Providers would have the flexibility to schedule and place jobs in a way that minimizes dataflow and maximizes utilization, as long as they reach the correct answer. If the customer chooses to double-check a result and finds the provider was mistaken, they’d be able to collect from the provider’s insurance. That, in turn, might free the customer to bid jobs out to competing providers. Our theory is akin to an end-to-end argument [ 21]: accountability to one high-level abstraction (correctness) can create agility on other axes.  We have begun to design and implement a framework for computation-centric networking, which we call Fixpoint. We are defining a low-level, lightweight representation for deterministic computations-on-named-data, known as "Fix." To represent the relationships between code and data, Fix defines an addressing scheme that allows data to be identified either in terms of its contents (similar to systems like Git, BitTorrent, and IPFS) or by referring to a deter- ministic computation that computes it. The Fixpoint system includes a compiler that transforms Fix into raw machine codelets, and runtime engines that evaluate such codelets on various platforms: multicore computers, clusters, and server- less computing platforms.  Our preliminary benchmarks have found that these abstrac- tions are lightweight enough to let Fixpoint provide isolation and reproducibility with overhead close to an ordinary virtual function call. On a recent x86-64 CPU and Linux kernel, Fix- point’s invocation overhead is about 37&times; faster than vforking a process, and about 531&times; faster than record-replay techniques such as rr. The raw invocation overhead is roughly 50 ns, about 5&times; as slow as a virtual function call in C++.       Last Modified: 07/14/2023       Submitted by: Keith Winstein]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
