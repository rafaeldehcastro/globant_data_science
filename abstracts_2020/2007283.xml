<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[CHS: Small: Inverse Methods for Computer Graphics Material Appearance Design]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>498941.00</AwardTotalIntnAmount>
<AwardAmount>498941</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032924341</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[Material appearance is a critical feature of visual design systems in the service of a wide range of industrial needs, from creating augmented/virtual reality (AR/VR) training environments to designing physical products to specifying the appearance of characters and objects in film and games.  Visual accuracy is needed for reliable training, and intuitive tools are needed to minimize the time required to bring new systems online.  But while design of the geometry of physical products using computational tools is well-established, an unresolved problem is that the appearance of objects shown in computer design systems cannot reliably be matched in physical production.  This project will develop tools for appearance design that create accurate simulations and are easy to use.  Project outcomes will have broad impact, by enabling systems to accelerate job training, by making design for manufacture efficient, and by expanding access to production tools.&lt;br/&gt;&lt;br/&gt;This project will study appearance space to create a new type of material appearance design system.  But studying the full range of material appearance is a grand challenge, so rather than attempting to develop a general theory, appearance space will be studied in three contexts: the space of particular material classes; the space of procedural models encoded as node graphs; and the space of physically realizable bi-scale materials.  In the context of material classes, image examples of classes of materials (e.g., grass, shiny metals, silk fabric) will be gathered and classified by unsupervised learning techniques to discover the structure of each class and the overlap in appearance classifications.  In the context of node graphs used for appearance design, existing graphs for material classes will be collected to find types and structures to drive the design of an automatic system for node graph generation.  And in the context of bi-scale material appearance, classes of meso-scale geometries and micro-scale variations will be studied to characterize the range of appearance they can produce.  The three studies will be brought together in a system that takes examples of distant and close appearance, along with additional user-supplied class qualifiers, and creates new node types and node graph structures to produces a tunable model for the user to edit as needed.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>08/21/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/15/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2007283</AwardID>
<Investigator>
<FirstName>Holly</FirstName>
<LastName>Rushmeier</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Holly Rushmeier</PI_FULL_NAME>
<EmailAddress><![CDATA[rushmeier@cs.yale.edu]]></EmailAddress>
<NSF_ID>000179012</NSF_ID>
<StartDate>08/21/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Julie</FirstName>
<LastName>Dorsey</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Julie Dorsey</PI_FULL_NAME>
<EmailAddress><![CDATA[dorsey@cs.yale.edu]]></EmailAddress>
<NSF_ID>000117724</NSF_ID>
<StartDate>08/21/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Yale University</Name>
<CityName>NEW HAVEN</CityName>
<ZipCode>065118917</ZipCode>
<PhoneNumber>2037854689</PhoneNumber>
<StreetAddress>105 WALL ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<StateCode>CT</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CT03</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>FL6GV84CKN57</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>YALE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>FL6GV84CKN57</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Yale University]]></Name>
<CityName>New Haven</CityName>
<StateCode>CT</StateCode>
<ZipCode>065208285</ZipCode>
<StreetAddress><![CDATA[AK Watson Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CT03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~498941</FUND_OBLG>
</Award>
</rootTag>
