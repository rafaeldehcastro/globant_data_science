<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[RAPID: Wireless Positioning for Mitigating COVID19 Surface Transmissions]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2020</AwardEffectiveDate>
<AwardExpirationDate>08/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>100000.00</AwardTotalIntnAmount>
<AwardAmount>100000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Murat Torlak</SignBlockName>
<PO_EMAI>mtorlak@nsf.gov</PO_EMAI>
<PO_PHON>7032927748</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[The project develops a new micro-location technology for tracking hand movements and alerting users when they are about to touch their face. The technology uses wireless signals and mobile sensors to track the distance between a user's hand and their face, and introduces new algorithms and frameworks that enable achieving high accuracy and robustness at ultra-low cost. Such technology can significantly reduce COVID19 surface transmissions, which account for 10% of all COVID transmissions according to the CDC and scientific studies. The success of this project can have an immediate impact on essential workers (in factories and grocery stores) and aide in a quicker economic recovery while minimizing the impact of a potential second wave as the economy re-opens. The potential long-term impact of this research extends beyond COVID19 and future pandemics to providing transformative capabilities in networked micro-location for smart environments, indoor navigation, and asset tracking.&lt;br/&gt;&lt;br/&gt;The goal of this proposal is to design and build a low-cost (sub-$5), ubiquitous wireless positioning technology that allows tracking and predicting hand-to-face distance. Developing such a technology requires addressing challenges in terms of accuracy (centimeter-scale), interference (from co-existing technologies and multi-path reflections), and compatibility (with existing ubiquitous technologies). To overcome these challenges, the project introduces a principled multi-modal sensor fusion framework for mobile devices. This framework operates by fusing various sensing modalities that already exist in mobile devices -- including BLE, accelerometers, magnetometers, and ultrasound. Taken individually, ultra-low-cost sensors for each of these modalities lack the necessary accuracy and robustness for centimeter-scale positioning; however, because they experience uncorrelated sources of noise and interference, combining these modalities in a principled probabilistic framework enables achieving high accuracy and robustness while maintaining low cost. If successful, the resulting system would be the most accurate, low-cost, and ubiquitious micro-location technology to date.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>06/01/2020</MinAmdLetterDate>
<MaxAmdLetterDate>06/01/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2032704</AwardID>
<Investigator>
<FirstName>Joseph</FirstName>
<LastName>Paradiso</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joseph Paradiso</PI_FULL_NAME>
<EmailAddress><![CDATA[joep@media.mit.edu]]></EmailAddress>
<NSF_ID>000096693</NSF_ID>
<StartDate>06/01/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kevin</FirstName>
<LastName>Esvelt</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kevin M Esvelt</PI_FULL_NAME>
<EmailAddress><![CDATA[esvelt@mit.edu]]></EmailAddress>
<NSF_ID>000726874</NSF_ID>
<StartDate>06/01/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Fadel</FirstName>
<LastName>Adib</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Fadel Adib</PI_FULL_NAME>
<EmailAddress><![CDATA[fadel@mit.edu]]></EmailAddress>
<NSF_ID>000746411</NSF_ID>
<StartDate>06/01/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>CAMBRIDGE</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>E2NYLCDML6V1</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>E2NYLCDML6V1</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021394307</ZipCode>
<StreetAddress><![CDATA[77 Massachusetts Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>158Y</Code>
<Text>COVID-19 Research</Text>
</ProgramElement>
<ProgramReference>
<Code>096Z</Code>
<Text>COVID-19 Research</Text>
</ProgramReference>
<ProgramReference>
<Code>7914</Code>
<Text>RAPID</Text>
</ProgramReference>
<Appropriation>
<Code>1N20</Code>
<Name>R&amp;RA CARES Act DEFC N</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>010N2021DB</Code>
<Name><![CDATA[R&RA CARES Act DEFC N]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~100000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of the Saving Face proposal was to design and build a low-cost (sub-$5), ubiquitous wireless positioning technology that allows us to track hand-to-face distance and alert users when they are about to touch their faces. Such technology can help reduce COVID19 surface transmissions. While two decades of research from the networking and mobile communities has led to significant strides in location tracking, existing approaches lack the accuracy, robustness, and/or cost necessary to scale to billions of users worldwide at ultra-low cost.</p> <p>Developing a wireless technology that enables accurate, low-cost sensing of hand-to-face contact required addressing challenges along multiple fronts. First, the technology must be highly accurate &ndash; of the order of centimeters &ndash; in order to track hand-face distances, and it must achieve this level of accuracy at low latency in order to alert users before they touch their face. Second, the technology must be robust to various sources of interference, including from co-existing transmissions as well as from reflections of wireless signals off other objects in the environment (i.e., the multipath effect). And finally, the technology must be ultra-low-cost and backward compatible with existing wireless technologies such as BLE, which have been widely adopted worldwide. To overcome these challenges, we developed a principled multi-modal fusion framework for mobile devices. Our framework builds on advances in Bayesian inference in order to fuse various sensing modalities that already exist in mobile devices &ndash; including BLE, accelerometers, magenetometers, and ultrasound. Taken individually, ultra-low-cost sensors for each of these modalities lack the necessary accuracy and robustness for centimeter-scale positioning; however, because they experience uncorrelated sources of noise and interference, combining these modalities in a principled probabilistic framework enables achieving high accuracy and robustness while maintaining low cost. The resulting system is highly accurate, low-cost, and scalable to billions of mobile devices. While the technology has direct implications for hand-to-face tracking in COVID19 and other pandemics, it also opens up new applications in mobile sensing and networked location-support services such as smart environments, indoor navigation, and asset tracking.</p> <p>Saving Face has been prototyped and tested in user studies emulating real-life activities such as sitting on a chair, walking around the room, or stacking cans. It has shown an&nbsp;average sensitivity of 93.7% (correctly detected face touches / total face touches) and an average precision (number of nudges due to a face-touch / total number of nudges) of 91.5%. At the same time, most users have stated that they would be willing to use the App in real life. Given its high detection accuracy, relatively seamless user experience (can be used in the background even when the user listens to music), and high scalability (it leverages hardware the user already owns and the App can easily be downloaded from the online stores), we believe Saving Face can become an effective, widely adopted solution for mitigating the surface transmission of COVID-19 and other infectious diseases.</p> <p>The concrete outcomes of this project are: 1) We introduced a novel and rapidly scalable approach to behavioral change to lower the hand-to-face transmission of COVID-19 and other pathogens. 2) We designed an acoustics-based system to track hand-to-face movements, based on signal processing (Frequency Modulated Carrier Wave - FMCW - and Doppler Shift) and machine learning (LogisticRegression) algorithms. 3) We implemented the system in a set of user-friendly iPhone and Android apps, available for anyone who owns a smartphone and a set of commercial earphones. 4) We evaluated the system&rsquo;s performance in multiple experimental environments - to observe an average sensitivity of 93.7% and precision of 91.5%, as well as an overall positive user experience and adoption intention.</p> <p>We published our results in the premier venue for ubiquitous computing (ACM IMWUT 2021). Our team has released the source code for the project and presented the early prototype to multiple corporate sponsors. The released project was featured as a finalist in Fast Company&rsquo;s Best Student Design Projects of 2020.&nbsp;</p> <p>Finally, while our tests have mainly focused on hand-to-face applications, the solutions we have developed can be applicable to multiple other gesture recognition issues, where a set of speakers and a microphone are available. This could span to areas such as behavior-reversal therapy (e.g., against compulsive hair pulling), security (e.g., device owner recognition), safety (e.g., falling asleep behind the wheel), or health monitoring (e.g., detecting movement patterns preliminary to a heart attack).</p><br> <p>            Last Modified: 12/16/2021<br>      Modified by: Fadel&nbsp;Adib</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of the Saving Face proposal was to design and build a low-cost (sub-$5), ubiquitous wireless positioning technology that allows us to track hand-to-face distance and alert users when they are about to touch their faces. Such technology can help reduce COVID19 surface transmissions. While two decades of research from the networking and mobile communities has led to significant strides in location tracking, existing approaches lack the accuracy, robustness, and/or cost necessary to scale to billions of users worldwide at ultra-low cost.  Developing a wireless technology that enables accurate, low-cost sensing of hand-to-face contact required addressing challenges along multiple fronts. First, the technology must be highly accurate &ndash; of the order of centimeters &ndash; in order to track hand-face distances, and it must achieve this level of accuracy at low latency in order to alert users before they touch their face. Second, the technology must be robust to various sources of interference, including from co-existing transmissions as well as from reflections of wireless signals off other objects in the environment (i.e., the multipath effect). And finally, the technology must be ultra-low-cost and backward compatible with existing wireless technologies such as BLE, which have been widely adopted worldwide. To overcome these challenges, we developed a principled multi-modal fusion framework for mobile devices. Our framework builds on advances in Bayesian inference in order to fuse various sensing modalities that already exist in mobile devices &ndash; including BLE, accelerometers, magenetometers, and ultrasound. Taken individually, ultra-low-cost sensors for each of these modalities lack the necessary accuracy and robustness for centimeter-scale positioning; however, because they experience uncorrelated sources of noise and interference, combining these modalities in a principled probabilistic framework enables achieving high accuracy and robustness while maintaining low cost. The resulting system is highly accurate, low-cost, and scalable to billions of mobile devices. While the technology has direct implications for hand-to-face tracking in COVID19 and other pandemics, it also opens up new applications in mobile sensing and networked location-support services such as smart environments, indoor navigation, and asset tracking.  Saving Face has been prototyped and tested in user studies emulating real-life activities such as sitting on a chair, walking around the room, or stacking cans. It has shown an average sensitivity of 93.7% (correctly detected face touches / total face touches) and an average precision (number of nudges due to a face-touch / total number of nudges) of 91.5%. At the same time, most users have stated that they would be willing to use the App in real life. Given its high detection accuracy, relatively seamless user experience (can be used in the background even when the user listens to music), and high scalability (it leverages hardware the user already owns and the App can easily be downloaded from the online stores), we believe Saving Face can become an effective, widely adopted solution for mitigating the surface transmission of COVID-19 and other infectious diseases.  The concrete outcomes of this project are: 1) We introduced a novel and rapidly scalable approach to behavioral change to lower the hand-to-face transmission of COVID-19 and other pathogens. 2) We designed an acoustics-based system to track hand-to-face movements, based on signal processing (Frequency Modulated Carrier Wave - FMCW - and Doppler Shift) and machine learning (LogisticRegression) algorithms. 3) We implemented the system in a set of user-friendly iPhone and Android apps, available for anyone who owns a smartphone and a set of commercial earphones. 4) We evaluated the system’s performance in multiple experimental environments - to observe an average sensitivity of 93.7% and precision of 91.5%, as well as an overall positive user experience and adoption intention.  We published our results in the premier venue for ubiquitous computing (ACM IMWUT 2021). Our team has released the source code for the project and presented the early prototype to multiple corporate sponsors. The released project was featured as a finalist in Fast Company’s Best Student Design Projects of 2020.   Finally, while our tests have mainly focused on hand-to-face applications, the solutions we have developed can be applicable to multiple other gesture recognition issues, where a set of speakers and a microphone are available. This could span to areas such as behavior-reversal therapy (e.g., against compulsive hair pulling), security (e.g., device owner recognition), safety (e.g., falling asleep behind the wheel), or health monitoring (e.g., detecting movement patterns preliminary to a heart attack).       Last Modified: 12/16/2021       Submitted by: Fadel Adib]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
