<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[PPoSS: Planning: Eliminating the Bottlenecks to ML Usability and Scalability]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2021</AwardExpirationDate>
<AwardTotalIntnAmount>250000.00</AwardTotalIntnAmount>
<AwardAmount>250000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wei Ding</SignBlockName>
<PO_EMAI>weiding@nsf.gov</PO_EMAI>
<PO_PHON>7032928017</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[Machine learning (ML) has the potential to dramatically benefit many aspects of daily life. Applications range from consumer and business technologies (virtual assistants) to transportation (driver assistance and self-driving cars) to health care (hospital observation and physician assistance) and science. Unfortunately, using ML techniques to solve specific, real-world problems remains difficult. Building ML applications often requires a multi-step, iterative process that involves repeated cycles of prototyping, evaluating results, and fixing failures. This project aims to dramatically reduce the difficulty of this iterative process, making it easier for a single person to quickly build ML applications to solve real-world problems.&lt;br/&gt;&lt;br/&gt;The technical goal of this project is to dramatically scale the productivity of the entire end-to-end ML model-development workflow so that a single subject-matter expert, armed with a large dataset and access to datacenter-scale accelerated compute capability, can build accurate models for new tasks in hours to days instead of weeks or months. To this end, the project will create automated tools that directly empower subject-matter experts to perform model-development tasks, in rapid iterative loops. These intelligent tools must execute with low latency and scale to huge datasets and potentially large, complex models. To meet these requirements, this project will combine new methods for automatically generated supervision from weak sources and for curating critical data for training and validation, new ML programming abstractions, and reconfigurable ML hardware accelerators to support a heterogeneous set of future use cases and algorithmic techniques.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>08/27/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/14/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2028602</AwardID>
<Investigator>
<FirstName>Christopher</FirstName>
<LastName>Re</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Christopher Re</PI_FULL_NAME>
<EmailAddress><![CDATA[chrismre@cs.stanford.edu]]></EmailAddress>
<NSF_ID>000555316</NSF_ID>
<StartDate>08/27/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kayvon</FirstName>
<LastName>Fatahalian</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kayvon Fatahalian</PI_FULL_NAME>
<EmailAddress><![CDATA[kayvonf@cs.stanford.edu]]></EmailAddress>
<NSF_ID>000624440</NSF_ID>
<StartDate>08/27/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Oyekunle</FirstName>
<LastName>Olukotun</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Oyekunle A Olukotun</PI_FULL_NAME>
<EmailAddress><![CDATA[kunle@stanford.edu]]></EmailAddress>
<NSF_ID>000320046</NSF_ID>
<StartDate>08/27/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Stanford University</Name>
<CityName>STANFORD</CityName>
<ZipCode>943052004</ZipCode>
<PhoneNumber>6507232300</PhoneNumber>
<StreetAddress>450 JANE STANFORD WAY</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>16</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA16</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>HJD6G4D6TJY5</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>THE LELAND STANFORD JUNIOR UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Stanford University]]></Name>
<CityName>Stanford</CityName>
<StateCode>CA</StateCode>
<ZipCode>943055008</ZipCode>
<StreetAddress><![CDATA[353 Jane Stanford Way]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>16</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA16</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7231</Code>
<Text>CYBERINFRASTRUCTURE</Text>
</ProgramElement>
<ProgramElement>
<Code>7484</Code>
<Text>IIS Special Projects</Text>
</ProgramElement>
<ProgramReference>
<Code>026Z</Code>
<Text>NSCI: National Strategic Computing Initi</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~250000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Machine learning (ML) has the potential to dramatically benefit many aspects of daily life. Applications range from consumer and business technologies (virtual assistants) to transportation (driver assistance and self-driving cars) to health care (hospital observation and physician assistance) and science. Unfortunately, using ML techniques to solve specific, real-world problems remains difficult. Building ML applications often requires a multi-step, iterative process that involves repeated cycles of prototyping, evaluating results, and fixing failures. This project dramatically reduces the difficulty of this iterative process, making it easier for a single person to quickly build ML applications to solve real-world problems.<br /><br />This project seeks to dramatically scale the productivity of the entire end-to-end ML model development work so that a single subject matter expert (SME), armed with a large dataset and access to datacenter-scale accelerated compute capability, can build accurate models for new tasks in hours to days instead of weeks or months&shy;&ndash;&ndash; and without the aid of a skilled ML engineer. Our approach is to create automated tools that directly empower subject matter experts to perform model development tasks, in rapid iterative loops. These intelligent tools execute with low latency and scale to huge datasets and potentially large, complex models. They are informed by the constraints of modern parallel systems and require the implementation of high-performance systems infrastructure to scale which we address with datacenter-scale distributed computing and via the design of flexible ML hardware accelerators. Altogether we have developed a detailed plan for a domain-specific full-stack approach that combines new methods for automatically generating supervision from weak sources and curating critical data for training and validation, new ML programming abstractions, and reconfigurable ML hardware accelerators to support a heterogeneous set of future use cases and algorithmic techniques.</p> <p>&nbsp;</p> <p>The broader impacts of this research project are that ML has the potential to impact application domains in industry, healthcare, and science, but machine learning expertise and their accompanying benefits have been concentrated in a few small places. Our work democratizes the benefits of machine learning by changing the way that users interact with machine learning models.</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 07/30/2022<br>      Modified by: Oyekunle&nbsp;A&nbsp;Olukotun</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Machine learning (ML) has the potential to dramatically benefit many aspects of daily life. Applications range from consumer and business technologies (virtual assistants) to transportation (driver assistance and self-driving cars) to health care (hospital observation and physician assistance) and science. Unfortunately, using ML techniques to solve specific, real-world problems remains difficult. Building ML applications often requires a multi-step, iterative process that involves repeated cycles of prototyping, evaluating results, and fixing failures. This project dramatically reduces the difficulty of this iterative process, making it easier for a single person to quickly build ML applications to solve real-world problems.  This project seeks to dramatically scale the productivity of the entire end-to-end ML model development work so that a single subject matter expert (SME), armed with a large dataset and access to datacenter-scale accelerated compute capability, can build accurate models for new tasks in hours to days instead of weeks or months&shy;&ndash;&ndash; and without the aid of a skilled ML engineer. Our approach is to create automated tools that directly empower subject matter experts to perform model development tasks, in rapid iterative loops. These intelligent tools execute with low latency and scale to huge datasets and potentially large, complex models. They are informed by the constraints of modern parallel systems and require the implementation of high-performance systems infrastructure to scale which we address with datacenter-scale distributed computing and via the design of flexible ML hardware accelerators. Altogether we have developed a detailed plan for a domain-specific full-stack approach that combines new methods for automatically generating supervision from weak sources and curating critical data for training and validation, new ML programming abstractions, and reconfigurable ML hardware accelerators to support a heterogeneous set of future use cases and algorithmic techniques.     The broader impacts of this research project are that ML has the potential to impact application domains in industry, healthcare, and science, but machine learning expertise and their accompanying benefits have been concentrated in a few small places. Our work democratizes the benefits of machine learning by changing the way that users interact with machine learning models.             Last Modified: 07/30/2022       Submitted by: Oyekunle A Olukotun]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
