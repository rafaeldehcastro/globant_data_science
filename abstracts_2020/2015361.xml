<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Parameter Estimation Theory and Algorithms under Latent Variable Models and Model Misspecification]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2020</AwardEffectiveDate>
<AwardExpirationDate>06/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>200000.00</AwardTotalIntnAmount>
<AwardAmount>200000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Yong Zeng</SignBlockName>
<PO_EMAI>yzeng@nsf.gov</PO_EMAI>
<PO_PHON>7032927299</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[Latent variables models have become one of the most powerful tools in modern statistics and data science. They are indispensable in the core data-driven technologies responsible for advancing a vast array of domains of engineering and sciences. While these tools represent remarkable achievements in which statisticians have played fundamental and decisive roles, there are urgent and formidable challenges lying ahead. As these tools are increasingly applied to ever bigger data sets and systems, there are deep concerns that they may no longer be understood, nor is their construction and deployment reliable or robust.  When treated as merely black-box modeling devices for fitting densities and curves, latent variable models are difficult to interpret and can be hard to detect or fix when something goes wrong, either when the model is severely misspecified or the learning algorithms simply break down. This project  aims to address the theoretical and computational issues that arise in modern latent variable models, and the learning efficiency and interpretability of such statistical models when they are misspecified.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;The goals of this project are to develop new methods, algorithms and theory for latent variable models. There are three major aims: (1) a statistical theory for parameter estimation that arises in latent variable models;  (2) scalable parameter learning algorithms which account for the geometry of the latent structures, as well as the geometry of the data representation arising from specific application domains; and (3) impacts of model misspecification on parameter estimation motivating the development of new methods. These three broadly described aims are partly motivated by the PI's collaborative efforts with scientists and engineers in several data-driven domains, namely intelligent transportation, astrophysics and topic modeling for information extraction. In all these domains, latent variable models are favored as an effective approximation device, but practitioners are interested in not only predictive performance but also interpretability. In terms of methods and tools, this research draws from and contributes to several related areas including statistical learning, nonparametric Bayesian statistics and non-convex optimization. In terms of broader impacts, the development of scalable geometric and variational inference algorithms for latent variable models will help to expand the statistical and computational tool box that are indispensable in the analysis of complex and big data. The investigation into the geometry of singularity structures and the role of optimal transport based theory in the analysis of models and the development of algorithms will help to accelerate the cross-fertilization between statistics and mathematics, computer science and operations research. In terms of education and training, the interdisciplinary nature of this project provides an exciting opportunity to attract and train a generation of researchers and students in variational methods and optimization, statistics and mathematics, as well as machine learning and intelligent infrastructure.  The materials developed in this project will be integrated into an undergraduate honor course and a summer school for statistical science and big data analytics developed at the University of Michigan.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>06/17/2020</MinAmdLetterDate>
<MaxAmdLetterDate>06/17/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2015361</AwardID>
<Investigator>
<FirstName>Xuanlong</FirstName>
<LastName>Nguyen</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xuanlong Nguyen</PI_FULL_NAME>
<EmailAddress><![CDATA[xuanlong@umich.edu]]></EmailAddress>
<NSF_ID>000559330</NSF_ID>
<StartDate>06/17/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Regents of the University of Michigan - Ann Arbor</Name>
<CityName>ANN ARBOR</CityName>
<ZipCode>481091079</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress>1109 GEDDES AVE, SUITE 3300</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI06</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>GNJ7BBP73WE9</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MICHIGAN</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Michigan Ann Arbor]]></Name>
<CityName>Ann Arbor</CityName>
<StateCode>MI</StateCode>
<ZipCode>481091107</ZipCode>
<StreetAddress><![CDATA[439 West Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<ProgramReference>
<Code>079Z</Code>
<Text>Machine Learning Theory</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~200000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>The major goals are to develop new methods and theory for latent variable models. They include (i) a statistical theory for parameter estimation that arises in latent variable models, as interpretability of a model's parameter estimates is of enormous interest; (ii) scalable parameter learning algorithms which account for the geometry of the latent structures, as well as the geometry of the data representation arising from specific application domains; and (iii) impacts of model misspecification on parameter estimation motivating the development of new methods.</span></p> <p><span><br /></span></p> <div>This award provided funding for the PI's research and educational program on the theory, algorithms and applications of latent variable models, including the case where the models are misspecified. Latent variable models are among the most powerful and widely used tools in modern statistics and data science. Understanding the roles these models play in making inference and prediction about quantities of interest are important, not only for improving the efficiency of the inference, in terms of data sample size and computational cost, but also improved interpretation of the finding and the understanding of the connection between the (observed) data and the (unobserved) quantities of interest.</div> <p>&nbsp;</p> <p>During the course of this project, the PI along with his graduate students and coleagues have made fundamental contributions to the theoretical foundations and algorithms of latent models. In terms of theory, they shed light on complex parameter estimation behaviors and developed rigorous theory for parameter estimation rates of convergence for a number of canonical latent variables, including the mixture of product distributions and the de Finett's mixing measures, and the infinite location-scale mixtures, using tools from optimal transport, harmonic analysis, and complex analysis. They have also initiated the application of optimal transport to complex data types, including functional data analysis, and toward improving existing learning techniques via geometric interpolation. Thus this research has contributed to improved understanding and development of novel methodologies. This project also contributes a number of novel and state of the art computational techniques for posterior inference of large scale hierarchical Bayesian models, helping to extending the scope of applicablity of advanced statistical learning techniques to a number of data domains, including intelligence transportation, traffic analysis and space weather forecast. The research supported by this award has led to over a dozen publications in journals and peer-reviewed conference proceedings in statistics, computer science and related fields.</p> <p><span>&nbsp;</span></p> <p><span>&nbsp;</span>In terms of education and outreach, this award provided the critical support for modernizing the statistics and data science curricula at the University of Michigan. It enabled the integration of the teaching of statistical and computational tools with modern applications in both graduate and undergraduate levels via course-based innovative projects and doctoral research. It has provided partial support for five PhD students in statistics and mathematics. The PI's involvement in organizing and co-leading a summer school and workshops helped to introduce hundreds of students and new researchers to the broad field of statistics and data science.</p> <div><span><br /></span></div> <p>&nbsp;</p><br> <p>            Last Modified: 10/05/2023<br>      Modified by: Xuanlong&nbsp;Nguyen</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The major goals are to develop new methods and theory for latent variable models. They include (i) a statistical theory for parameter estimation that arises in latent variable models, as interpretability of a model's parameter estimates is of enormous interest; (ii) scalable parameter learning algorithms which account for the geometry of the latent structures, as well as the geometry of the data representation arising from specific application domains; and (iii) impacts of model misspecification on parameter estimation motivating the development of new methods.    This award provided funding for the PI's research and educational program on the theory, algorithms and applications of latent variable models, including the case where the models are misspecified. Latent variable models are among the most powerful and widely used tools in modern statistics and data science. Understanding the roles these models play in making inference and prediction about quantities of interest are important, not only for improving the efficiency of the inference, in terms of data sample size and computational cost, but also improved interpretation of the finding and the understanding of the connection between the (observed) data and the (unobserved) quantities of interest.     During the course of this project, the PI along with his graduate students and coleagues have made fundamental contributions to the theoretical foundations and algorithms of latent models. In terms of theory, they shed light on complex parameter estimation behaviors and developed rigorous theory for parameter estimation rates of convergence for a number of canonical latent variables, including the mixture of product distributions and the de Finett's mixing measures, and the infinite location-scale mixtures, using tools from optimal transport, harmonic analysis, and complex analysis. They have also initiated the application of optimal transport to complex data types, including functional data analysis, and toward improving existing learning techniques via geometric interpolation. Thus this research has contributed to improved understanding and development of novel methodologies. This project also contributes a number of novel and state of the art computational techniques for posterior inference of large scale hierarchical Bayesian models, helping to extending the scope of applicablity of advanced statistical learning techniques to a number of data domains, including intelligence transportation, traffic analysis and space weather forecast. The research supported by this award has led to over a dozen publications in journals and peer-reviewed conference proceedings in statistics, computer science and related fields.      In terms of education and outreach, this award provided the critical support for modernizing the statistics and data science curricula at the University of Michigan. It enabled the integration of the teaching of statistical and computational tools with modern applications in both graduate and undergraduate levels via course-based innovative projects and doctoral research. It has provided partial support for five PhD students in statistics and mathematics. The PI's involvement in organizing and co-leading a summer school and workshops helped to introduce hundreds of students and new researchers to the broad field of statistics and data science.            Last Modified: 10/05/2023       Submitted by: Xuanlong Nguyen]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
