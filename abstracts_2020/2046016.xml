<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[CAREER: Long Document Summarization with Question-Summary Hierarchy and User Preference Control]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2021</AwardEffectiveDate>
<AwardExpirationDate>06/30/2026</AwardExpirationDate>
<AwardTotalIntnAmount>547582.00</AwardTotalIntnAmount>
<AwardAmount>320906</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928729</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[In an era when long documents are produced at an overwhelming speed, a reader may not have time even to skim over a document to decide which topics deserve a detailed look. The goal of this CAREER project is to build text summarization systems that can understand and aggregate information from long documents, so as to allow users to explore their content with summaries that are generated in styles they prefer. The summarization tools will make long documents more accessible and comprehensible, easing the knowledge learning experience of the general public. Researchers and practitioners can also use the tools to summarize long documents relevant to their work, and educators can incorporate them in their classes to bolster students' reading and writing skills. The project also broadens the investigatorâ€™s efforts of engaging young students in immersive research opportunities, allowing them to participate in the design and implementation of advanced summarization systems. &lt;br/&gt;&lt;br/&gt;This project develops a new summarization framework for long documents in which article-level abstractive summaries provide an overview, and a question-summary hierarchy presents different levels of details. The technical contributions of this project are three-fold. First, the quadratic time complexity of state-of-the-art summarization (e.g., Transformer) is reduced by using adaptively predicted sparse attentions and augmented with a knowledge encoder. Second, an open-ended question generation model fills automatically learned question templates to produce concrete questions that are coherent within the question-summary hierarchy. Third, summaries are tailored to user-specified styles via iterative adjustments during generation, reflecting important advice in plain-language guidelines. This project experiments with new datasets collected from government reports, since their length, topic diversity, and formulaic verbiage embody many common challenges for long document summarization. New evaluation methods are also designed, with cloze questions to target common erroneous generations, and with model confidence metrics to pinpoint errors without using references.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>03/10/2021</MinAmdLetterDate>
<MaxAmdLetterDate>07/17/2023</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2046016</AwardID>
<Investigator>
<FirstName>Lu</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lu Wang</PI_FULL_NAME>
<EmailAddress><![CDATA[wangluxy@umich.edu]]></EmailAddress>
<NSF_ID>000701671</NSF_ID>
<StartDate>03/10/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Regents of the University of Michigan - Ann Arbor</Name>
<CityName>ANN ARBOR</CityName>
<ZipCode>481091079</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress>1109 GEDDES AVE, SUITE 3300</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI06</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>GNJ7BBP73WE9</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MICHIGAN</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Michigan]]></Name>
<CityName>Ann Arbor</CityName>
<StateCode>MI</StateCode>
<ZipCode>481092121</ZipCode>
<StreetAddress><![CDATA[2260 Hayward St]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Fund>
<Code>01002223DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002324DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2021~99001</FUND_OBLG>
<FUND_OBLG>2022~97974</FUND_OBLG>
<FUND_OBLG>2023~123931</FUND_OBLG>
</Award>
</rootTag>
