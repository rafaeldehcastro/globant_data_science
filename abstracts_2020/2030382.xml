<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Collaborative Research: RAPID: Understanding and Facilitating Remote Triage and Rehabilitation During Pandemics via Visual Based Patient Physiologic Sensing]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2020</AwardEffectiveDate>
<AwardExpirationDate>05/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>8425.00</AwardTotalIntnAmount>
<AwardAmount>8425</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Donald Wunsch</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration><![CDATA[This RAPID project plans to investigate visual-based physiological sensing technologies to facilitate remote triage and rehabilitation during pandemics, by using low-cost consumer-grade cameras to track such physiological conditions as respiration rate, heart rate, and blood oxygen saturation levels from videos.  The physiological data can be visualized and archived, and shared by users with medical practitioners to understand and support remote triage and rehabilitation.&lt;br/&gt;&lt;br/&gt;The proposed research can enhance the interaction between medical providers and patients, and help address a projected surge in telehealth needs due to COVID-19.  The PI team plans to conduct the first-of-a-kind data collection, by incorporating the novel contact-free video sensing into a biomedical cohort study that is being rolled out by a public-health collaboration team. This cross-disciplinary opportunity of multimodal data collection will offer insights on the relationship of multiple biosensing modalities, and the data collected would facilitate the research on early detection of COVID-19 and related diseases. The visual-based physiological sensing will also help enhance the remote interaction between rehabilitation therapists and patients during pandemics.&lt;br/&gt;&lt;br/&gt;The intellectual merit of this effort lies in advancing promising engineering techniques of video-based contact-free physiological monitoring to support the rising needs of remote triage and rehabilitation during pandemics. The research findings and techniques developed address an important missing component in telehealth, which simultaneously achieves social-distancing, avoids hospital overcrowding, and prioritizes personal protective equipment in response to pandemics. By collaborating with another cohort study, an unprecedented multitude of data collected by the joint effort will provide key insights toward understanding and managing COVID-19 diseases and remote triage for future outbreaks. The timeliness of this opportunity cannot be met by any regular NSF programs other than the RAPID.&lt;br/&gt;&lt;br/&gt;The projectâ€™s broader impact lies in two aspects. The multidisciplinary effort will provide important new knowledge and insights toward understanding and developing technology capabilities for remote triage and rehabilitation, which will contribute to the early detection, spread control, and effective management and prevention of future epidemics. The techniques developed through the project to support tele-rehabilitation will have a strong potential to improve the adverse conditions and quality of life of the affected citizens.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>05/19/2020</MinAmdLetterDate>
<MaxAmdLetterDate>05/19/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2030382</AwardID>
<Investigator>
<FirstName>Simon</FirstName>
<LastName>Ho</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Simon Ho</PI_FULL_NAME>
<EmailAddress><![CDATA[simon.ho@som.umaryland.edu]]></EmailAddress>
<NSF_ID>000825709</NSF_ID>
<StartDate>05/19/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland at Baltimore</Name>
<CityName>BALTIMORE</CityName>
<ZipCode>212011531</ZipCode>
<PhoneNumber>4107063559</PhoneNumber>
<StreetAddress>220 ARCH ST OFC LEVEL2</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD07</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>Z9CRZKD42ZT1</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MARYLAND, BALTIMORE</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maryland, Baltimore]]></Name>
<CityName/>
<StateCode>MD</StateCode>
<ZipCode>212011082</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>158Y</Code>
<Text>COVID-19 Research</Text>
</ProgramElement>
<ProgramReference>
<Code>096Z</Code>
<Text>COVID-19 Research</Text>
</ProgramReference>
<ProgramReference>
<Code>1653</Code>
<Text>Adaptive &amp; intelligent systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7914</Code>
<Text>RAPID</Text>
</ProgramReference>
<Appropriation>
<Code>1N20</Code>
<Name>R&amp;RA CARES Act DEFC N</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>010N2021DB</Code>
<Name><![CDATA[R&RA CARES Act DEFC N]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~8425</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The main goal of this project was to investigate visual-based physiological sensing technologies to facilitate remote triage and rehabilitation. Physiological data such as respiratory rate, heart rate, and more can be obtained from video captured using low-cost consumer-grade cameras found in smartphone and tablet devices. These physiological data can be visualized and archived, and then shared by users with medical providers to better understand and support remote triage and rehabilitation.</p> <p>Under the support of the NSF, we carried out research activities aimed at understanding the use of visual-based sensing technologies for measuring blood oxygen saturation, breathing pattern and heart rate variability. We have developed two contact-free methods for measuring blood oxygen saturation using videos of the hand captured by smartphone cameras. The first approach was a signal processing/analytics approach that improves on the traditional method of blood oxygen estimation. We found that to improve the measurement accuracy of blood oxygen saturation, it is important to (1) exploit more color information than the traditional approaches and (2) pre-clean the videos with accurately estimated heart rate information. This was achieved by using a narrow adaptive bandpass filter centered at an accurately estimated heart rate frequency via an adaptive frequency-tracking algorithm. The second approach was a data-driven approach employing neural networks. We found that a synergy between neural network design principles and optophysiological knowledge can lead to significant gains. These findings demonstrate that principled approaches, as compared to purely data-driven approaches, are effective tools for solving challenging physiological research questions.</p> <p>To obtain measurements of breathing pattern and heart rate variability (HRV) from heartbeat signals from video, we investigated the use of denoising techniques from signal processing and neural network-based machine learning to generate clean photoplethysmography (PPG) signals. For example, we explored an end-to-end remote PPG (rPPG) extraction model that extracts facial features from video and captures the temporal relationships with the PPG waveform. We found that a loss function capturing the peak locations of the PPG waveform can significantly improve the quality of the output PPG signal. We demonstrated that for physiological processes that are waveform-shape sensitive such as breathing pattern and HRV, it is crucial to explicitly preserve the time information of the waveforms when denoising.</p> <p>We have also made substantial progress toward privacy protection while using visual-based physiological sensing technologies. To address the privacy concerns of using facial videos, we developed an anonymization transform that removes sensitive visual information on facial features that might identify individuals. The success of the anonymization transform demonstrates that it is possible for facial videos to only contain physiological information with the help of image processing/computer vision techniques. Such technical possibility can lower or eliminate concerns in sharing video data with the R&amp;D community. This will make it easier for researchers to gather larger and more diversified datasets, which can, in turn, foster the advancement of the discipline.</p> <p>We created a tablet application prototype to support data collection and algorithm evaluation. The application's social-distancing mode supports data collection from healthy participants, which allows continued scientific inquiries amid epi-/pandemics. To facilitate data collection, the team also incorporated relevant aspects of respiratory care and pulmonary rehabilitation.</p> <p>Further technical details and updates can be found in the reports of collaborative partners, University of Maryland, College Park and North Carolina State University under NSF award numbers 2030502 and 2030430, respectively.</p> <p>Overall, in terms of intellectual merit, this project has explored the emerging research area of visual-based physiological sensing by drawing insights from multiple disciplines including signal processing, machine learning, privacy protection, rehabilitation and medicine. The contact-free sensing techniques could potentially impact the health of the public by supporting the rising needs of remote triage and rehabilitation during epi-/pandemics. The anonymization transforms for identity protection of recorded videos can enhance the public's trust in scientific and medical research and facilitate benchmark building and safe data sharing in the research community to promote further progress in this area.</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/29/2021<br>      Modified by: Simon&nbsp;Ho</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The main goal of this project was to investigate visual-based physiological sensing technologies to facilitate remote triage and rehabilitation. Physiological data such as respiratory rate, heart rate, and more can be obtained from video captured using low-cost consumer-grade cameras found in smartphone and tablet devices. These physiological data can be visualized and archived, and then shared by users with medical providers to better understand and support remote triage and rehabilitation.  Under the support of the NSF, we carried out research activities aimed at understanding the use of visual-based sensing technologies for measuring blood oxygen saturation, breathing pattern and heart rate variability. We have developed two contact-free methods for measuring blood oxygen saturation using videos of the hand captured by smartphone cameras. The first approach was a signal processing/analytics approach that improves on the traditional method of blood oxygen estimation. We found that to improve the measurement accuracy of blood oxygen saturation, it is important to (1) exploit more color information than the traditional approaches and (2) pre-clean the videos with accurately estimated heart rate information. This was achieved by using a narrow adaptive bandpass filter centered at an accurately estimated heart rate frequency via an adaptive frequency-tracking algorithm. The second approach was a data-driven approach employing neural networks. We found that a synergy between neural network design principles and optophysiological knowledge can lead to significant gains. These findings demonstrate that principled approaches, as compared to purely data-driven approaches, are effective tools for solving challenging physiological research questions.  To obtain measurements of breathing pattern and heart rate variability (HRV) from heartbeat signals from video, we investigated the use of denoising techniques from signal processing and neural network-based machine learning to generate clean photoplethysmography (PPG) signals. For example, we explored an end-to-end remote PPG (rPPG) extraction model that extracts facial features from video and captures the temporal relationships with the PPG waveform. We found that a loss function capturing the peak locations of the PPG waveform can significantly improve the quality of the output PPG signal. We demonstrated that for physiological processes that are waveform-shape sensitive such as breathing pattern and HRV, it is crucial to explicitly preserve the time information of the waveforms when denoising.  We have also made substantial progress toward privacy protection while using visual-based physiological sensing technologies. To address the privacy concerns of using facial videos, we developed an anonymization transform that removes sensitive visual information on facial features that might identify individuals. The success of the anonymization transform demonstrates that it is possible for facial videos to only contain physiological information with the help of image processing/computer vision techniques. Such technical possibility can lower or eliminate concerns in sharing video data with the R&amp;D community. This will make it easier for researchers to gather larger and more diversified datasets, which can, in turn, foster the advancement of the discipline.  We created a tablet application prototype to support data collection and algorithm evaluation. The application's social-distancing mode supports data collection from healthy participants, which allows continued scientific inquiries amid epi-/pandemics. To facilitate data collection, the team also incorporated relevant aspects of respiratory care and pulmonary rehabilitation.  Further technical details and updates can be found in the reports of collaborative partners, University of Maryland, College Park and North Carolina State University under NSF award numbers 2030502 and 2030430, respectively.  Overall, in terms of intellectual merit, this project has explored the emerging research area of visual-based physiological sensing by drawing insights from multiple disciplines including signal processing, machine learning, privacy protection, rehabilitation and medicine. The contact-free sensing techniques could potentially impact the health of the public by supporting the rising needs of remote triage and rehabilitation during epi-/pandemics. The anonymization transforms for identity protection of recorded videos can enhance the public's trust in scientific and medical research and facilitate benchmark building and safe data sharing in the research community to promote further progress in this area.          Last Modified: 08/29/2021       Submitted by: Simon Ho]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
