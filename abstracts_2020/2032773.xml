<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Mechanisms supporting feature-based attention]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/01/2020</AwardEffectiveDate>
<AwardExpirationDate>02/28/2023</AwardExpirationDate>
<AwardTotalIntnAmount>550396.00</AwardTotalIntnAmount>
<AwardAmount>550396</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jonathan Fritz</SignBlockName>
<PO_EMAI>jfritz@nsf.gov</PO_EMAI>
<PO_PHON>7032927923</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[Whether attending to the road while driving or trying to find your keys on a cluttered desk, our ability to select relevant information from other sensory inputs is critical for everyday survival. Many studies have shown that the ability to attend to items is highly limited; yet, it is unclear where these limits stem from and what the underlying neural mechanisms are that determine these limits. In this proposal we aim to test what constrains our ability to select information and to examine the flexibility of the human attention system across different selection demands and sensory environments. We use the human visual system as a model system to test how attention interacts with perceptual representations to guide behavior, and to examine how attention modulates neural activity to enhance perception and memory. Understanding how attention modulates these neural representations in visual cortex will help to uncover how variations in these neural patterns give rise to common perceptual and cognitive disorders like ADHD and schizophrenia.   &lt;br/&gt;&lt;br/&gt;The current research project aims to broadly understand how attention operates in different sensory environments and task contexts. We hypothesize that the capacity limits of feature-based attention are constrained by a combination of the organization of feature representations in the visual system (i.e., perceptual confusability) and by center-surround selection mechanisms. Furthermore, we hypothesize that the selection mechanisms are flexible and adjust to current task demands in terms of magnitude (enhancement and suppression) and shape (e.g., shifts in tuning curves; size of the inhibitory surround). Our approach includes psychophysics, computational modeling, and electrophysiological recordings (frequency-tagged potentials in EEG) that can tease apart perceptual factors from attentional effects, and allow to directly measure feature representations in visual cortex. Together, the proposed experiments will provide important insights into how perceptual organization and attention mechanisms interact to influence limits of attention, and will examine the flexibility of the human attention system across different task contexts. The development of novel experimental designs and neural measures to track perceptual representations in visual cortex and how they are modulated by attention will be important to test perceptual and cognitive models and how they influence visual processing more broadly.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>09/10/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/14/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2032773</AwardID>
<Investigator>
<FirstName>Viola</FirstName>
<LastName>Stoermer</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Viola S Stoermer</PI_FULL_NAME>
<EmailAddress><![CDATA[viola.s.stoermer@dartmouth.edu]]></EmailAddress>
<NSF_ID>000728746</NSF_ID>
<StartDate>09/10/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Dartmouth College</Name>
<CityName>HANOVER</CityName>
<ZipCode>037552170</ZipCode>
<PhoneNumber>6036463007</PhoneNumber>
<StreetAddress>7 LEBANON ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New Hampshire</StateName>
<StateCode>NH</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NH02</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>EB8ASJBCFER9</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF DARTMOUTH COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>EB8ASJBCFER9</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Dartmouth College]]></Name>
<CityName>Hanover</CityName>
<StateCode>NH</StateCode>
<ZipCode>037551421</ZipCode>
<StreetAddress><![CDATA[11 Rope Ferry Road #6210]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Hampshire</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NH02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1699</Code>
<Text>Cognitive Neuroscience</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>1699</Code>
<Text>COGNEURO</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01001920DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2019~550395</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Selective attention refers to the cognitive function that allows us to focus our mind&rsquo;s resources on relevant information while filtering out irrelevant and distracting information. It is a core ability underlying the limits of many cognitive functions, and thus has been a prominent research field in psychology. Studies have shown that selective attention is limited, meaning that not all sensory information can be prioritized at once, and also that the effectiveness of selection varies with task demands, stimuli, and between individuals. The majority of research exploring these limits of attentional selection has focused on the selection based on space: when allocating processing resources to a specific location in the visual field, processing of sensory information falling within this attended region is enhanced. However, people can also use visual features, such as the color, motion direction, or shape, to select visual information in a visual scene. For example, when trying to find my keys on a cluttered desk, I can use their shape or color to help me find them. The mechanisms supporting feature-based selection as well as their limits are not well understood. Thus, the current project set out to uncover the selection principles and limits of feature-based attention using behavior, human electrophysiology (EEG), and computational models.</p> <p>Across multiple studies, we assessed how people attend to visual features and what limits their ability to do so. We used psychophysical tasks to precisely measure the organization of feature representations in the visual system (i.e., perceptual confusability), and then assessed how selection operates over this precisely mapped-out feature space. With this approach, we found a series of significant results: For example, participants can &ndash; surprisingly efficiently &ndash; tune their attention broadly across different feature ranges with only small costs in performance, suggesting that feature-based attention can &ldquo;zoom-in&rdquo; or &ldquo;zoom-out&rdquo; in feature space, similar to what has been shown for spatial attention. Furthermore, in another set of studies we found that selecting a feature among perceptually similar distractors can result in distortions in the underlying perceptual space, such that the selected target feature is shifted away from the distractor, presumably supporting effective stimulus selection (i.e., effectively increasing the signal-to-noise ratio between target and distractor). Furthermore, we found that selecting a single feature spreads to other features that are part of the same feature bundle (or object), which subsequently spreads across locations &ndash; indicating that feature-based enhancement is ubiquitous in visual perception. Finally, in a series of studies we showed that instead of selecting relevant features, people can also ignore specific feature values (e.g., the color red), but that filtering out irrelevant information is less effective than selecting relevant information, at least when people are explicitly instructed to do so. However, when people incidentally learn to ignore specific feature values based on the statistical properties of the environment, they can do so relatively well &ndash; suggesting that learned attentional ignoring maybe be a particular powerful way to deal with visual distraction.</p> <p>Overall, we found that there are many parallels between feature- and spatial attention in terms of their core underlying selection principles, and that differences between the effects of attention on perceptual processing can largely be explained by differences in the underlying representational structures. These results open new questions about the relationship between spatial and feature-based attention, and how different underlying representational structures play a role in constraining attentional selection and cognition more broadly.</p> <p>The project involved training undergraduate and graduate students as well as a postdoctoral fellow on electrophysiology techniques and computational skills, programming experiments, stimulus preparation, as well as data analysis, manuscript preparation, and presentation skills, including several members of underrepresented groups. It also included the dissemination of research to the scientific community and to the public at large through outreach.</p> <p>&nbsp;</p><br> <p>            Last Modified: 06/23/2023<br>      Modified by: Viola&nbsp;S&nbsp;Stoermer</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Selective attention refers to the cognitive function that allows us to focus our mind’s resources on relevant information while filtering out irrelevant and distracting information. It is a core ability underlying the limits of many cognitive functions, and thus has been a prominent research field in psychology. Studies have shown that selective attention is limited, meaning that not all sensory information can be prioritized at once, and also that the effectiveness of selection varies with task demands, stimuli, and between individuals. The majority of research exploring these limits of attentional selection has focused on the selection based on space: when allocating processing resources to a specific location in the visual field, processing of sensory information falling within this attended region is enhanced. However, people can also use visual features, such as the color, motion direction, or shape, to select visual information in a visual scene. For example, when trying to find my keys on a cluttered desk, I can use their shape or color to help me find them. The mechanisms supporting feature-based selection as well as their limits are not well understood. Thus, the current project set out to uncover the selection principles and limits of feature-based attention using behavior, human electrophysiology (EEG), and computational models.  Across multiple studies, we assessed how people attend to visual features and what limits their ability to do so. We used psychophysical tasks to precisely measure the organization of feature representations in the visual system (i.e., perceptual confusability), and then assessed how selection operates over this precisely mapped-out feature space. With this approach, we found a series of significant results: For example, participants can &ndash; surprisingly efficiently &ndash; tune their attention broadly across different feature ranges with only small costs in performance, suggesting that feature-based attention can "zoom-in" or "zoom-out" in feature space, similar to what has been shown for spatial attention. Furthermore, in another set of studies we found that selecting a feature among perceptually similar distractors can result in distortions in the underlying perceptual space, such that the selected target feature is shifted away from the distractor, presumably supporting effective stimulus selection (i.e., effectively increasing the signal-to-noise ratio between target and distractor). Furthermore, we found that selecting a single feature spreads to other features that are part of the same feature bundle (or object), which subsequently spreads across locations &ndash; indicating that feature-based enhancement is ubiquitous in visual perception. Finally, in a series of studies we showed that instead of selecting relevant features, people can also ignore specific feature values (e.g., the color red), but that filtering out irrelevant information is less effective than selecting relevant information, at least when people are explicitly instructed to do so. However, when people incidentally learn to ignore specific feature values based on the statistical properties of the environment, they can do so relatively well &ndash; suggesting that learned attentional ignoring maybe be a particular powerful way to deal with visual distraction.  Overall, we found that there are many parallels between feature- and spatial attention in terms of their core underlying selection principles, and that differences between the effects of attention on perceptual processing can largely be explained by differences in the underlying representational structures. These results open new questions about the relationship between spatial and feature-based attention, and how different underlying representational structures play a role in constraining attentional selection and cognition more broadly.  The project involved training undergraduate and graduate students as well as a postdoctoral fellow on electrophysiology techniques and computational skills, programming experiments, stimulus preparation, as well as data analysis, manuscript preparation, and presentation skills, including several members of underrepresented groups. It also included the dissemination of research to the scientific community and to the public at large through outreach.          Last Modified: 06/23/2023       Submitted by: Viola S Stoermer]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
