<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[CIF: Small: An Information Theoretic Framework for Minimizing Supervision in Image/Video Analysis]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>James Fowler</SignBlockName>
<PO_EMAI>jafowler@nsf.gov</PO_EMAI>
<PO_PHON>7032928910</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[The recent successes in image and video analysis have been largely in the domain of supervised learning. Supervised learning methods  assume the availability of extensive amounts of manually annotated/labeled training data, which limits the applicability of existing methods to complex and unseen environments. This has motivated growing interest in developing semi-supervised, and even unsupervised, methods for image and video analysis, i.e., methods that have limited or even no manually annotated data. These methods focus on how to learn visual analysis models with limited labeled data; however, the problem of what to label is far less addressed. If one can identify the optimal subset to label, it is likely that the learning process will be more efficient than randomly choosing representatives that are labeled by a human. This project will focus on mathematically rigorous approaches on how to choose these samples to label.&lt;br/&gt;&lt;br/&gt;The project will investigate information theoretic approaches, coupled with an understanding of the inherent structure in visual data, that would help identify samples that require annotation. A well-known idea in information theory is typical sets. The concept of a typical set is based on the intuitive notion that some portions of a dataset carry more information than others. The project will investigate the applicability of this notion of typicality from information theory to select a minimal set of most informative samples, which will be manually labeled, such that visual analysis models (e.g., classifiers) designed on this subset can maximize performance (of the task of interest) on the entire dataset. The inherent structure in visual data will be combined within this information theoretic framework to obtain the optimal set of representatives to label. The approach will be analyzed in the context of various learning paradigms, including active learning, transfer learning, and weakly supervised learning. The project will involve theoretical analysis of the representative selection process, algorithm design, and experimental evaluation on applications in image segmentation, activity recognition, and target re-identification.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>06/22/2020</MinAmdLetterDate>
<MaxAmdLetterDate>06/22/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2008020</AwardID>
<Investigator>
<FirstName>Amit</FirstName>
<LastName>Roy-Chowdhury</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Amit K Roy-Chowdhury</PI_FULL_NAME>
<EmailAddress><![CDATA[amitrc@ece.ucr.edu]]></EmailAddress>
<NSF_ID>000309390</NSF_ID>
<StartDate>06/22/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ertem</FirstName>
<LastName>Tuncel</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ertem Tuncel</PI_FULL_NAME>
<EmailAddress><![CDATA[ertem.tuncel@ucr.edu]]></EmailAddress>
<NSF_ID>000490628</NSF_ID>
<StartDate>06/22/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Riverside</Name>
<CityName>RIVERSIDE</CityName>
<ZipCode>925210001</ZipCode>
<PhoneNumber>9518275535</PhoneNumber>
<StreetAddress>200 UNIVERSTY OFC BUILDING</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>39</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA39</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>MR5QC5FCAVH5</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF CALIFORNIA AT RIVERSIDE</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Riverside]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>925010001</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>39</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA39</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>2878</Code>
<Text>Special Projects - CCF</Text>
</ProgramElement>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~500000</FUND_OBLG>
</Award>
</rootTag>
