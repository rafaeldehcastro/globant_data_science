<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[RAPID: Higher Accuracy and Availability of COVID-19 Testing and Monitoring via Post-CT Image Boosting and Analysis]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/15/2020</AwardEffectiveDate>
<AwardExpirationDate>05/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>150000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[The COVID-19 pandemic has caused an unprecedented health crisis in the United States. Given the lack of an effective vaccine or drug in the short term, testing techniques with high accuracy and availability are needed to mitigate the COVID-19 outbreak through expansive deployment. However, the current genetic-based test for COVID-19 involves many different materials (e.g., swabs, tubes, and chemical solutions), of which certain ones are in short supply at different times in different places across the United States. Furthermore, the test is a multi-step process that is error-prone, resulting in low accuracy. To address these shortcomings, this project seeks to deliver an alternative COVID-19 test that can be widely available and deliver results in minutes with high accuracy. By realizing, deploying, and continually improving a high-performance software tool to facilitate early and accurate testing and monitoring of COVID-19 via post-image boosting and analysis of computed tomography (CT) scans, which use computer-processed combinations of many X-ray measurements to produce cross-section images of the chest (in particular, the lungs) this research will facilitate accurate COVID-19 diagnosis in real time. &lt;br/&gt;&lt;br/&gt;The project leverages and extends recent advances in artificial intelligence and high-performance computing to create a high-performance software tool to significantly enhance the quality of chest CT images. These enhanced CT images, in turn, facilitate more accurate analysis and identification of the hallmark features of COVID-19, including consolidation, bilateral and peripheral disease, linear opacities, “crazy-paving” patterns, and the “reverse halo” sign. Specifically, we realize a novel deep-learning neural network that enhances the resolution and reduces the artifacts of chest CT images. It does so by modeling the image-formation processes in chest CT to deliver a super-resolution and deblur-based iterative framework for CT images. The neural network only learns the relevant blur kernels, appropriate weighting factors, and penalty functions of the regularization terms in the optimal solution for the CT super-resolution task. All told, this enabling approach will mitigate the negative effects of COVID-19 on public health, society, and the economy by delivering a highly accurate and highly available test for the rapid diagnosis and monitoring of COVID-19.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>06/02/2020</MinAmdLetterDate>
<MaxAmdLetterDate>06/02/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2031215</AwardID>
<Investigator>
<FirstName>Wuchun</FirstName>
<LastName>Feng</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Wuchun Feng</PI_FULL_NAME>
<EmailAddress><![CDATA[feng@cs.vt.edu]]></EmailAddress>
<NSF_ID>000066142</NSF_ID>
<StartDate>06/02/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Guohua</FirstName>
<LastName>Cao</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Guohua Cao</PI_FULL_NAME>
<EmailAddress><![CDATA[ghcao@vt.edu]]></EmailAddress>
<NSF_ID>000624733</NSF_ID>
<StartDate>06/02/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Virginia Polytechnic Institute and State University</Name>
<CityName>BLACKSBURG</CityName>
<ZipCode>240603359</ZipCode>
<PhoneNumber>5402315281</PhoneNumber>
<StreetAddress>300 TURNER ST NW</StreetAddress>
<StreetAddress2><![CDATA[STE 4200]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA09</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>QDE5UHE5XD16</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>VIRGINIA POLYTECHNIC INSTITUTE &amp; STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>M515A1DKXAN8</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Virginia Polytechnic Institute and State University]]></Name>
<CityName>Blacksburg</CityName>
<StateCode>VA</StateCode>
<ZipCode>240611050</ZipCode>
<StreetAddress><![CDATA[620 Drillfield Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>158Y</Code>
<Text>COVID-19 Research</Text>
</ProgramElement>
<ProgramReference>
<Code>096Z</Code>
<Text>COVID-19 Research</Text>
</ProgramReference>
<ProgramReference>
<Code>7914</Code>
<Text>RAPID</Text>
</ProgramReference>
<ProgramReference>
<Code>7942</Code>
<Text>HIGH-PERFORMANCE COMPUTING</Text>
</ProgramReference>
<Appropriation>
<Code>1N20</Code>
<Name>R&amp;RA CARES Act DEFC N</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>010N2021DB</Code>
<Name><![CDATA[R&RA CARES Act DEFC N]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~150000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In early 2020, the COVID-19 pandemic caused an unprecedented health crisis in the United States. To mitigate the outbreak, more expansive testing was needed in 2020 and is still needed worldwide, particularly in light of the outbreak of the Delta variant, which has fueled a fourth wave of the pandemic in the USA&nbsp; and many other places in the world. Unfortunately, the "gold standard" RT-PCR&nbsp; genetic test for COVID-19 is both material- and labor-intensive, encompassing a multi-stage, end-to-end process that is time-consuming and error-prone and, in turn, resulting in a long turnaround time (i.e., days) and low accuracy (i.e., 59%-67%).&nbsp;</p> <p>Due to the overall inaccuracy of the RT-PCR test for COVID-19 (i.e., &lt; 67%) and its relatively high turnaround time,&nbsp;this project delivered an alternative COVID-19 test called ComputeCOVID19+ that delivers results in minutes, and more importantly, with high accuracy (91%). ComputeCOVID19+ facilitates early and accurate testing and monitoring of COVID-19 via post-image boosting and analysis of computed tomography (CT) scans, which use computer-processed combinations of many X-ray measurements to produce cross-section images of the chest (in particular, the lungs) to facilitate accurate COVID-19 diagnosis. Because our ComputeCOVID19+ framework significantly enhances the quality of chest CT images, it facilitates more accurate analysis and identification of the hallmark features of COVID-19, including consolidation, bilateral and peripheral disease, linear opacities, ?crazy-paving? pattern, and the ?reverse halo? sign. Specifically, we realize a novel deep-learning neural network that enhances the resolution and reduces the artifacts of chest CT images. It does so by modeling the image-formation processes in chest CT to deliver a super-resolution and deblur-based iterative framework for CT images. The neural network only learns the relevant blur kernels, appropriate weighting factors, and penalty functions of the regularization terms in the optimal solution for the CT super-resolution task. All told, this enabling approach will mitigate the negative effects of COVID-19 on public health, society, and the economy by delivering a highly accurate and highly available test for the rapid diagnosis and monitoring of COVID-19.</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/17/2021<br>      Modified by: Wuchun&nbsp;Feng</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2021/2031215/2031215_10674423_1629146632374_2021-RAPID-PostCT-ComputeCOVID-vs-PCR--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/2031215/2031215_10674423_1629146632374_2021-RAPID-PostCT-ComputeCOVID-vs-PCR--rgov-800width.jpg" title="RT-PCR vs. ComputeCOVID19+"><img src="/por/images/Reports/POR/2021/2031215/2031215_10674423_1629146632374_2021-RAPID-PostCT-ComputeCOVID-vs-PCR--rgov-66x44.jpg" alt="RT-PCR vs. ComputeCOVID19+"></a> <div class="imageCaptionContainer"> <div class="imageCaption">COVID-19 Testing:  The "Gold Standard" RT-PCR Genetic Test vs. ComputeCOVID19+ Post-CT Image Enhancement Test.</div> <div class="imageCredit">Wu-chun Feng</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Wuchun&nbsp;Feng</div> <div class="imageTitle">RT-PCR vs. ComputeCOVID19+</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/2031215/2031215_10674423_1629146859220_2021-RAPID-PostCT-ComputeCOVID-Cases--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/2031215/2031215_10674423_1629146859220_2021-RAPID-PostCT-ComputeCOVID-Cases--rgov-800width.jpg" title="Confirmed Cases of COVID-19 Per Million People"><img src="/por/images/Reports/POR/2021/2031215/2031215_10674423_1629146859220_2021-RAPID-PostCT-ComputeCOVID-Cases--rgov-66x44.jpg" alt="Confirmed Cases of COVID-19 Per Million People"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This plot of daily new confirmed COVID-19 cases per million people shows the USA, UK, and Japan in the 4th wave of the pandemic in spite of vaccinations. (Note: Japan's 4th wave coincided with the 2021 Summer Olympics.)</div> <div class="imageCredit">Wu-chun Feng via OurWorldInData</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Wuchun&nbsp;Feng</div> <div class="imageTitle">Confirmed Cases of COVID-19 Per Million People</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/2031215/2031215_10674423_1629150812453_2021-RAPID-PostCT-ComputeCOVID-Framework--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/2031215/2031215_10674423_1629150812453_2021-RAPID-PostCT-ComputeCOVID-Framework--rgov-800width.jpg" title="Post-CT Image Enhancement via ComputeCOVID19+"><img src="/por/images/Reports/POR/2021/2031215/2031215_10674423_1629150812453_2021-RAPID-PostCT-ComputeCOVID-Framework--rgov-66x44.jpg" alt="Post-CT Image Enhancement via ComputeCOVID19+"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The green arrows show the post-CT image enhancement and analysis of the ComputeCOVID19+ workflow. Our image enhancement measurably improves the accuracy of COVID-19 diagnosis (over that of using the original CT images) and significantly improves the accuracy when compared to RT-PCR (91% vs. 67%).</div> <div class="imageCredit">Wu-chun Feng</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Wuchun&nbsp;Feng</div> <div class="imageTitle">Post-CT Image Enhancement via ComputeCOVID19+</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/2031215/2031215_10674423_1629151075961_2021-RAPID-PostCT-ComputeCOVID-DDnet--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/2031215/2031215_10674423_1629151075961_2021-RAPID-PostCT-ComputeCOVID-DDnet--rgov-800width.jpg" title="The Architecture of a Dense &amp; Deconvolution Network (DDnet)"><img src="/por/images/Reports/POR/2021/2031215/2031215_10674423_1629151075961_2021-RAPID-PostCT-ComputeCOVID-DDnet--rgov-66x44.jpg" alt="The Architecture of a Dense &amp; Deconvolution Network (DDnet)"></a> <div class="imageCaptionContainer"> <div class="imageCaption">DDnet consists of a convolution network with 37 convolution layers and a deconvolution network with eight deconvolution layers. The convolution network, deconvolution network, and shortcut connections distinguish DDnet from existing state of the art.</div> <div class="imageCredit">Guohua Cao</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Wuchun&nbsp;Feng</div> <div class="imageTitle">The Architecture of a Dense & Deconvolution Network (DDnet)</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/2031215/2031215_10674423_1629151618310_2021-RAPID-PostCT-ComputeCOVID-Eval--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/2031215/2031215_10674423_1629151618310_2021-RAPID-PostCT-ComputeCOVID-Eval--rgov-800width.jpg" title="Image Enhancement Using Deep Learning DDnet"><img src="/por/images/Reports/POR/2021/2031215/2031215_10674423_1629151618310_2021-RAPID-PostCT-ComputeCOVID-Eval--rgov-66x44.jpg" alt="Image Enhancement Using Deep Learning DDnet"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The result of enhancing a CT image using the ComputeCOVID19+ framework. The "Enhancement AI" portion of  of the framework removed streaking and noise artifacts present in the image. The absolute difference maps between the low dose X-ray CT image and enhanced CT image indicate the efficacy of DDnet.</div> <div class="imageCredit">Wu-chun Feng</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Wuchun&nbsp;Feng</div> <div class="imageTitle">Image Enhancement Using Deep Learning DDnet</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/2031215/2031215_10674423_1629152139377_2021-RAPID-PostCT-ComputeCOVID-Summary--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/2031215/2031215_10674423_1629152139377_2021-RAPID-PostCT-ComputeCOVID-Summary--rgov-800width.jpg" title="Summary of ComputeCOVID19+"><img src="/por/images/Reports/POR/2021/2031215/2031215_10674423_1629152139377_2021-RAPID-PostCT-ComputeCOVID-Summary--rgov-66x44.jpg" alt="Summary of ComputeCOVID19+"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This figure presents a high-level summary of ComputeCOVID19+ relative to the current state of the art.</div> <div class="imageCredit">Wu-chun Feng</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Wuchun&nbsp;Feng</div> <div class="imageTitle">Summary of ComputeCOVID19+</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In early 2020, the COVID-19 pandemic caused an unprecedented health crisis in the United States. To mitigate the outbreak, more expansive testing was needed in 2020 and is still needed worldwide, particularly in light of the outbreak of the Delta variant, which has fueled a fourth wave of the pandemic in the USA  and many other places in the world. Unfortunately, the "gold standard" RT-PCR  genetic test for COVID-19 is both material- and labor-intensive, encompassing a multi-stage, end-to-end process that is time-consuming and error-prone and, in turn, resulting in a long turnaround time (i.e., days) and low accuracy (i.e., 59%-67%).   Due to the overall inaccuracy of the RT-PCR test for COVID-19 (i.e., &lt; 67%) and its relatively high turnaround time, this project delivered an alternative COVID-19 test called ComputeCOVID19+ that delivers results in minutes, and more importantly, with high accuracy (91%). ComputeCOVID19+ facilitates early and accurate testing and monitoring of COVID-19 via post-image boosting and analysis of computed tomography (CT) scans, which use computer-processed combinations of many X-ray measurements to produce cross-section images of the chest (in particular, the lungs) to facilitate accurate COVID-19 diagnosis. Because our ComputeCOVID19+ framework significantly enhances the quality of chest CT images, it facilitates more accurate analysis and identification of the hallmark features of COVID-19, including consolidation, bilateral and peripheral disease, linear opacities, ?crazy-paving? pattern, and the ?reverse halo? sign. Specifically, we realize a novel deep-learning neural network that enhances the resolution and reduces the artifacts of chest CT images. It does so by modeling the image-formation processes in chest CT to deliver a super-resolution and deblur-based iterative framework for CT images. The neural network only learns the relevant blur kernels, appropriate weighting factors, and penalty functions of the regularization terms in the optimal solution for the CT super-resolution task. All told, this enabling approach will mitigate the negative effects of COVID-19 on public health, society, and the economy by delivering a highly accurate and highly available test for the rapid diagnosis and monitoring of COVID-19.          Last Modified: 08/17/2021       Submitted by: Wuchun Feng]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
