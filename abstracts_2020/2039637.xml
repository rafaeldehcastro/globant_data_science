<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[EAGER: SaTC-EDU: A transdisciplinary program for pre-college youth to prepare the future workforce for FATE in AI]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2020</AwardEffectiveDate>
<AwardExpirationDate>10/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>299987.00</AwardTotalIntnAmount>
<AwardAmount>299987</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11010000</Code>
<Directorate>
<Abbreviation>EDU</Abbreviation>
<LongName>Directorate for STEM Education</LongName>
</Directorate>
<Division>
<Abbreviation>DGE</Abbreviation>
<LongName>Division Of Graduate Education</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Li Yang</SignBlockName>
<PO_EMAI>liyang@nsf.gov</PO_EMAI>
<PO_PHON>7032920000</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[The techniques and algorithms associated with artificial intelligence (AI) are simultaneously an outstanding benefit and a looming threat to cybersecurity. AI can aid in the detection of malicious attacks but can also contribute to the efficacy of such attacks. As AI-enabled systems become embedded in our most critical social institutions, the manipulation of their intended behavior is a serious threat to many fundamental rights. The challenge is not only technical, but also apparent in interactions across physical, social, and technological spheres. In order to respond to these challenges, it is critical to establish transdisciplinary approaches that bring together the fields of AI, cybersecurity, and social sciences to effectively understand and apply fairness, accountability, transparency, and ethics (FATE) principles in AI. To support this goal, this project will develop a novel educational approach called TechHive: AI. The approach will focus on recruiting teens from marginalized communities and providing them with training in how to address AI cybersecurity threats in ways that adhere to the FATE principles. The project’s focus ensures that students will receive the necessary preparation to pursue career pathways in AI and cybersecurity. In addition, it will support the development of an informed public capable of understanding the privacy, confidentiality, ethics, safety, and security implications of AI.&lt;br/&gt;&lt;br/&gt;The transdisciplinary project team will develop a set of design principles and processes to support learning at the intersection of AI, cybersecurity, and FATE. Specific deliverables will include: (1) a transdisciplinary curricular model for teaching cybersecurity and AI; (2) guidelines for the development of effective online and hybrid learning models that integrate STEM and social science curricula with FATE principles in cybersecurity and AI; and (3) a research report that will detail the effectiveness of this model to support high schoolers’ development of workforce skills. In addition, the project aims to address the following research questions: (1) Is there increased awareness and/or value of FATE principles among participating students? (2) Do students have increased awareness of the effects of technology on society and development of skills to design and deploy technology in ways that maximize societal benefit? (3) What design principles and processes best promote learning at the intersection of AI, cybersecurity, and FATE principles, especially among high schoolers within a hybrid/online instructional context? The design principles and processes produced through this collaborative effort will support the development of a knowledge base of best practices in integrating technical education with ethical training. &lt;br/&gt;&lt;br/&gt;This project is supported by a special initiative of the Secure and Trustworthy Cyberspace (SaTC) program to foster new, previously unexplored, collaborations between the fields of cybersecurity, artificial intelligence, and education. The SaTC program aligns with the Federal Cybersecurity Research and Development Strategic Plan and the National Privacy Research Strategy to protect and preserve the growing social and economic benefits of cyber systems while ensuring security and privacy.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>07/28/2020</MinAmdLetterDate>
<MaxAmdLetterDate>07/28/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2039637</AwardID>
<Investigator>
<FirstName>Mark</FirstName>
<LastName>Nitzberg</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mark J Nitzberg</PI_FULL_NAME>
<EmailAddress><![CDATA[nitz@berkeley.edu]]></EmailAddress>
<NSF_ID>000830766</NSF_ID>
<StartDate>07/28/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Matthew A.</FirstName>
<LastName>Cannady</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Matthew A. Cannady</PI_FULL_NAME>
<EmailAddress><![CDATA[mcannady@berkeley.edu]]></EmailAddress>
<NSF_ID>000620916</NSF_ID>
<StartDate>07/28/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Brandie</FirstName>
<LastName>Nonnecke</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Brandie Nonnecke</PI_FULL_NAME>
<EmailAddress><![CDATA[nonnecke@berkeley.edu]]></EmailAddress>
<NSF_ID>000822717</NSF_ID>
<StartDate>07/28/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Berkeley</Name>
<CityName>BERKELEY</CityName>
<ZipCode>947101749</ZipCode>
<PhoneNumber>5106433891</PhoneNumber>
<StreetAddress>1608 4TH ST STE 201</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA12</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>GS3YEVSS12N6</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>NUDGYLBB4S99</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Berkeley]]></Name>
<CityName>Berkeley</CityName>
<StateCode>CA</StateCode>
<ZipCode>947205200</ZipCode>
<StreetAddress><![CDATA[1 Centennial Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>025Z</Code>
<Text>SaTC: Secure and Trustworthy Cyberspace</Text>
</ProgramReference>
<ProgramReference>
<Code>093Z</Code>
<Text>AI Education/Workforce Develop</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0420</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>04002021DB</Code>
<Name><![CDATA[NSF Education & Human Resource]]></Name>
<FUND_SYMB_ID>040106</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~299987</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-2dcc878b-7fff-213c-947e-b9005a34230e"> </span></p> <p dir="ltr"><span>The techniques and algorithms associated with Artificial Intelligence (AI) are simultaneously an outstanding benefit and looming threat to cybersecurity. As AI-enabled systems enter into our most critical social institutions, the manipulation of their intended behavior is a serious threat to many fundamental rights, including bias in the judicial system, discrimination in hiring practices, and general safety. The challenge is not only technical. Rather, it manifests in interactions across physical, social, and technological spheres. To respond, this project took a transdisciplinary approach, bringing together the fields of AI and social sciences to effectively understand and apply security, accountability, fairness, ethics, and transparency (SAFE-T) principles in AI. In particular, the project team developed a novel educational approach, </span><span>TechHive:AI</span><span>, that recruited teens from local communities and invited them to develop techniques to address AI cybersecurity threats. In order to inspire further interest development and disciplinary integration, this project brought together experts in AI, social sciences, and learning design to create and deliver the curriculum as well as study the effects on the learners, the design process, and the integration of these previously independent disciplines. The outputs of this project include: (1) a transdisciplinary curriculum model for teaching cybersecurity and AI; (2) guidelines for the development of effective learning models that integrate STEM and social science curriculum with SAFE-T principles in cybersecurity and AI; and (3) research insights on the importance of integration of these concepts within simulations that learners can manipulate themselves.</span></p> <p dir="ltr"><span>Intellectual Merit</span><span><br /></span><span>Through the iterative design, development, and implementation pilots of TechHive AI, we saw considerable promise in learning activities where youth had access to technological resources that allowed them to engage with both the technical and the ethical aspects of AI. We found real value for students in building knowledge about the ethical consequences of AI through designing, directly manipulating the inputs of, and interrogating the outputs of AI models.</span></p> <p dir="ltr"><span>In this regard, the curriculum designers and educators observed that the situating the technical information and ethical concerns within particular contexts (e.g. college admissions, judicial systems) appeared to encourage learner engagement (i.e., participation in digital discourse through chat discussions; contributions to co-created ideation and reflection documents).&nbsp;</span></p> <p dir="ltr"><span>While TechHive:AI shows initial promise, additional research is needed to systematically examine the efficacy of this and similar instructional models, to gather evidence for particular instructional strategies or resources to advance sociotechnical learning, and of the feasibility of various models for implementation. With that said, the underlying instructional design model that aims at coherent integration across sociotechnical domains can support practitioners, learning designers, and researchers in engaging students in technical and responsible AI learning. Our framework details how the programmatic elements fit together and build on one another can complement international K-12 AI education efforts to articulate what students should understand about AI across grade bands, and how instructional materials and educators can support students in building that understanding.&nbsp;</span></p> <p><span>Broader Impacts</span><span><br /></span><span>Given historical barriers to access and blind spots in the development and deployment of AI systems, we see it as paramount to center equity in the design of AI-involving learning experiences and in the questions that drive research of those experiences. We see this as critical not only to respond to the expanding need for an AI-literate workforce, but to better position that workforce for innovations that adhere to principles of responsible AI. </span><span>The SAFE-T principles offer a human-centered approach to understanding, analyzing, and mitigating threats of AI. These principles can serve as a guide that enables a more holistic understanding of the interconnections between technical and social aspects of AI. Integrating these principles into AI education is a critical step toward developing a robust workforce that has both AI technical competencies and understanding of the privacy, confidentiality, ethics, and safety implications of AI.</span></p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 01/26/2022<br>      Modified by: Matthew A.&nbsp;Cannady</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   The techniques and algorithms associated with Artificial Intelligence (AI) are simultaneously an outstanding benefit and looming threat to cybersecurity. As AI-enabled systems enter into our most critical social institutions, the manipulation of their intended behavior is a serious threat to many fundamental rights, including bias in the judicial system, discrimination in hiring practices, and general safety. The challenge is not only technical. Rather, it manifests in interactions across physical, social, and technological spheres. To respond, this project took a transdisciplinary approach, bringing together the fields of AI and social sciences to effectively understand and apply security, accountability, fairness, ethics, and transparency (SAFE-T) principles in AI. In particular, the project team developed a novel educational approach, TechHive:AI, that recruited teens from local communities and invited them to develop techniques to address AI cybersecurity threats. In order to inspire further interest development and disciplinary integration, this project brought together experts in AI, social sciences, and learning design to create and deliver the curriculum as well as study the effects on the learners, the design process, and the integration of these previously independent disciplines. The outputs of this project include: (1) a transdisciplinary curriculum model for teaching cybersecurity and AI; (2) guidelines for the development of effective learning models that integrate STEM and social science curriculum with SAFE-T principles in cybersecurity and AI; and (3) research insights on the importance of integration of these concepts within simulations that learners can manipulate themselves. Intellectual Merit Through the iterative design, development, and implementation pilots of TechHive AI, we saw considerable promise in learning activities where youth had access to technological resources that allowed them to engage with both the technical and the ethical aspects of AI. We found real value for students in building knowledge about the ethical consequences of AI through designing, directly manipulating the inputs of, and interrogating the outputs of AI models. In this regard, the curriculum designers and educators observed that the situating the technical information and ethical concerns within particular contexts (e.g. college admissions, judicial systems) appeared to encourage learner engagement (i.e., participation in digital discourse through chat discussions; contributions to co-created ideation and reflection documents).  While TechHive:AI shows initial promise, additional research is needed to systematically examine the efficacy of this and similar instructional models, to gather evidence for particular instructional strategies or resources to advance sociotechnical learning, and of the feasibility of various models for implementation. With that said, the underlying instructional design model that aims at coherent integration across sociotechnical domains can support practitioners, learning designers, and researchers in engaging students in technical and responsible AI learning. Our framework details how the programmatic elements fit together and build on one another can complement international K-12 AI education efforts to articulate what students should understand about AI across grade bands, and how instructional materials and educators can support students in building that understanding.   Broader Impacts Given historical barriers to access and blind spots in the development and deployment of AI systems, we see it as paramount to center equity in the design of AI-involving learning experiences and in the questions that drive research of those experiences. We see this as critical not only to respond to the expanding need for an AI-literate workforce, but to better position that workforce for innovations that adhere to principles of responsible AI. The SAFE-T principles offer a human-centered approach to understanding, analyzing, and mitigating threats of AI. These principles can serve as a guide that enables a more holistic understanding of the interconnections between technical and social aspects of AI. Integrating these principles into AI education is a critical step toward developing a robust workforce that has both AI technical competencies and understanding of the privacy, confidentiality, ethics, and safety implications of AI.             Last Modified: 01/26/2022       Submitted by: Matthew A. Cannady]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
