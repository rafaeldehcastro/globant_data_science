<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[NSF Convergence Accelerator Track D: Towards Intelligent Sharing and Search for AI Models and Datasets]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2020</AwardEffectiveDate>
<AwardExpirationDate>12/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>947200.00</AwardTotalIntnAmount>
<AwardAmount>947200</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>15020000</Code>
<Directorate>
<Abbreviation>TIP</Abbreviation>
<LongName>Dir for Tech, Innovation, &amp; Partnerships</LongName>
</Directorate>
<Division>
<Abbreviation>ITE</Abbreviation>
<LongName>Innovation and Technology Ecosystems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Mike Pozmantier</SignBlockName>
<PO_EMAI>mpozmant@nsf.gov</PO_EMAI>
<PO_PHON>7032924475</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[The NSF Convergence Accelerator supports use-inspired, team-based, multidisciplinary efforts that address challenges of national importance and will produce deliverables of value to society in the near future. A major goal of AI-driven applications is to discover the underlying patterns in domain-specific datasets, which typically requires tremendous field experience and interdisciplinary knowledge to design or even select suitable AI models. This project will develop a hub and portal for AI data sets and models. It will offer data and model matching recommendations, the use of domain knowledge to improve search strategies for data sets and models, and support for privacy. The hub and portal will engage a broad range of users (in STEM and non-STEM fields) creating AI-driven innovations in various domains that we can only imagine today. Successful execution will provide new tangible artifacts consisting of model and data schemas, software, systems, and services that would make the AI models and datasets easily discoverable, accessible, interoperable, and reproducible.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;Four novel techniques will be used to realize the envisioned system: (1) A fine-grained privacy control technique with adaptive descriptive statistics, achieving a balance between the privacy needs of data owners and application-driven usability. All other components will have access to only the privacy-controlled data; (2) An automated metadata generation method that exploits various kinds of information about AI models and datasets (e.g., data values, model parameters, auxiliary descriptions) to incorporate domain logic into semantics. This metadata, together with the models and datasets, will be organized as a text-rich network; (3) A representation learning method that transforms information in the text-rich network into a latent space, where datasets/models with similar semantics would be close to each other. This learning over multimodal data will enable comprehensive understandings about models and datasets; (4) A learning-to-match model with constraints will be built to bridge datasets and models. The constraints are mainly induced from schema alignment between models and datasets, which can also filter out obvious non-compatible model and dataset choices, significantly expediting the search and matching process.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>09/08/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/14/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.083</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2040727</AwardID>
<Investigator>
<FirstName>Rajesh</FirstName>
<LastName>Gupta</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rajesh K Gupta</PI_FULL_NAME>
<EmailAddress><![CDATA[gupta@cs.ucsd.edu]]></EmailAddress>
<NSF_ID>000449012</NSF_ID>
<StartDate>09/08/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Lucila</FirstName>
<LastName>Ohno-Machado</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lucila Ohno-Machado</PI_FULL_NAME>
<EmailAddress><![CDATA[lohnomachado@health.ucsd.edu]]></EmailAddress>
<NSF_ID>000613818</NSF_ID>
<StartDate>09/08/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Arun</FirstName>
<LastName>Kumar</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Arun K Kumar</PI_FULL_NAME>
<EmailAddress><![CDATA[arunkk@eng.ucsd.edu]]></EmailAddress>
<NSF_ID>000732398</NSF_ID>
<StartDate>09/08/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Giorgio</FirstName>
<LastName>Quer</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Giorgio Quer</PI_FULL_NAME>
<EmailAddress><![CDATA[gquer@scripps.edu]]></EmailAddress>
<NSF_ID>000778852</NSF_ID>
<StartDate>09/08/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jingbo</FirstName>
<LastName>Shang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jingbo Shang</PI_FULL_NAME>
<EmailAddress><![CDATA[jshang@ucsd.edu]]></EmailAddress>
<NSF_ID>000814942</NSF_ID>
<StartDate>09/08/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-San Diego</Name>
<CityName>LA JOLLA</CityName>
<ZipCode>920930021</ZipCode>
<PhoneNumber>8585344896</PhoneNumber>
<StreetAddress>9500 GILMAN DRIVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>50</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA50</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>UYTTZT6G9DT1</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SAN DIEGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California San Diego]]></Name>
<CityName>La Jolla</CityName>
<StateCode>CA</StateCode>
<ZipCode>920930404</ZipCode>
<StreetAddress><![CDATA[9500 Gilman Dr, CSE 4104]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>50</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA50</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>131Y</Code>
<Text>Convergence Accelerator Resrch</Text>
</ProgramElement>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~947200</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>We have developed a proof-of-concept prototype of our intelligent, context-aware sharing, search, and matching AIMaker platform with an amenable user interface. In AIMaker, a user can directly input a few keyphrases (such as &ldquo;models for sensor time series prediction&rdquo;) to search for desired models, or they can upload a toy data file from their dataset(s) and AIMaker would provide more&nbsp;<em>contextualized</em>&nbsp;search based on this sample file for a target model. To realize this matching by dataset, the user has to first add a dataset to our platform by specifying some metadata (please note that there is no data file upload here), and then the user can do some matching and search.</span></p> <p><span>Our AIMaker platform is supported by our technical research on the topics of automated keyphrase extraction, few-shot and weakly supervised learning for metadata generation and management, text-rich network construction and representation learning, type inference and schema alignment, privacy-preserving and robustness techniques, an explainable AI framework for biomedical time-series, and AI-driven applications in smart building, intellectual patent, and biomedical domains. All these research results have been turned into scientific publications in top venues, including 32 published, peer reviewed papers, 2 tech reports, and 3 submissions.</span></p> <p><span>We have prepared a dataset consisting of three types of elements: AI tasks, AI datasets, and AI models. A task usually involves a common issue that researchers use different datasets to address, and a single dataset may have been used to train different models with different functionality. Therefore, both the tasks-datasets pair and the datasets-models pair have a one-to-many relationship. Our dataset, mainly obtained from paperswithcode.com, github.com, and dblp.org, contains a total of 2,307 tasks, 2,379 datasets, and 4,896 models. Most of the datasets and models fall under fields such as computer vision, natural language processing, and medicine.</span></p> <p><span>In addition, we have created the first ever large benchmark labeled dataset for the feature type inference task. Our dataset has 9,921 examples from 1,240 real data files from sources such as Kaggle and UCI ML repository. We manually hand-labeled these 9,921 columns with a standardized 9-class label vocabulary. The classes include feature types such as Numeric, Categorical, Datetime, and Not-Generalizable (e.g., primary keys of the table). The entire labeling process took about 90 man-hours across 5 months. The labeled dataset not only enables us to objectively quantify the feature type inference task but also offers us an ML-based approach to automate it. We have released a public repository on GitHub with our labeled data and pre-trained ML models used to automate the task (https://github.com/pvn25/ML-Data- Prep-Zoo). Moreover, we have made all the models and featurization routines available for use by wrapping them under functions in a Python library (https://github.com/pvn25/ML-Data-Prep- Zoo/tree/master/MLFeatureTypeInference/Library).</span></p> <p><span>We have already launched the ML Data Prep Zoo, an open-source community-oriented repository for benchmark tasks, labeled datasets, and models from our automated schema inference and other data preparation tasks. We plan to keep expanding that repository. The platform we produce in this proposed work, AIMaker, will also be open sourced on GitHub. We will use it as the core tool for the HDSI Data Planet Fellowships at UCSD to nurture a community of contributors and users with direct impact on domain science research.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 04/11/2023<br>      Modified by: Jingbo&nbsp;Shang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ We have developed a proof-of-concept prototype of our intelligent, context-aware sharing, search, and matching AIMaker platform with an amenable user interface. In AIMaker, a user can directly input a few keyphrases (such as "models for sensor time series prediction") to search for desired models, or they can upload a toy data file from their dataset(s) and AIMaker would provide more contextualized search based on this sample file for a target model. To realize this matching by dataset, the user has to first add a dataset to our platform by specifying some metadata (please note that there is no data file upload here), and then the user can do some matching and search.  Our AIMaker platform is supported by our technical research on the topics of automated keyphrase extraction, few-shot and weakly supervised learning for metadata generation and management, text-rich network construction and representation learning, type inference and schema alignment, privacy-preserving and robustness techniques, an explainable AI framework for biomedical time-series, and AI-driven applications in smart building, intellectual patent, and biomedical domains. All these research results have been turned into scientific publications in top venues, including 32 published, peer reviewed papers, 2 tech reports, and 3 submissions.  We have prepared a dataset consisting of three types of elements: AI tasks, AI datasets, and AI models. A task usually involves a common issue that researchers use different datasets to address, and a single dataset may have been used to train different models with different functionality. Therefore, both the tasks-datasets pair and the datasets-models pair have a one-to-many relationship. Our dataset, mainly obtained from paperswithcode.com, github.com, and dblp.org, contains a total of 2,307 tasks, 2,379 datasets, and 4,896 models. Most of the datasets and models fall under fields such as computer vision, natural language processing, and medicine.  In addition, we have created the first ever large benchmark labeled dataset for the feature type inference task. Our dataset has 9,921 examples from 1,240 real data files from sources such as Kaggle and UCI ML repository. We manually hand-labeled these 9,921 columns with a standardized 9-class label vocabulary. The classes include feature types such as Numeric, Categorical, Datetime, and Not-Generalizable (e.g., primary keys of the table). The entire labeling process took about 90 man-hours across 5 months. The labeled dataset not only enables us to objectively quantify the feature type inference task but also offers us an ML-based approach to automate it. We have released a public repository on GitHub with our labeled data and pre-trained ML models used to automate the task (https://github.com/pvn25/ML-Data- Prep-Zoo). Moreover, we have made all the models and featurization routines available for use by wrapping them under functions in a Python library (https://github.com/pvn25/ML-Data-Prep- Zoo/tree/master/MLFeatureTypeInference/Library).  We have already launched the ML Data Prep Zoo, an open-source community-oriented repository for benchmark tasks, labeled datasets, and models from our automated schema inference and other data preparation tasks. We plan to keep expanding that repository. The platform we produce in this proposed work, AIMaker, will also be open sourced on GitHub. We will use it as the core tool for the HDSI Data Planet Fellowships at UCSD to nurture a community of contributors and users with direct impact on domain science research.          Last Modified: 04/11/2023       Submitted by: Jingbo Shang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
