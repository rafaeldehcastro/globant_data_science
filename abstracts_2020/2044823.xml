<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[CAREER: Next-Generation Methods for Statistical Integration of High-Dimensional Disparate Data Sources]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2021</AwardEffectiveDate>
<AwardExpirationDate>05/31/2026</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>245638</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Yong Zeng</SignBlockName>
<PO_EMAI>yzeng@nsf.gov</PO_EMAI>
<PO_PHON>7032927299</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[Multi-view data (collected on the same samples from multiple sources) are increasingly common with advances in multi-omics, neuroimaging and wearable technologies. For example, wearable devices such as physical activity trackers, continuous glucose monitors and ambulatory blood pressure monitors are worn concurrently to provide measurements of distinct subjects’ characteristics. There is enormous potential in integrating that concurrent information from the distinct vantages to better understand between-view associations and improve prediction of health outcomes. Existing tools for data integration are sensitive to outliers, and are not designed for mixed data types (e.g. continuous skewed glucose measurements, zero-inflated activity counts, binary indicators of sleep/wake). The PI will develop a more robust framework for multi-view data integration that is better able to account for outliers, better match the mixed types of data actually collected, and be more accurate in separating common from view-specific signals. The new methods will be implemented in open-source software accompanied by reproducible workflow examples, providing immediate and easy access for other researchers. The educational component centers on the development of structured research experiences (SRE) for students. SRE enhances students written communication, software development and reproducible research skills, all of which are lacking in traditional curriculum. This will improve students’ preparation for conducting research, and widen their STEM employment opportunities. The involvement of students from traditionally underrepresented groups will positively impact their retention rate and will broaden the participation of underrepresented groups in STEM.&lt;br/&gt;&lt;br/&gt;Popular dimension reduction methods, such as principal component analysis and discriminant analysis, are tailored for single-view data, and thus fail to discover coordinated multi-view signals on a global level. On the other hand, existing multi-view dimension reduction methods suffer from reliance on the Gaussianity assumption, an inability to capture joint functional signals, and a lack of theoretical guarantees. The PI will address these drawbacks by (i) developing a joint dimension reduction framework for skewed continuous, binary and zero-inflated view types; (ii) a joint dimension reduction framework for mixed functional multi-view data and (iii) a new paradigm for simultaneous extraction of signals across views based on hierarchical low-rank constraints.  This work will lead to critically needed new statistical methods for data integration with direct relevance for researchers working with wearable monitors, microbiome and multi-omics data through interdisciplinary collaborations of the PI. The proposed structured research experiences will center on the design and reproducibility of simulations studies, and align with computational components of the proposed research, including direct students’ involvement in multiple simulation studies.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>02/08/2021</MinAmdLetterDate>
<MaxAmdLetterDate>04/26/2023</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2044823</AwardID>
<Investigator>
<FirstName>Irina</FirstName>
<LastName>Gaynanova</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Irina Gaynanova</PI_FULL_NAME>
<EmailAddress><![CDATA[irinag@stat.tamu.edu]]></EmailAddress>
<NSF_ID>000735944</NSF_ID>
<StartDate>02/08/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Texas A&amp;M University</Name>
<CityName>COLLEGE STATION</CityName>
<ZipCode>778454375</ZipCode>
<PhoneNumber>9798626777</PhoneNumber>
<StreetAddress>400 HARVEY MITCHELL PKY S STE 30</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>JF6XLNB4CDJ5</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>TEXAS A &amp; M UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>HH6VX5XDL284</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Texas A&M University]]></Name>
<CityName>College Station</CityName>
<StateCode>TX</StateCode>
<ZipCode>778433143</ZipCode>
<StreetAddress><![CDATA[3143 TAMU]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Fund>
<Code>01002324DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002223DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2021~78917</FUND_OBLG>
<FUND_OBLG>2022~78421</FUND_OBLG>
<FUND_OBLG>2023~88300</FUND_OBLG>
</Award>
</rootTag>
