<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[CIF: Small: Alpha Loss: A New Framework for Understanding and Trading Off Computation, Accuracy, and Robustness in Machine Learning]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>507999.00</AwardTotalIntnAmount>
<AwardAmount>539999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Alfred Hero</SignBlockName>
<PO_EMAI>ahero@nsf.gov</PO_EMAI>
<PO_PHON>7032920000</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[At the heart of the machine learning (ML) and artificial intelligence (AI) revolution are models that are trained using vast amounts of data. Given the increasing use of such data-driven modeling, there is an urgent need to understand and leverage the tradeoffs between various performance characteristics such as accuracy (statistical efficiency), computational speed (computational efficiency), and robustness (say to noise, adversarial tampering, and imbalance or biased data). This project develops a unified and powerful framework for understanding and trading off these facets by introducing the family of alpha-loss functions -- often-used loss functions such as the 0-1 loss, the log-loss, and the exponential-loss appear as instantiations of the alpha-loss framework. Over the past few years, we have seen a steadily growing recognition amongst advocates, regulators, and scientists that data-driven inference and decision engines pose significant challenges for ensuring  non-discrimination, and fair and inclusive representation. The alpha-loss framework, combined with several technological advances, will allow practitioners to incorporate fairness as an explicit knob to be tuned during the development of machine learning models. Broader impacts of this work also include developing ML modules for a week-long summer camp for high school students as well as providing research opportunities for such students. &lt;br/&gt;&lt;br/&gt;This project: (i) develops theoretical results on the behavior of the loss landscape as a function of the tuning parameter alpha, thereby illuminating the value and limitation of the industry standard log-loss, (ii) establishes accuracy-speed tradeoffs and generalization bounds, and (iii) designs practical adaptive algorithms with guarantees for tuning the hyperparameter alpha to achieve various operating points along the tradeoff. This project establishes the robustness properties of alpha-loss via the theory of influence functions. By introducing much-needed models for noise and adversarial examples, this work develops a principled method to choose alpha slightly larger than 1 to design models more robust to noise and adversaries. Using both influence functions and constrained learning settings such as fair classification, this project studies the efficacy of tuning alpha below one in order to enhance sensitivity to limited samples in highly imbalanced training datasets. Finally, this project also develops alpha-Boost as a tunable boosting algorithm with guaranteed convergence, robustness to noise and, where needed, online adaptation. Research is enhanced at every stage of this project through rigorous testing of algorithms on both synthetic and publicly available real datasets.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>08/25/2020</MinAmdLetterDate>
<MaxAmdLetterDate>03/29/2023</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2007688</AwardID>
<Investigator>
<FirstName>Lalitha</FirstName>
<LastName>Sankar</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lalitha Sankar</PI_FULL_NAME>
<EmailAddress><![CDATA[lalithasankar@asu.edu]]></EmailAddress>
<NSF_ID>000547715</NSF_ID>
<StartDate>08/25/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Gautam</FirstName>
<LastName>Dasarathy</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gautam Dasarathy</PI_FULL_NAME>
<EmailAddress><![CDATA[gautamd@asu.edu]]></EmailAddress>
<NSF_ID>000792031</NSF_ID>
<StartDate>08/25/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Arizona State University</Name>
<CityName>TEMPE</CityName>
<ZipCode>852813670</ZipCode>
<PhoneNumber>4809655479</PhoneNumber>
<StreetAddress>660 S MILL AVENUE STE 204</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ04</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>NTLHJXM55KZ6</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>ARIZONA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Arizona State University]]></Name>
<CityName>Tempe</CityName>
<StateCode>AZ</StateCode>
<ZipCode>852876011</ZipCode>
<StreetAddress><![CDATA[PO Box 876011]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>2878</Code>
<Text>Special Projects - CCF</Text>
</ProgramElement>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<ProgramReference>
<Code>079Z</Code>
<Text>Machine Learning Theory</Text>
</ProgramReference>
<ProgramReference>
<Code>2878</Code>
<Text>SPECIAL PROJECTS - CCF</Text>
</ProgramReference>
<ProgramReference>
<Code>7797</Code>
<Text>COMM &amp; INFORMATION FOUNDATIONS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002324DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~507999</FUND_OBLG>
<FUND_OBLG>2021~16000</FUND_OBLG>
<FUND_OBLG>2023~16000</FUND_OBLG>
</Award>
</rootTag>
