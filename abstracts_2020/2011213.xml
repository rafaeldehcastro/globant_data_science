<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Collaborative Research: FoMR: Enabling High Instructions-per-Cycle (IPC) Counts in Future Multi-NUMA (Non Uniform Memory Access) Systems]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2020</AwardEffectiveDate>
<AwardExpirationDate>06/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>95000.00</AwardTotalIntnAmount>
<AwardAmount>95000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Danella Zhao</SignBlockName>
<PO_EMAI>dzhao@nsf.gov</PO_EMAI>
<PO_PHON>7032924434</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[Emerging memory technologies, such as three-dimensional die-stacked dynamic random access memory (3D-DRAM) and non-volatile random-access memory (NVRAM), introduce promising opportunities in achieving high performance for computer processors. Computer servers with mixed memory technologies introduce a new multi-dimensional non-uniform memory access (“multi-NUMA”) method, where the computer memory hierarchy has widely varying performance and efficiency characteristics depending on the type of memory and where it resides in the system. Despite the promising benefits, multi-NUMA systems impose significant architecture design challenges due to the level of heterogeneity they introduce. The multi-dimensional heterogeneity, which ranges from access latency, bandwidth, and access granularity to reliability and functionality, makes memory hierarchy performance and access behavior difficult to predict and manipulate. Addressing these issues can influence the architecture design for building efficient multi-NUMA systems and also spawn new applications that can deal with larger volumes of heterogeneous data than what is possible at present.&lt;br/&gt;&lt;br/&gt;This project aims to improve the performance of future server systems that incorporate mixed memory technologies. To achieve the objective, this project consists of three phases. The first phase seeks to reinvestigate the basic performance models, assumptions, and metrics of memory hierarchy architecture design, across memory system performance, reliability, and scalability, by encompassing the multi-NUMA scenario. Guided by the multi-NUMA-aware architecture design strategies, the second phase will focus on reconsidering the design of memory hierarchy architecture components that are critical to the application’s instructions-per-cycle (IPC) performance. Finally, the third phase seeks to ensure scalable IPC performance in both multi-socket and memory-fabric-based multi-NUMA systems.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>07/13/2020</MinAmdLetterDate>
<MaxAmdLetterDate>07/13/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2011213</AwardID>
<Investigator>
<FirstName>Joseph</FirstName>
<LastName>Izraelevitz</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joseph H Izraelevitz</PI_FULL_NAME>
<EmailAddress><![CDATA[joseph.izraelevitz@colorado.edu]]></EmailAddress>
<NSF_ID>000815399</NSF_ID>
<StartDate>07/13/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Colorado at Boulder</Name>
<CityName>BOULDER</CityName>
<ZipCode>803090001</ZipCode>
<PhoneNumber>3034926221</PhoneNumber>
<StreetAddress>3100 MARINE ST</StreetAddress>
<StreetAddress2><![CDATA[STE 481 572 UCB]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<StateCode>CO</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CO02</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>SPVKK1RC2MZ3</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>THE REGENTS OF THE UNIVERSITY OF COLORADO</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Colorado at Boulder]]></Name>
<CityName>Boulder</CityName>
<StateCode>CO</StateCode>
<ZipCode>803031058</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CO02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>021Z</Code>
<Text>Industry Partnerships</Text>
</ProgramReference>
<ProgramReference>
<Code>7798</Code>
<Text>SOFTWARE &amp; HARDWARE FOUNDATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramReference>
<ProgramReference>
<Code>8585</Code>
<Text>NSF/Intel Partnership Projects</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~95000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Our goal in this project was to improve the instructions-per-cycle (IPC) of future server systems that incorporate mixed memory technologies. To achieve our objective, we proposed to perform the following research thrusts. First, we would reinvestigate the basic performance models, assumptions, and metrics of memory hierarchy architecture design, across memory system performance, reliability, and scalability, by encompassing the multi-NUMA scenario. Second, guided by our multi-NUMA-aware architecture design strategies, we would reconsider the design of memory hierarchy architecture components that are critical to application's IPC performance. Third, we would seek to ensure scalable IPC performance in both multi-socket and memory-fabric-based multi-NUMA systems.<br /><br />In early project periods, we focused on exploring use cases of multi-NUMA systems in current and future applications.&nbsp; In this category, we explored novel I/O interfaces to the file system in order to improve single thread performance when performing file accesses.&nbsp; These novel interfaces expanded POSIX semantics in order to avoid unnecessary copying within the memory hierarchy and file system, and were integrated into two separate file systems.&nbsp; This design was validated across a variety of micro and macro benchmarks, with performance improvements between 30 and 300%.&nbsp; Our work was published as "SubZero: Zero-copy IO for Persistent Main Memory File Systems", awarded the best paper award at ACM SIGOPS Asia-Pacific Workshop on Systems (APSys) in August 2020.<br /><br />In the final year of the project, we worked to improve our solution for converting existing programs into programs that can survive the loss of power using persistent memory (e.g. Intel Optane or Samsung memory-semantic SSDs).&nbsp; Our solution, Zhuque, interposes on C library functions in order to map all relevant program space into persistent memory and leverages "flush on fail" technologies such as Intel's eADR or CXL's global persistent flush.&nbsp; We continued development of Zhuque during this period to include a small kernel module for appropriately handling context switches and other kernel entries by migrating process kernel state into persistent memory.&nbsp; This work was published as "Zhuque: Failure is Not an Option, it&rsquo;s an Exception" at USENIX Annual Technical Conference (ATC) in July 2023.</p><br> <p>            Last Modified: 10/25/2023<br>      Modified by: Joseph&nbsp;H&nbsp;Izraelevitz</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Our goal in this project was to improve the instructions-per-cycle (IPC) of future server systems that incorporate mixed memory technologies. To achieve our objective, we proposed to perform the following research thrusts. First, we would reinvestigate the basic performance models, assumptions, and metrics of memory hierarchy architecture design, across memory system performance, reliability, and scalability, by encompassing the multi-NUMA scenario. Second, guided by our multi-NUMA-aware architecture design strategies, we would reconsider the design of memory hierarchy architecture components that are critical to application's IPC performance. Third, we would seek to ensure scalable IPC performance in both multi-socket and memory-fabric-based multi-NUMA systems.  In early project periods, we focused on exploring use cases of multi-NUMA systems in current and future applications.  In this category, we explored novel I/O interfaces to the file system in order to improve single thread performance when performing file accesses.  These novel interfaces expanded POSIX semantics in order to avoid unnecessary copying within the memory hierarchy and file system, and were integrated into two separate file systems.  This design was validated across a variety of micro and macro benchmarks, with performance improvements between 30 and 300%.  Our work was published as "SubZero: Zero-copy IO for Persistent Main Memory File Systems", awarded the best paper award at ACM SIGOPS Asia-Pacific Workshop on Systems (APSys) in August 2020.  In the final year of the project, we worked to improve our solution for converting existing programs into programs that can survive the loss of power using persistent memory (e.g. Intel Optane or Samsung memory-semantic SSDs).  Our solution, Zhuque, interposes on C library functions in order to map all relevant program space into persistent memory and leverages "flush on fail" technologies such as Intel's eADR or CXL's global persistent flush.  We continued development of Zhuque during this period to include a small kernel module for appropriately handling context switches and other kernel entries by migrating process kernel state into persistent memory.  This work was published as "Zhuque: Failure is Not an Option, it’s an Exception" at USENIX Annual Technical Conference (ATC) in July 2023.       Last Modified: 10/25/2023       Submitted by: Joseph H Izraelevitz]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
