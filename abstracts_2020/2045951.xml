<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[CAREER: From Fairness to Justice in AI systems]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2021</AwardEffectiveDate>
<AwardExpirationDate>09/30/2026</AwardExpirationDate>
<AwardTotalIntnAmount>550000.00</AwardTotalIntnAmount>
<AwardAmount>550000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[Despite the incredible success of Artificial Intelligence (AI) systems, their predictions and decisions have been shown to discriminatory in crucial domains such as employment, housing, and lending. Hence, it is imperative to center the interests of the public, protect disadvantaged groups, and empower society in the design and execution of the technology we create. This can only be done by considering the entire ecosystem in which the AI is situated â€“ one cannot assume perfect data or perfect usage of the technology. In this project novel approaches towards anti-discriminatory AI will be assessed and redesigned taking into account common flaws in the data stream. The evaluation of the systems will be done in the broader context in which the technology is commonly used in order to assess the downstream effects and long-term impacts of different approaches to fair machine learning interventions. Further, the researchers will produce engaging content for students, the AI community and the public, in order to engage all in working towards the socially-conscious design of AI systems.&lt;br/&gt;&lt;br/&gt;From a technical standpoint, this work will design new approaches that take into account the problems that arise when a machine-learning algorithm is lifted out of the lab and placed into a broader ecosystem in which data is erroneous and humans interact with the AI system. Outcomes of this project will include new models and algorithms for fundamental problems in fair machine learning such as classification, summarization, ranking, and online advertising that can satisfy fairness demands while simultaneously performing well according to their original objectives. Importantly, these algorithms will function in a robust manner that account for realities such as missing, incorrect, or adversarial data. The projects will increase our understanding of the demand and nature of fairness within specific social and economic contexts, and the impact that fair machine learning interventions can have. This project will significantly impact and advance the technical core of computer and data science, and inculcate a more holistic approach towards social justice in AI systems.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>07/13/2021</MinAmdLetterDate>
<MaxAmdLetterDate>09/13/2022</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2045951</AwardID>
<Investigator>
<FirstName>Elisa</FirstName>
<LastName>Celis</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Elisa Celis</PI_FULL_NAME>
<EmailAddress><![CDATA[elisa.celis@yale.edu]]></EmailAddress>
<NSF_ID>000792338</NSF_ID>
<StartDate>07/13/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Yale University</Name>
<CityName>NEW HAVEN</CityName>
<ZipCode>065118917</ZipCode>
<PhoneNumber>2037854689</PhoneNumber>
<StreetAddress>105 WALL ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<StateCode>CT</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CT03</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>FL6GV84CKN57</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>YALE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>FL6GV84CKN57</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Yale University]]></Name>
<CityName>New Haven</CityName>
<StateCode>CT</StateCode>
<ZipCode>065208290</ZipCode>
<StreetAddress><![CDATA[24 Hillhouse Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CT03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0122</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002223DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2021~326725</FUND_OBLG>
<FUND_OBLG>2022~223275</FUND_OBLG>
</Award>
</rootTag>
