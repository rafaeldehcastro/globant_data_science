<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Integrating Human and Machine Learning for Enabling Co-Adaptive Body-Machine Interfaces]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2021</AwardEffectiveDate>
<AwardExpirationDate>08/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>714227.00</AwardTotalIntnAmount>
<AwardAmount>714227</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CMMI</Abbreviation>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Alex Leonessa</SignBlockName>
<PO_EMAI>aleoness@nsf.gov</PO_EMAI>
<PO_PHON>7032922633</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[This project for the Mind, Machine, and Motor Nexus (M3X) program will advance understanding of how people learn new neuromotor skills, and subsequently apply that understanding to the creation of innovative wearable device controllers called body-machine interfaces (BoMIs). Individuals with neuromuscular impairment -- perhaps due to stroke or spinal cord injury -- may have difficulty carrying out the activities of everyday life. This project explores novel interfaces through which an individual can use their body's residual mobility to issue commands to assistive devices such as computer cursors, wheelchairs, or robotic arms. The project has three main research goals. The first is to improve existing methods for translating small body movements into controller commands for assistive devices. The second is to model the process by which the human user learns over time to use the body-machine interface. The third is to apply the obtained model of the learning process to enable the body-machine interface to adjust to the evolving characteristics of the human user. An interface that does not adapt to changes in its user may significantly degrade in performance over time. On the other hand, an interface whose properties instantly change with every small shift in user behavior will be difficult to control. The ultimate outcome of this project will be human-machine interfaces based on body movement that consider the user and the interface as two components of an integrated system in which each component continually learns from and adapts to the other. The results of the project will lead to assistive devices that more affordable, and provide more versatile control and ease of use. The underlying principles of co-adaptation to be identified through this work are also relevant to rehabilitation from disease or injury, as well as to increasing the capabilities of human-operated robotic systems.&lt;br/&gt;&lt;br/&gt;Recent work has shown that linear methods such as principal component analysis (PCA) may be effectively used in a body-machine interface (BoMI) to map elements from a higher dimensional feature space of body movements onto a lower dimensional space of device commands. In this project, the features that provide input to the BoMI are generated by multiple inertial measurement units (IMUs) worn by the user; the IMUs report their current orientation in an inertial reference space. The output from the BoMI are commands used to control a sequence of representative devices, specifically a computer cursor, a simulated wheelchair, an actual wheelchair, and a simulated manipulator arm. The three technical goals of the project are as follows: 1) Compare the performance of a linear map based on PCA to a nonlinear map based on an autoencoder network (AEN) for providing input features to the BoMI that translates residual mobility space features into device commands. The AEN is capable of representing a richer variety of features than PCA, but it remains to be shown, for example, whether human users can make effective use of that variety. 2) Obtain a computable representation of the process by which humans learn neuromotor skills. This representation will be based on the premise that humans simultaneously learn both a forward and inverse map of the relationship between neuromotor signals and the resulting physical outcomes. Once learned, the forward map predicts the outcomes that will result from a certain set of signals, while the inverse map is used to generate the signals that correspond to a given desired physical outcome. As a person learns mastery of a neuromotor skill, the forward and inverse maps become more accurate predictors of actual behavior, and the degree of learning can be monitored through estimates of these maps. 3) Incorporate a co-adaptation algorithm into the BoMI for maintaining performance as the user's mastery of the BoMI changes. In most current approaches to human-machine interfaces, the interface is fixed following an initial calibration stage, and the user must learn to control that interface configuration. In this project, the learning representation of objective (2) will be used to monitor and periodically update the BoMI map parameters. The implementation of this objective is aided by parallels between the human learning model and the AEN training method, which automatically generates a decoder network that captures the inverse map between desired device commands and the corresponding residual mobility features needed to produce them.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>07/26/2021</MinAmdLetterDate>
<MaxAmdLetterDate>07/26/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2054406</AwardID>
<Investigator>
<FirstName>Sara</FirstName>
<LastName>Solla</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sara A Solla</PI_FULL_NAME>
<EmailAddress><![CDATA[solla@northwestern.edu]]></EmailAddress>
<NSF_ID>000428940</NSF_ID>
<StartDate>07/26/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ferdinando</FirstName>
<LastName>Mussa-Ivaldi</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ferdinando A Mussa-Ivaldi</PI_FULL_NAME>
<EmailAddress><![CDATA[sandro@northwestern.edu]]></EmailAddress>
<NSF_ID>000106336</NSF_ID>
<StartDate>07/26/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rehabilitation Institute of Chicago</Name>
<CityName>CHICAGO</CityName>
<ZipCode>606113167</ZipCode>
<PhoneNumber>3122385195</PhoneNumber>
<StreetAddress>355 E ERIE ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL07</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>XAJWT43U55A3</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>REHABILITATION INSTITUTE OF CHICAGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rehabilitation Institute of Chicago]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606113167</ZipCode>
<StreetAddress><![CDATA[355 East Erie St]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>058Y</Code>
<Text>M3X - Mind, Machine, and Motor</Text>
</ProgramElement>
<ProgramReference>
<Code>070E</Code>
<Text>INTEG OF HUMAN &amp; COGNITIVE</Text>
</ProgramReference>
<ProgramReference>
<Code>7632</Code>
<Text>HUMAN-ROBOT INTERACTION</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2021~714227</FUND_OBLG>
</Award>
</rootTag>
