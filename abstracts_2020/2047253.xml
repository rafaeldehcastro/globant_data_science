<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[CAREER: Learning Structured Representations with Deep Probabilistic Programs]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2021</AwardEffectiveDate>
<AwardExpirationDate>09/30/2026</AwardExpirationDate>
<AwardTotalIntnAmount>474383.00</AwardTotalIntnAmount>
<AwardAmount>474383</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Vladimir Pavlovic</SignBlockName>
<PO_EMAI>vpavlovi@nsf.gov</PO_EMAI>
<PO_PHON>7032928318</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[Programming languages can play a decisive role in democratizing machine learning research. In deep learning, programming frameworks have made it possible – and even routine – to define neural networks in a modular manner. This has led to an explosion of research, with breakthroughs in computer vision, natural language processing, and reinforcement learning. The proposed work will develop deep probabilistic programming languages, which train neural networks to perform inference in simulation-based models. These languages will help the community address emerging challenges in artificial intelligence research by developing models that incorporate inductive biases to reason about uncertainty and improve generalization from limited data. In applications in the physical sciences, inductive biases can incorporate our physical knowledge of a problem domain. More generally, probabilistic programs help us represent model structure, for example to reason about how actions affect objects in a scene. &lt;br/&gt;&lt;br/&gt;The technical challenge that the proposed work addresses is scaling up methods for inference in probabilistic programs. To do so, the investigators will develop a language for inference programming, which will allow users to optimize the inference approach for a specific model. Inference methods reason about the posterior distribution over unknown variables in a program in light of observed data. Stochastic variational methods approximate the posterior by training a neural network that accepts data as input and returns a distribution over variables. This strategy works well in simple models in which unknown variables take the form of an unstructured vector. However, in models with more complex structure, efficient inference often requires reasoning about conditional independence. This is challenging for programmatically specified models, where reasoning about model structure requires program analysis. To address this challenge, the investigators will develop an inference language based on two constructs. The first are model combinators, which define a first-order language for composing black-box programs in a manner that allows us to reason about conditional independence. The second are inference combinators, which may be used to apply correct-by-construction importance sampling operations to specific components of the model. Together, model and inference combinators will allow users to develop correct and efficient stochastic variational methods for specific models. In addition to developing these fundamental abstractions and proving their correctness, the investigators will demonstrate the utility of these methods in applications to few-shot deep generative models, and structured energy-based models.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>07/07/2021</MinAmdLetterDate>
<MaxAmdLetterDate>08/17/2022</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2047253</AwardID>
<Investigator>
<FirstName>Jan-Willem</FirstName>
<LastName>van de Meent</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jan-Willem van de Meent</PI_FULL_NAME>
<EmailAddress><![CDATA[j.vandemeent@northeastern.edu]]></EmailAddress>
<NSF_ID>000757594</NSF_ID>
<StartDate>07/07/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northeastern University</Name>
<CityName>BOSTON</CityName>
<ZipCode>021155005</ZipCode>
<PhoneNumber>6173733004</PhoneNumber>
<StreetAddress>360 HUNTINGTON AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>HLTMVS2JZBS6</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>NORTHEASTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northeastern University]]></Name>
<CityName>Boston</CityName>
<StateCode>MA</StateCode>
<ZipCode>021155005</ZipCode>
<StreetAddress><![CDATA[360 Huntington Ave.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0122</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002223DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2021~224383</FUND_OBLG>
<FUND_OBLG>2022~250000</FUND_OBLG>
</Award>
</rootTag>
