<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Predicting attention fluctuations and their consequences for memory from functional brain connectivity]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/01/2021</AwardEffectiveDate>
<AwardExpirationDate>04/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>499999.00</AwardTotalIntnAmount>
<AwardAmount>499999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Betty Tuller</SignBlockName>
<PO_EMAI>btuller@nsf.gov</PO_EMAI>
<PO_PHON>7032927238</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[Sustained attention is critical for safely and successfully completing everyday tasks, like driving a car or listening to a presentation. Our ability to maintain focus, however, fluctuates over time when we experience mind wandering, distraction, boredom, or depletion (i.e., feeling like we’re “out of gas” when we try to sustain attention). Resulting attention failures can have deleterious consequences for ongoing behavior, such as a lapse in attention causing us to miss our exit on the highway. Such failures may also impact later memory, for example, leading to poor performance on tests of material we encountered while being inattentive. Although fluctuations in attention are pervasive, researchers lack a way to track changes in attention over time, predict attention lapses, and characterize the consequences of attention fluctuations for subsequent memory in a variety of situations, such as watching a lecture or performing an attention task (e.g., a task that requires a person to monitor a stream of images and detect a rare target picture). This project will use functional magnetic resonance imaging (fMRI) data to predict attention fluctuations during psychological and “naturalistic” tasks—like watching movies and listening to stories—and ask whether fMRI activity signatures of attentional states impact what people go on to remember at a later time. This work may help us better track attention changes and predict attention failures in lab-based and real-world contexts and will lead to a better understanding of the manner in which how we attend affects what we remember.&lt;br/&gt;&lt;br/&gt;Recent work suggests that patterns of functional brain connectivity predict a person’s overall ability to sustain attention. Functional connectivity is measured with functional magnetic resonance imaging (fMRI) and reflects statistical dependence between the fMRI signal time-courses in two different brain regions. When regions are said to be strongly functionally connected, activity in those regions tends to increase and decrease in sync, whereas activity in regions that are weakly functionally connected varies out of sync. The proposed project asks whether changes in functional connectivity from one moment to the next—that is, functional connectivity dynamics—reflect changes in the degree to which a person is attending to the task at hand. The project will also characterize how these fluctuating attentional states affect ongoing behavior and later memory. Specifically, the investigators will collect fMRI data during three different types of scans. During each scan, volunteers will be asked to either perform attention tasks in which they press a button in response to certain pictures that appear in a stream of images on a screen, rest quietly, or watch movies or listen to stories—the latter of which more closely mirror real-world situations in which we commonly experience attention fluctuations. The researchers will ask three primary questions. First, how do functional connectivity dynamics (measured by calculating functional connectivity strength in short time windows during fMRI scans) relate to attention dynamics during the tasks, rest period, and narratives? Second, how overlapping or distinct are brain networks in which the strength of activity predicts overall sustained attention and attention fluctuations in different contexts (i.e., task performance, rest, and visual and auditory narrative perception)? Finally, how are brain signatures of attentional states during encoding of information related to later memory performance, including recognition of the images encountered during the attention tasks and verbal recall of the movie and story narratives? This work may improve our ability to track changes in focus over time and predict attention failures in experimental and naturalistic contexts. It will provide insights into the functional architecture of sustained attention itself and inform us about the relationships between sustained attention and memory.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>04/14/2021</MinAmdLetterDate>
<MaxAmdLetterDate>05/20/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2043740</AwardID>
<Investigator>
<FirstName>Monica</FirstName>
<LastName>Rosenberg</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Monica D Rosenberg</PI_FULL_NAME>
<EmailAddress><![CDATA[mdrosenberg@uchicago.edu]]></EmailAddress>
<NSF_ID>000827659</NSF_ID>
<StartDate>04/14/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Chicago</Name>
<CityName>CHICAGO</CityName>
<ZipCode>606375418</ZipCode>
<PhoneNumber>7737028669</PhoneNumber>
<StreetAddress>5801 S ELLIS AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL01</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>ZUE9HKT2CLC9</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CHICAGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>ZUE9HKT2CLC9</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Chicago]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606371554</ZipCode>
<StreetAddress><![CDATA[5848 S. University Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1699</Code>
<Text>Cognitive Neuroscience</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>1699</Code>
<Text>COGNEURO</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2021~499999</FUND_OBLG>
</Award>
</rootTag>
