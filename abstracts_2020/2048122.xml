<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[CAREER: Faithful Natural Language Generation]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/01/2021</AwardEffectiveDate>
<AwardExpirationDate>03/31/2026</AwardExpirationDate>
<AwardTotalIntnAmount>549896.00</AwardTotalIntnAmount>
<AwardAmount>565896</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928729</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[Natural Language Generation is a fundamental component of many real-world applications, including generating captions for visually-impaired people. The CAREER project will seek to develop new methods for generating higher quality and more reliable sentences, and ensure better and more faithful generation results. The project will also lead to open-source software and tools that facilitate the diagnosis of neural generation models, and provide resources for building the next generation faithful language generation models. The investigator will integrate research with educational components, and enable underrepresented high school students to access Artificial Intelligence and Natural Language Processing research and course materials. &lt;br/&gt;&lt;br/&gt;A major challenge that prevents deep learning based natural language generation models in practical deployment is faithfulness. For example, in the task of image captioning, when using sequence-to-sequence models for generation, it often leads to the “hallucination” phenomenon: an object that does not belong to the context might be generated in the text. Similarly, in the task of data-to-text generation (e.g., generating a Wikipedia biography from structured data) problem, deep learning models are prone to generate erroneous entities and attributes that do not belong to the input data. These behaviors significantly downgrade the performance of neural generative models, and the faithfulness of the output becomes a significant issue for building the next generation faithful natural language generation engines. This project will investigate the complex relationships between uncertainty and faithfulness at various levels. And several mitigation strategies will also be considered. An interactive agent will be built to reason in user-generated text to understand the faithfulness constraint. The goal of this project is to deeply understand how to quantify and access faithfulness in robust settings, and build useful open-source software that facilitates this purpose.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>03/12/2021</MinAmdLetterDate>
<MaxAmdLetterDate>09/21/2023</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2048122</AwardID>
<Investigator>
<FirstName>William</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>William Wang</PI_FULL_NAME>
<EmailAddress><![CDATA[william@cs.ucsb.edu]]></EmailAddress>
<NSF_ID>000727287</NSF_ID>
<StartDate>03/12/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Santa Barbara</Name>
<CityName>SANTA BARBARA</CityName>
<ZipCode>931060001</ZipCode>
<PhoneNumber>8058934188</PhoneNumber>
<StreetAddress>3227 CHEADLE HALL</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>24</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA24</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>G9QBQDH39DF4</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SANTA BARBARA</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Santa Barbara]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>931060001</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>24</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA24</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002324DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002223DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2021~98599</FUND_OBLG>
<FUND_OBLG>2022~123737</FUND_OBLG>
<FUND_OBLG>2023~343560</FUND_OBLG>
</Award>
</rootTag>
