<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[CHS: Small: Creating a VR Workspace for Design by Physical Manipulation]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2020</AwardEffectiveDate>
<AwardExpirationDate>07/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Dan Cosley</SignBlockName>
<PO_EMAI>dcosley@nsf.gov</PO_EMAI>
<PO_PHON>7032928832</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[From an early age, humans learn to see, touch, hold, manipulate, and alter their physical surroundings using both of their hands and tools. A sculptor holds clay in one hand and precisely carves out material to create an intricate work of art. A mechanic uses hands and tools to reach the most inaccessible nooks of a car’s engine to make repairs. All who work their hands, threading needles, carving soap sculptures, or wiring electrical wall sockets know the extraordinary dexterity and precision they possess when working in the space within the near reach of both hands. The project investigates a new class of augmented and virtual reality (AR/VR) environments that allow designers to be more creative in this workspace. Existing AR/VR systems only allow users to interact at an arm’s length making it impossible to leverage the innate human ability to use hands and tools for precise actions close to the body. As a result, the original promise of AR and VR in facilitating creative thinking and problem-solving is still unrealized. Towards this, a workspace is designed in this project to enable designers to create virtual designs in three-dimensional (3D) space by mirroring the intricate, complex, and precise actions that humans can perform in daily life. The research team will develop AR/VR technology and approaches that will enable users to directly “sketch” 3D digital objects, precisely control those objects, and assemble them to create physically feasible designs.  The research team will integrate the new technology and tools from this project to promote geometric reasoning in K-12 students, undergraduate, and graduate curriculum. The project has the potential to make a long-term contribution to the future of creative work and may positively impact U.S. competency in design, manufacturing, and education by enabling small businesses to innovate effectively and economically.&lt;br/&gt;&lt;br/&gt;In order to enable the creation of a new class of AR and VR interfaces for 3D design, this research investigates precise spatial manipulation of virtual objects to facilitate 3D digital design. The research team will systematically explore new spatial interactions  by leveraging the perceptual-motor sweet spot, i.e., a portion of frontal space in the immediate vicinity of the human body where highly precise interactions are possible through the confluence of visuo-tactile perception, proprioception, and fine bi-manual motor control. Through a series of iterative design-prototype-evaluate cycles, the research team will (1) study the visuo-motor and biomechanical aspects of  tangible bi-manual interactions in the workspace for spatial object manipulation; (2) develop digital workflows for 3D design and modeling of virtual mechanical artifacts based on the those interactions; and (3) expand the digital workflows to enable physics-based design powered by haptics. First and foremost, the project will contribute to the understanding of how inherent human dexterity can be leveraged to enable precise spatial interactions. Second, the project will reveal how precise spatial interactions promote design creativity and enable creators to design functional artifacts. Finally, the research will provide tested methods for operationalizing the perceptual-motor sweet-spot through new interactive methods that integrate user intent, design feasibility, and physical realization of functional products.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>07/22/2020</MinAmdLetterDate>
<MaxAmdLetterDate>07/22/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2008800</AwardID>
<Investigator>
<FirstName>Francis</FirstName>
<LastName>Quek</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Francis Quek</PI_FULL_NAME>
<EmailAddress><![CDATA[quek@tamu.edu]]></EmailAddress>
<NSF_ID>000324474</NSF_ID>
<StartDate>07/22/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Shinjiro</FirstName>
<LastName>Sueda</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shinjiro Sueda</PI_FULL_NAME>
<EmailAddress><![CDATA[sueda@tamu.edu]]></EmailAddress>
<NSF_ID>000737684</NSF_ID>
<StartDate>07/22/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Vinayak</FirstName>
<LastName>Krishnamurthy</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Vinayak R Krishnamurthy</PI_FULL_NAME>
<EmailAddress><![CDATA[vinayak@tamu.edu]]></EmailAddress>
<NSF_ID>000729629</NSF_ID>
<StartDate>07/22/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Texas A&amp;M Engineering Experiment Station</Name>
<CityName>COLLEGE STATION</CityName>
<ZipCode>778433124</ZipCode>
<PhoneNumber>9798626777</PhoneNumber>
<StreetAddress>3124 TAMU</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>QD1MX6N5YTN4</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>TEXAS A&amp;M ENGINEERING EXPERIMENT STATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>QD1MX6N5YTN4</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Texas A&M Engineering Experiment Station]]></Name>
<CityName>College Station</CityName>
<StateCode>TX</StateCode>
<ZipCode>778433123</ZipCode>
<StreetAddress><![CDATA[3123 TAMU]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~500000</FUND_OBLG>
</Award>
</rootTag>
