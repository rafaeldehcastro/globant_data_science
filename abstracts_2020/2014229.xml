<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[SBIR Phase I:  Eyes in Sync]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2020</AwardEffectiveDate>
<AwardExpirationDate>08/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>225000.00</AwardTotalIntnAmount>
<AwardAmount>245000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>15030000</Code>
<Directorate>
<Abbreviation>TIP</Abbreviation>
<LongName>Dir for Tech, Innovation, &amp; Partnerships</LongName>
</Directorate>
<Division>
<Abbreviation>TI</Abbreviation>
<LongName>Translational Impacts</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Diane Hickey</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration><![CDATA[The broader impact of this Small Business Innovation Research (SBIR) Phase I project is to advance technologies for vision improvement. Many suffer from undetected problems with moving their eyes for reading, and current technologies do not reveal this in school screenings or sometimes, even in doctor's offices. This product will be an app designed for smartphones to engage children in games that build skills for optimally using the two eyes together, a critical element in reading ability and visual performance. The innovation will enhance scientific and technological understanding by integrating in one app eye movement, psychophysical, and reading fluency assessment. The technical result will be an all-in-one, portable, easy and fun-to-use solution for improving visual skills and reading in children. It will provide data to learning technologists to improve solutions customized to address conditions, such as dyslexia and autism.&lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research (SBIR) Phase I project addresses the issue of “functional binocular vision” or FBV. When the eyes do not look at exactly the same place, or when they cannot move across a page of text accurately and efficiently, discomfort often occurs. This discomfort causes children in particular to stop reading, affecting their learning. The project aims to develop and test an approach less expensive and more appealing than solutions available today. The proposed app will test existing visual skills (convergence and tracking) and reading fluency, then track the eyes as they move while the user plays games. Users receive points for being able to identify targets; they can only perceive the targets if their eyes are working together correctly. The technology will enable users to get immediate feedback on how they performed in the games (their visual skill level) and how their reading speed (fluency) improves.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>05/22/2020</MinAmdLetterDate>
<MaxAmdLetterDate>12/18/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2014229</AwardID>
<Investigator>
<FirstName>Maureen</FirstName>
<LastName>Powers</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Maureen K Powers</PI_FULL_NAME>
<EmailAddress><![CDATA[mopowers@eyesinsync.com]]></EmailAddress>
<NSF_ID>000712701</NSF_ID>
<StartDate>05/22/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Eyes in Synch LLC</Name>
<CityName>SAN PABLO</CityName>
<ZipCode>948061560</ZipCode>
<PhoneNumber>5107724911</PhoneNumber>
<StreetAddress>2771 SARGENT AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA08</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>UBBPUKKL2994</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>EYES IN SYNCH LLC</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Eyes in Sync]]></Name>
<CityName>Oakland</CityName>
<StateCode>CA</StateCode>
<ZipCode>946111525</ZipCode>
<StreetAddress><![CDATA[6775 Moore Dr]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramElement>
<Code>8091</Code>
<Text>SBIR Outreach &amp; Tech. Assist</Text>
</ProgramElement>
<ProgramReference>
<Code>1707</Code>
<Text>ADVANCED LEARNING TECHNOLOGIES</Text>
</ProgramReference>
<ProgramReference>
<Code>8033</Code>
<Text>Hardware Software Integration</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~225000</FUND_OBLG>
<FUND_OBLG>2021~20000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div> <p>This project aimed to develop an app that would provide practice for neuromuscular coordination of the eyes. It was designed to be used by anyone whose eyes feel uncomfortable from long screen times, reading, or active sports. The app is unique in that it is (a) in virtual reality on a standalone device (Quest 2 for now), (b) moves targets in depth independent of the background field, (c) in enclosed in a super fun game, <em>and</em> (d) available to the public as a low cost. In order to move from place to place in the game (Crystal Key), users encounter puzzles that can only be solved if their eyes are in the correct position to view the image in 3D.</p> <p>Testing the app in two separate studies revealed that</p> <ul> <li>Images can be programmed in 3D space within a VR background</li> <li>Users do not experience VR sickness, or have minimal symptoms</li> <li>Using the app for 10 sessions of 2 minutes each improved vergence eye movements</li> <li>Users showed improvement in symptoms of eye-brain fatigue</li> <li>Users&nbsp;improved the accuracy and visual processing speed to detect stimuli in 3D space</li> <li>Users prefer an adventure game like Crystal Key as opposed to several other game scenarios</li> </ul> <p>An unanticipated phenomenon while viewing the 3D stimuli was a shimmering perception. We plan to develop this as a separate set of computer coding, so that artists or moviemakers or game developers can incorporate it into their own products through a license from Eyes in Sync.</p> <p>When fully developed, Crystal Key will provide an inexpensive, scientifically valid, fun tool for improving academic function in school children: our main goal is to facilitate reading fluency, which we know from earlier work does improve (more words read correctly per minute) after this type of neuromuscular training of the eye-brain connection. Ultimately, this app could revolutionize education, because we have seen improvements in fluency of 20% to 200% in earlier apps. Other organizations have expressed interest, including military and sports. With further development in Phase II, the product should be available commercially in about 18 months.</p> </div><br> <p>            Last Modified: 11/30/2021<br>      Modified by: Maureen&nbsp;K&nbsp;Powers</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  This project aimed to develop an app that would provide practice for neuromuscular coordination of the eyes. It was designed to be used by anyone whose eyes feel uncomfortable from long screen times, reading, or active sports. The app is unique in that it is (a) in virtual reality on a standalone device (Quest 2 for now), (b) moves targets in depth independent of the background field, (c) in enclosed in a super fun game, and (d) available to the public as a low cost. In order to move from place to place in the game (Crystal Key), users encounter puzzles that can only be solved if their eyes are in the correct position to view the image in 3D.  Testing the app in two separate studies revealed that  Images can be programmed in 3D space within a VR background Users do not experience VR sickness, or have minimal symptoms Using the app for 10 sessions of 2 minutes each improved vergence eye movements Users showed improvement in symptoms of eye-brain fatigue Users improved the accuracy and visual processing speed to detect stimuli in 3D space Users prefer an adventure game like Crystal Key as opposed to several other game scenarios   An unanticipated phenomenon while viewing the 3D stimuli was a shimmering perception. We plan to develop this as a separate set of computer coding, so that artists or moviemakers or game developers can incorporate it into their own products through a license from Eyes in Sync.  When fully developed, Crystal Key will provide an inexpensive, scientifically valid, fun tool for improving academic function in school children: our main goal is to facilitate reading fluency, which we know from earlier work does improve (more words read correctly per minute) after this type of neuromuscular training of the eye-brain connection. Ultimately, this app could revolutionize education, because we have seen improvements in fluency of 20% to 200% in earlier apps. Other organizations have expressed interest, including military and sports. With further development in Phase II, the product should be available commercially in about 18 months.        Last Modified: 11/30/2021       Submitted by: Maureen K Powers]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
