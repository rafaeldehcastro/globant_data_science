<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[CAREER: Learning and property testing -- a complexity theoretic perspective]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2021</AwardEffectiveDate>
<AwardExpirationDate>06/30/2026</AwardExpirationDate>
<AwardTotalIntnAmount>420983.00</AwardTotalIntnAmount>
<AwardAmount>206804</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Brass</SignBlockName>
<PO_EMAI>pbrass@nsf.gov</PO_EMAI>
<PO_PHON>7032922182</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[From genomics to meteorology, advanced technology has led to collection of data at an unprecedented scale. In turn, the future promise of science is crucially reliant on our ability to analyze such massive and complex datasets. To gain deeper insights here, modern data analysis relies on mathematical abstractions called models. In particular, a central desideratum of machine learning is to find simple models which fit a given dataset. Accordingly, theoretical computer science, machine learning and statistics have developed both mathematical and algorithmic frameworks in this pursuit. The goal of this project is to put this agenda under the lens of computational complexity theory. In particular, using tools and insights from complexity theory, the investigator will study (i) efficient learning algorithms for several high-dimensional models which appear in machine learning and statistics, and (ii) explore the tradeoffs between robustness, efficiency, data size and accuracy for these models. Besides the mathematical foundations of machine learning, the underlying questions also appear in a wide variety of applications ranging from evolutionary biology to signal processing. Through the introduction of new courses at the intersection of complexity theory, machine learning and statistics, as well as other activities such as workshops and seminars, the project will train the next generation of graduate students who will achieve fluency in all of these areas leading to a further cross-pollination of ideas between these disciplines. The project will also support activities aimed at attracting undergraduate students to research in theoretical computer science, especially those from underrepresented groups. &lt;br/&gt;&lt;br/&gt;The project has two principal thrusts: (1) Noise tolerant learning algorithms for high-dimensional models: The project will study both supervised and unsupervised models such as linear separators, Gaussian mixture models and trace reconstruction (which is an abstraction of the problem of ancestral DNA reconstruction from evolutionary biology). For these models, the project will explore the three-way tradeoff between sample efficiency, computational efficiency and noise tolerance. (2) Algorithms to test high dimensional models for sparse representations: Examples of such models include Boolean functions over the hypercube and high-dimensional matrices. The overarching goal here is to design algorithms whose complexity is independent of the ambient dimension, thus avoiding the proverbial curse of dimensionality. Underlying this broad agenda is the insight that Boolean function analysis -- a suite of tools developed in complexity theory which combines combinatorics, harmonic analysis and probability theory -- is an effective algorithmic tool for learning and testing high dimensional models in machine learning and statistics.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>02/23/2021</MinAmdLetterDate>
<MaxAmdLetterDate>06/27/2023</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2045128</AwardID>
<Investigator>
<FirstName>Anindya</FirstName>
<LastName>De</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Anindya De</PI_FULL_NAME>
<EmailAddress><![CDATA[de.anindya@gmail.com]]></EmailAddress>
<NSF_ID>000726648</NSF_ID>
<StartDate>02/23/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Pennsylvania</Name>
<CityName>PHILADELPHIA</CityName>
<ZipCode>191046205</ZipCode>
<PhoneNumber>2158987293</PhoneNumber>
<StreetAddress>3451 WALNUT ST STE 440A</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA03</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>GM1XX56LEP58</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>GM1XX56LEP58</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Pennsylvania]]></Name>
<CityName>Philadelphia</CityName>
<StateCode>PA</StateCode>
<ZipCode>191043409</ZipCode>
<StreetAddress><![CDATA[3330 Walnut St, Levine Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7796</Code>
<Text>Algorithmic Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7926</Code>
<Text>ALGORITHMS</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002324DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2021~126567</FUND_OBLG>
<FUND_OBLG>2023~80237</FUND_OBLG>
</Award>
</rootTag>
